2022-09-28 11:24:43,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-28 11:24:43,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-28 11:24:43,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-28 11:24:43,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-28 11:24:48,372:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2022-09-28 11:25:58,533:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")

2022-09-28 11:26:09,157:INFO:PyCaret RegressionExperiment
2022-09-28 11:26:09,157:INFO:Logging name: reg-default-name
2022-09-28 11:26:09,157:INFO:ML Usecase: MLUsecase.REGRESSION
2022-09-28 11:26:09,157:INFO:version 3.0.0.rc4
2022-09-28 11:26:09,157:INFO:Initializing setup()
2022-09-28 11:26:09,157:INFO:self.USI: d6e7
2022-09-28 11:26:09,157:INFO:self.variable_keys: {'gpu_param', 'n_jobs_param', 'target_param', 'fold_generator', 'variable_keys', '_all_metrics', 'data', 'exp_id', 'USI', 'y', 'master_model_container', 'seed', 'fold_shuffle_param', 'transform_target_method_param', 'y_train', 'logging_param', '_available_plots', 'X_test', '_ml_usecase', 'y_test', 'pipeline', 'X_train', '_all_models_internal', 'exp_name_log', 'X', 'transform_target_param', 'memory', 'log_plots_param', 'idx', 'fold_groups_param', '_gpu_n_jobs_param', 'display_container', '_all_models', 'html_param'}
2022-09-28 11:26:09,158:INFO:Checking environment
2022-09-28 11:26:09,158:INFO:python_version: 3.10.6
2022-09-28 11:26:09,158:INFO:python_build: ('main', 'Aug 11 2022 13:36:31')
2022-09-28 11:26:09,158:INFO:machine: arm64
2022-09-28 11:26:09,158:INFO:platform: macOS-12.5.1-arm64-arm-64bit
2022-09-28 11:26:09,158:INFO:Memory: svmem(total=17179869184, available=5775048704, percent=66.4, used=7502888960, free=97288192, active=5693751296, inactive=5676007424, wired=1809137664)
2022-09-28 11:26:09,158:INFO:Physical Core: 10
2022-09-28 11:26:09,158:INFO:Logical Core: 10
2022-09-28 11:26:09,158:INFO:Checking libraries
2022-09-28 11:26:09,159:INFO:System:
2022-09-28 11:26:09,159:INFO:    python: 3.10.6 (main, Aug 11 2022, 13:36:31) [Clang 13.1.6 (clang-1316.0.21.2.5)]
2022-09-28 11:26:09,159:INFO:executable: /Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/bin/python
2022-09-28 11:26:09,159:INFO:   machine: macOS-12.5.1-arm64-arm-64bit
2022-09-28 11:26:09,159:INFO:PyCaret required dependencies:
2022-09-28 11:26:09,160:INFO:                 pip: 22.2.2
2022-09-28 11:26:09,160:INFO:          setuptools: 65.4.0
2022-09-28 11:26:09,160:INFO:             pycaret: 3.0.0rc4
2022-09-28 11:26:09,160:INFO:             IPython: 8.5.0
2022-09-28 11:26:09,160:INFO:          ipywidgets: 8.0.2
2022-09-28 11:26:09,160:INFO:                tqdm: 4.64.1
2022-09-28 11:26:09,160:INFO:               numpy: 1.22.4
2022-09-28 11:26:09,160:INFO:              pandas: 1.4.4
2022-09-28 11:26:09,160:INFO:              jinja2: 3.1.2
2022-09-28 11:26:09,161:INFO:               scipy: 1.8.1
2022-09-28 11:26:09,161:INFO:              joblib: 1.2.0
2022-09-28 11:26:09,161:INFO:             sklearn: 1.1.2
2022-09-28 11:26:09,161:INFO:                pyod: 1.0.5
2022-09-28 11:26:09,161:INFO:            imblearn: 0.9.1
2022-09-28 11:26:09,161:INFO:   category_encoders: 2.5.0
2022-09-28 11:26:09,161:INFO:            lightgbm: 3.3.2
2022-09-28 11:26:09,162:INFO:               numba: 0.55.2
2022-09-28 11:26:09,162:INFO:            requests: 2.28.1
2022-09-28 11:26:09,162:INFO:          matplotlib: 3.6.0
2022-09-28 11:26:09,162:INFO:          scikitplot: 0.3.7
2022-09-28 11:26:09,162:INFO:         yellowbrick: 1.5
2022-09-28 11:26:09,162:INFO:              plotly: 5.10.0
2022-09-28 11:26:09,162:INFO:             kaleido: 0.2.1
2022-09-28 11:26:09,162:INFO:         statsmodels: 0.13.2
2022-09-28 11:26:09,162:INFO:              sktime: 0.13.4
2022-09-28 11:26:09,162:INFO:               tbats: 1.1.0
2022-09-28 11:26:09,162:INFO:            pmdarima: 1.8.5
2022-09-28 11:26:09,162:INFO:              psutil: 5.9.2
2022-09-28 11:26:09,162:INFO:PyCaret optional dependencies:
2022-09-28 11:26:09,172:INFO:                shap: Not installed
2022-09-28 11:26:09,172:INFO:           interpret: Not installed
2022-09-28 11:26:09,172:INFO:                umap: Not installed
2022-09-28 11:26:09,172:INFO:    pandas_profiling: Not installed
2022-09-28 11:26:09,172:INFO:  explainerdashboard: Not installed
2022-09-28 11:26:09,172:INFO:             autoviz: Not installed
2022-09-28 11:26:09,172:INFO:           fairlearn: Not installed
2022-09-28 11:26:09,172:INFO:             xgboost: 1.6.2
2022-09-28 11:26:09,172:INFO:            catboost: Not installed
2022-09-28 11:26:09,172:INFO:              kmodes: Not installed
2022-09-28 11:26:09,172:INFO:             mlxtend: Not installed
2022-09-28 11:26:09,172:INFO:       statsforecast: Not installed
2022-09-28 11:26:09,172:INFO:        tune_sklearn: Not installed
2022-09-28 11:26:09,172:INFO:                 ray: Not installed
2022-09-28 11:26:09,173:INFO:            hyperopt: Not installed
2022-09-28 11:26:09,173:INFO:              optuna: Not installed
2022-09-28 11:26:09,173:INFO:               skopt: Not installed
2022-09-28 11:26:09,173:INFO:              mlflow: Not installed
2022-09-28 11:26:09,173:INFO:              gradio: Not installed
2022-09-28 11:26:09,173:INFO:             fastapi: Not installed
2022-09-28 11:26:09,173:INFO:             uvicorn: Not installed
2022-09-28 11:26:09,173:INFO:              m2cgen: Not installed
2022-09-28 11:26:09,173:INFO:           evidently: Not installed
2022-09-28 11:26:09,173:INFO:                nltk: Not installed
2022-09-28 11:26:09,173:INFO:            pyLDAvis: Not installed
2022-09-28 11:26:09,173:INFO:              gensim: Not installed
2022-09-28 11:26:09,173:INFO:               spacy: Not installed
2022-09-28 11:26:09,173:INFO:           wordcloud: Not installed
2022-09-28 11:26:09,173:INFO:            textblob: Not installed
2022-09-28 11:26:09,173:INFO:               fugue: Not installed
2022-09-28 11:26:09,173:INFO:           streamlit: Not installed
2022-09-28 11:26:09,173:INFO:             prophet: Not installed
2022-09-28 11:26:09,173:INFO:None
2022-09-28 11:26:09,173:INFO:Set up data.
2022-09-28 11:26:09,178:INFO:Set up train/test split.
2022-09-28 11:26:09,181:INFO:Set up index.
2022-09-28 11:26:09,181:INFO:Set up folding strategy.
2022-09-28 11:26:09,181:INFO:Assigning column types.
2022-09-28 11:26:09,182:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-09-28 11:26:09,183:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-28 11:26:09,185:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:26:09,188:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:26:09,224:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:26:09,246:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:26:09,246:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:26:09,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:26:09,819:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-28 11:26:09,821:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:26:09,824:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:26:09,857:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:26:09,876:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:26:09,877:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:26:09,878:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:26:09,878:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-09-28 11:26:09,880:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:26:09,882:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:26:09,906:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:26:09,925:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:26:09,925:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:26:09,926:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:26:09,928:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:26:09,930:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:26:09,955:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:26:09,975:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:26:09,975:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:26:09,976:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:26:09,976:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-09-28 11:26:09,980:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:26:10,004:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:26:10,024:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:26:10,024:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:26:10,025:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:26:10,029:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:26:10,053:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:26:10,072:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:26:10,072:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:26:10,073:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:26:10,073:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-09-28 11:26:10,101:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:26:10,119:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:26:10,119:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:26:10,120:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:26:10,149:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:26:10,168:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:26:10,168:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:26:10,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:26:10,169:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-09-28 11:26:10,197:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:26:10,216:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:26:10,217:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:26:10,244:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:26:10,263:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:26:10,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:26:10,264:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-09-28 11:26:10,311:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:26:10,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:26:10,359:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:26:10,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:26:10,362:INFO:Preparing preprocessing pipeline...
2022-09-28 11:26:10,363:INFO:Set up simple imputation.
2022-09-28 11:26:10,363:INFO:Set up variance threshold.
2022-09-28 11:26:10,388:INFO:Finished creating preprocessing pipeline.
2022-09-28 11:26:10,390:INFO:Pipeline: Pipeline(memory=Memory(location=/var/folders/67/hmlyjz1x4x7b_71cqk6bxrg00000gq/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demand_point_index',
                                             'x_coordinate', 'y_coordinate',
                                             '2010', '2011', '2012', '2013',
                                             '2014', '2015', '2016', '2017'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-09-28 11:26:10,390:INFO:Creating final display dataframe.
2022-09-28 11:26:10,479:INFO:Setup display_container:                Description             Value
0               Session id               123
1                   Target              2018
2              Target type        Regression
3               Data shape        (4096, 12)
4         Train data shape        (2867, 12)
5          Test data shape        (1229, 12)
6         Numeric features                11
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              d6e7
2022-09-28 11:26:10,530:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:26:10,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:26:10,579:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:26:10,580:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:26:10,582:INFO:setup() successfully completed in 1.43s...............
2022-09-28 11:27:25,377:INFO:Initializing compare_models()
2022-09-28 11:27:25,378:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-09-28 11:27:25,378:INFO:Checking exceptions
2022-09-28 11:27:25,383:INFO:Preparing display monitor
2022-09-28 11:27:25,428:INFO:Initializing Linear Regression
2022-09-28 11:27:25,429:INFO:Total runtime is 7.065137227376302e-06 minutes
2022-09-28 11:27:25,430:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:25,431:INFO:Initializing create_model()
2022-09-28 11:27:25,431:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:25,431:INFO:Checking exceptions
2022-09-28 11:27:25,433:INFO:Importing libraries
2022-09-28 11:27:25,433:INFO:Copying training dataset
2022-09-28 11:27:25,437:INFO:Defining folds
2022-09-28 11:27:25,437:INFO:Declaring metric variables
2022-09-28 11:27:25,439:INFO:Importing untrained model
2022-09-28 11:27:25,441:INFO:Linear Regression Imported successfully
2022-09-28 11:27:25,444:INFO:Starting cross validation
2022-09-28 11:27:25,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:27,111:INFO:Calculating mean and std
2022-09-28 11:27:27,117:INFO:Creating metrics dataframe
2022-09-28 11:27:27,125:INFO:Uploading results into container
2022-09-28 11:27:27,125:INFO:Uploading model into container now
2022-09-28 11:27:27,126:INFO:master_model_container: 1
2022-09-28 11:27:27,126:INFO:display_container: 2
2022-09-28 11:27:27,126:INFO:LinearRegression(n_jobs=-1)
2022-09-28 11:27:27,126:INFO:create_model() successfully completed......................................
2022-09-28 11:27:27,203:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:27,203:INFO:Creating metrics dataframe
2022-09-28 11:27:27,207:INFO:Initializing Lasso Regression
2022-09-28 11:27:27,207:INFO:Total runtime is 0.029651633898417153 minutes
2022-09-28 11:27:27,209:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:27,209:INFO:Initializing create_model()
2022-09-28 11:27:27,209:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:27,209:INFO:Checking exceptions
2022-09-28 11:27:27,210:INFO:Importing libraries
2022-09-28 11:27:27,210:INFO:Copying training dataset
2022-09-28 11:27:27,212:INFO:Defining folds
2022-09-28 11:27:27,212:INFO:Declaring metric variables
2022-09-28 11:27:27,213:INFO:Importing untrained model
2022-09-28 11:27:27,215:INFO:Lasso Regression Imported successfully
2022-09-28 11:27:27,219:INFO:Starting cross validation
2022-09-28 11:27:27,220:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:27,278:INFO:Calculating mean and std
2022-09-28 11:27:27,278:INFO:Creating metrics dataframe
2022-09-28 11:27:27,279:INFO:Uploading results into container
2022-09-28 11:27:27,279:INFO:Uploading model into container now
2022-09-28 11:27:27,279:INFO:master_model_container: 2
2022-09-28 11:27:27,279:INFO:display_container: 2
2022-09-28 11:27:27,280:INFO:Lasso(random_state=123)
2022-09-28 11:27:27,280:INFO:create_model() successfully completed......................................
2022-09-28 11:27:27,339:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:27,340:INFO:Creating metrics dataframe
2022-09-28 11:27:27,343:INFO:Initializing Ridge Regression
2022-09-28 11:27:27,343:INFO:Total runtime is 0.03192038536071777 minutes
2022-09-28 11:27:27,345:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:27,345:INFO:Initializing create_model()
2022-09-28 11:27:27,345:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:27,345:INFO:Checking exceptions
2022-09-28 11:27:27,346:INFO:Importing libraries
2022-09-28 11:27:27,346:INFO:Copying training dataset
2022-09-28 11:27:27,348:INFO:Defining folds
2022-09-28 11:27:27,348:INFO:Declaring metric variables
2022-09-28 11:27:27,349:INFO:Importing untrained model
2022-09-28 11:27:27,351:INFO:Ridge Regression Imported successfully
2022-09-28 11:27:27,354:INFO:Starting cross validation
2022-09-28 11:27:27,354:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:27,394:INFO:Calculating mean and std
2022-09-28 11:27:27,395:INFO:Creating metrics dataframe
2022-09-28 11:27:27,396:INFO:Uploading results into container
2022-09-28 11:27:27,396:INFO:Uploading model into container now
2022-09-28 11:27:27,396:INFO:master_model_container: 3
2022-09-28 11:27:27,396:INFO:display_container: 2
2022-09-28 11:27:27,396:INFO:Ridge(random_state=123)
2022-09-28 11:27:27,396:INFO:create_model() successfully completed......................................
2022-09-28 11:27:27,457:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:27,457:INFO:Creating metrics dataframe
2022-09-28 11:27:27,460:INFO:Initializing Elastic Net
2022-09-28 11:27:27,461:INFO:Total runtime is 0.033873184521993 minutes
2022-09-28 11:27:27,462:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:27,462:INFO:Initializing create_model()
2022-09-28 11:27:27,462:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:27,462:INFO:Checking exceptions
2022-09-28 11:27:27,463:INFO:Importing libraries
2022-09-28 11:27:27,463:INFO:Copying training dataset
2022-09-28 11:27:27,465:INFO:Defining folds
2022-09-28 11:27:27,465:INFO:Declaring metric variables
2022-09-28 11:27:27,466:INFO:Importing untrained model
2022-09-28 11:27:27,468:INFO:Elastic Net Imported successfully
2022-09-28 11:27:27,470:INFO:Starting cross validation
2022-09-28 11:27:27,470:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:27,524:INFO:Calculating mean and std
2022-09-28 11:27:27,525:INFO:Creating metrics dataframe
2022-09-28 11:27:27,526:INFO:Uploading results into container
2022-09-28 11:27:27,526:INFO:Uploading model into container now
2022-09-28 11:27:27,526:INFO:master_model_container: 4
2022-09-28 11:27:27,526:INFO:display_container: 2
2022-09-28 11:27:27,526:INFO:ElasticNet(random_state=123)
2022-09-28 11:27:27,526:INFO:create_model() successfully completed......................................
2022-09-28 11:27:27,586:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:27,586:INFO:Creating metrics dataframe
2022-09-28 11:27:27,590:INFO:Initializing Least Angle Regression
2022-09-28 11:27:27,590:INFO:Total runtime is 0.036026918888092035 minutes
2022-09-28 11:27:27,591:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:27,591:INFO:Initializing create_model()
2022-09-28 11:27:27,591:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:27,591:INFO:Checking exceptions
2022-09-28 11:27:27,592:INFO:Importing libraries
2022-09-28 11:27:27,592:INFO:Copying training dataset
2022-09-28 11:27:27,594:INFO:Defining folds
2022-09-28 11:27:27,594:INFO:Declaring metric variables
2022-09-28 11:27:27,596:INFO:Importing untrained model
2022-09-28 11:27:27,597:INFO:Least Angle Regression Imported successfully
2022-09-28 11:27:27,600:INFO:Starting cross validation
2022-09-28 11:27:27,601:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:27,617:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,619:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,621:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,623:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,626:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,629:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,631:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,634:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,635:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,638:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,643:INFO:Calculating mean and std
2022-09-28 11:27:27,643:INFO:Creating metrics dataframe
2022-09-28 11:27:27,644:INFO:Uploading results into container
2022-09-28 11:27:27,644:INFO:Uploading model into container now
2022-09-28 11:27:27,645:INFO:master_model_container: 5
2022-09-28 11:27:27,645:INFO:display_container: 2
2022-09-28 11:27:27,645:INFO:Lars(random_state=123)
2022-09-28 11:27:27,645:INFO:create_model() successfully completed......................................
2022-09-28 11:27:27,704:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:27,704:INFO:Creating metrics dataframe
2022-09-28 11:27:27,708:INFO:Initializing Lasso Least Angle Regression
2022-09-28 11:27:27,708:INFO:Total runtime is 0.03800415198008219 minutes
2022-09-28 11:27:27,710:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:27,710:INFO:Initializing create_model()
2022-09-28 11:27:27,710:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:27,710:INFO:Checking exceptions
2022-09-28 11:27:27,711:INFO:Importing libraries
2022-09-28 11:27:27,711:INFO:Copying training dataset
2022-09-28 11:27:27,713:INFO:Defining folds
2022-09-28 11:27:27,713:INFO:Declaring metric variables
2022-09-28 11:27:27,714:INFO:Importing untrained model
2022-09-28 11:27:27,716:INFO:Lasso Least Angle Regression Imported successfully
2022-09-28 11:27:27,721:INFO:Starting cross validation
2022-09-28 11:27:27,722:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:27,740:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:27:27,741:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:27:27,744:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:27:27,747:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:27:27,749:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:27:27,752:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:27:27,755:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:27:27,757:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:27:27,759:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:27:27,761:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:27:27,766:INFO:Calculating mean and std
2022-09-28 11:27:27,766:INFO:Creating metrics dataframe
2022-09-28 11:27:27,767:INFO:Uploading results into container
2022-09-28 11:27:27,768:INFO:Uploading model into container now
2022-09-28 11:27:27,768:INFO:master_model_container: 6
2022-09-28 11:27:27,768:INFO:display_container: 2
2022-09-28 11:27:27,768:INFO:LassoLars(random_state=123)
2022-09-28 11:27:27,768:INFO:create_model() successfully completed......................................
2022-09-28 11:27:27,828:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:27,828:INFO:Creating metrics dataframe
2022-09-28 11:27:27,832:INFO:Initializing Orthogonal Matching Pursuit
2022-09-28 11:27:27,832:INFO:Total runtime is 0.04006883303324381 minutes
2022-09-28 11:27:27,834:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:27,834:INFO:Initializing create_model()
2022-09-28 11:27:27,834:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:27,834:INFO:Checking exceptions
2022-09-28 11:27:27,835:INFO:Importing libraries
2022-09-28 11:27:27,835:INFO:Copying training dataset
2022-09-28 11:27:27,837:INFO:Defining folds
2022-09-28 11:27:27,837:INFO:Declaring metric variables
2022-09-28 11:27:27,838:INFO:Importing untrained model
2022-09-28 11:27:27,840:INFO:Orthogonal Matching Pursuit Imported successfully
2022-09-28 11:27:27,843:INFO:Starting cross validation
2022-09-28 11:27:27,843:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:27,858:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,860:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,862:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,864:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,867:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,868:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,871:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,873:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,875:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,877:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:27:27,883:INFO:Calculating mean and std
2022-09-28 11:27:27,883:INFO:Creating metrics dataframe
2022-09-28 11:27:27,884:INFO:Uploading results into container
2022-09-28 11:27:27,884:INFO:Uploading model into container now
2022-09-28 11:27:27,884:INFO:master_model_container: 7
2022-09-28 11:27:27,884:INFO:display_container: 2
2022-09-28 11:27:27,885:INFO:OrthogonalMatchingPursuit()
2022-09-28 11:27:27,885:INFO:create_model() successfully completed......................................
2022-09-28 11:27:27,944:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:27,945:INFO:Creating metrics dataframe
2022-09-28 11:27:27,949:INFO:Initializing Bayesian Ridge
2022-09-28 11:27:27,949:INFO:Total runtime is 0.042013883590698235 minutes
2022-09-28 11:27:27,950:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:27,951:INFO:Initializing create_model()
2022-09-28 11:27:27,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:27,951:INFO:Checking exceptions
2022-09-28 11:27:27,951:INFO:Importing libraries
2022-09-28 11:27:27,952:INFO:Copying training dataset
2022-09-28 11:27:27,953:INFO:Defining folds
2022-09-28 11:27:27,953:INFO:Declaring metric variables
2022-09-28 11:27:27,955:INFO:Importing untrained model
2022-09-28 11:27:27,957:INFO:Bayesian Ridge Imported successfully
2022-09-28 11:27:27,960:INFO:Starting cross validation
2022-09-28 11:27:27,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:28,002:INFO:Calculating mean and std
2022-09-28 11:27:28,002:INFO:Creating metrics dataframe
2022-09-28 11:27:28,004:INFO:Uploading results into container
2022-09-28 11:27:28,004:INFO:Uploading model into container now
2022-09-28 11:27:28,004:INFO:master_model_container: 8
2022-09-28 11:27:28,004:INFO:display_container: 2
2022-09-28 11:27:28,004:INFO:BayesianRidge()
2022-09-28 11:27:28,004:INFO:create_model() successfully completed......................................
2022-09-28 11:27:28,064:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:28,064:INFO:Creating metrics dataframe
2022-09-28 11:27:28,068:INFO:Initializing Passive Aggressive Regressor
2022-09-28 11:27:28,068:INFO:Total runtime is 0.04399971961975097 minutes
2022-09-28 11:27:28,070:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:28,070:INFO:Initializing create_model()
2022-09-28 11:27:28,070:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:28,070:INFO:Checking exceptions
2022-09-28 11:27:28,071:INFO:Importing libraries
2022-09-28 11:27:28,071:INFO:Copying training dataset
2022-09-28 11:27:28,073:INFO:Defining folds
2022-09-28 11:27:28,073:INFO:Declaring metric variables
2022-09-28 11:27:28,074:INFO:Importing untrained model
2022-09-28 11:27:28,076:INFO:Passive Aggressive Regressor Imported successfully
2022-09-28 11:27:28,078:INFO:Starting cross validation
2022-09-28 11:27:28,079:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:28,122:INFO:Calculating mean and std
2022-09-28 11:27:28,123:INFO:Creating metrics dataframe
2022-09-28 11:27:28,124:INFO:Uploading results into container
2022-09-28 11:27:28,124:INFO:Uploading model into container now
2022-09-28 11:27:28,124:INFO:master_model_container: 9
2022-09-28 11:27:28,124:INFO:display_container: 2
2022-09-28 11:27:28,124:INFO:PassiveAggressiveRegressor(random_state=123)
2022-09-28 11:27:28,124:INFO:create_model() successfully completed......................................
2022-09-28 11:27:28,184:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:28,184:INFO:Creating metrics dataframe
2022-09-28 11:27:28,188:INFO:Initializing Huber Regressor
2022-09-28 11:27:28,188:INFO:Total runtime is 0.046001799901326496 minutes
2022-09-28 11:27:28,190:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:28,190:INFO:Initializing create_model()
2022-09-28 11:27:28,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:28,190:INFO:Checking exceptions
2022-09-28 11:27:28,191:INFO:Importing libraries
2022-09-28 11:27:28,191:INFO:Copying training dataset
2022-09-28 11:27:28,192:INFO:Defining folds
2022-09-28 11:27:28,192:INFO:Declaring metric variables
2022-09-28 11:27:28,194:INFO:Importing untrained model
2022-09-28 11:27:28,195:INFO:Huber Regressor Imported successfully
2022-09-28 11:27:28,198:INFO:Starting cross validation
2022-09-28 11:27:28,198:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:28,239:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:27:28,239:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:27:28,244:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:27:28,246:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:27:28,247:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:27:28,248:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:27:28,249:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:27:28,263:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:27:28,264:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:27:28,275:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:27:28,279:INFO:Calculating mean and std
2022-09-28 11:27:28,279:INFO:Creating metrics dataframe
2022-09-28 11:27:28,280:INFO:Uploading results into container
2022-09-28 11:27:28,281:INFO:Uploading model into container now
2022-09-28 11:27:28,281:INFO:master_model_container: 10
2022-09-28 11:27:28,281:INFO:display_container: 2
2022-09-28 11:27:28,281:INFO:HuberRegressor()
2022-09-28 11:27:28,281:INFO:create_model() successfully completed......................................
2022-09-28 11:27:28,340:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:28,340:INFO:Creating metrics dataframe
2022-09-28 11:27:28,345:INFO:Initializing K Neighbors Regressor
2022-09-28 11:27:28,345:INFO:Total runtime is 0.048617283503214516 minutes
2022-09-28 11:27:28,347:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:28,347:INFO:Initializing create_model()
2022-09-28 11:27:28,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:28,347:INFO:Checking exceptions
2022-09-28 11:27:28,348:INFO:Importing libraries
2022-09-28 11:27:28,348:INFO:Copying training dataset
2022-09-28 11:27:28,349:INFO:Defining folds
2022-09-28 11:27:28,349:INFO:Declaring metric variables
2022-09-28 11:27:28,351:INFO:Importing untrained model
2022-09-28 11:27:28,352:INFO:K Neighbors Regressor Imported successfully
2022-09-28 11:27:28,355:INFO:Starting cross validation
2022-09-28 11:27:28,355:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:28,404:INFO:Calculating mean and std
2022-09-28 11:27:28,404:INFO:Creating metrics dataframe
2022-09-28 11:27:28,406:INFO:Uploading results into container
2022-09-28 11:27:28,406:INFO:Uploading model into container now
2022-09-28 11:27:28,406:INFO:master_model_container: 11
2022-09-28 11:27:28,406:INFO:display_container: 2
2022-09-28 11:27:28,406:INFO:KNeighborsRegressor(n_jobs=-1)
2022-09-28 11:27:28,406:INFO:create_model() successfully completed......................................
2022-09-28 11:27:28,466:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:28,466:INFO:Creating metrics dataframe
2022-09-28 11:27:28,471:INFO:Initializing Decision Tree Regressor
2022-09-28 11:27:28,471:INFO:Total runtime is 0.05071543455123901 minutes
2022-09-28 11:27:28,473:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:28,473:INFO:Initializing create_model()
2022-09-28 11:27:28,473:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:28,473:INFO:Checking exceptions
2022-09-28 11:27:28,474:INFO:Importing libraries
2022-09-28 11:27:28,474:INFO:Copying training dataset
2022-09-28 11:27:28,475:INFO:Defining folds
2022-09-28 11:27:28,475:INFO:Declaring metric variables
2022-09-28 11:27:28,477:INFO:Importing untrained model
2022-09-28 11:27:28,478:INFO:Decision Tree Regressor Imported successfully
2022-09-28 11:27:28,481:INFO:Starting cross validation
2022-09-28 11:27:28,481:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:28,547:INFO:Calculating mean and std
2022-09-28 11:27:28,547:INFO:Creating metrics dataframe
2022-09-28 11:27:28,548:INFO:Uploading results into container
2022-09-28 11:27:28,548:INFO:Uploading model into container now
2022-09-28 11:27:28,548:INFO:master_model_container: 12
2022-09-28 11:27:28,548:INFO:display_container: 2
2022-09-28 11:27:28,549:INFO:DecisionTreeRegressor(random_state=123)
2022-09-28 11:27:28,549:INFO:create_model() successfully completed......................................
2022-09-28 11:27:28,608:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:28,608:INFO:Creating metrics dataframe
2022-09-28 11:27:28,613:INFO:Initializing Random Forest Regressor
2022-09-28 11:27:28,613:INFO:Total runtime is 0.053077280521392815 minutes
2022-09-28 11:27:28,614:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:28,614:INFO:Initializing create_model()
2022-09-28 11:27:28,614:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:28,614:INFO:Checking exceptions
2022-09-28 11:27:28,615:INFO:Importing libraries
2022-09-28 11:27:28,615:INFO:Copying training dataset
2022-09-28 11:27:28,617:INFO:Defining folds
2022-09-28 11:27:28,617:INFO:Declaring metric variables
2022-09-28 11:27:28,618:INFO:Importing untrained model
2022-09-28 11:27:28,620:INFO:Random Forest Regressor Imported successfully
2022-09-28 11:27:28,622:INFO:Starting cross validation
2022-09-28 11:27:28,623:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:29,726:INFO:Calculating mean and std
2022-09-28 11:27:29,726:INFO:Creating metrics dataframe
2022-09-28 11:27:29,727:INFO:Uploading results into container
2022-09-28 11:27:29,728:INFO:Uploading model into container now
2022-09-28 11:27:29,728:INFO:master_model_container: 13
2022-09-28 11:27:29,728:INFO:display_container: 2
2022-09-28 11:27:29,728:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:27:29,728:INFO:create_model() successfully completed......................................
2022-09-28 11:27:29,788:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:29,788:INFO:Creating metrics dataframe
2022-09-28 11:27:29,793:INFO:Initializing Extra Trees Regressor
2022-09-28 11:27:29,794:INFO:Total runtime is 0.0727562665939331 minutes
2022-09-28 11:27:29,795:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:29,795:INFO:Initializing create_model()
2022-09-28 11:27:29,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:29,795:INFO:Checking exceptions
2022-09-28 11:27:29,796:INFO:Importing libraries
2022-09-28 11:27:29,796:INFO:Copying training dataset
2022-09-28 11:27:29,798:INFO:Defining folds
2022-09-28 11:27:29,798:INFO:Declaring metric variables
2022-09-28 11:27:29,799:INFO:Importing untrained model
2022-09-28 11:27:29,801:INFO:Extra Trees Regressor Imported successfully
2022-09-28 11:27:29,803:INFO:Starting cross validation
2022-09-28 11:27:29,804:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:30,369:INFO:Calculating mean and std
2022-09-28 11:27:30,369:INFO:Creating metrics dataframe
2022-09-28 11:27:30,371:INFO:Uploading results into container
2022-09-28 11:27:30,371:INFO:Uploading model into container now
2022-09-28 11:27:30,371:INFO:master_model_container: 14
2022-09-28 11:27:30,371:INFO:display_container: 2
2022-09-28 11:27:30,372:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:27:30,372:INFO:create_model() successfully completed......................................
2022-09-28 11:27:30,433:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:30,433:INFO:Creating metrics dataframe
2022-09-28 11:27:30,438:INFO:Initializing AdaBoost Regressor
2022-09-28 11:27:30,438:INFO:Total runtime is 0.08349488178888956 minutes
2022-09-28 11:27:30,439:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:30,439:INFO:Initializing create_model()
2022-09-28 11:27:30,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:30,440:INFO:Checking exceptions
2022-09-28 11:27:30,440:INFO:Importing libraries
2022-09-28 11:27:30,440:INFO:Copying training dataset
2022-09-28 11:27:30,441:INFO:Defining folds
2022-09-28 11:27:30,441:INFO:Declaring metric variables
2022-09-28 11:27:30,443:INFO:Importing untrained model
2022-09-28 11:27:30,444:INFO:AdaBoost Regressor Imported successfully
2022-09-28 11:27:30,446:INFO:Starting cross validation
2022-09-28 11:27:30,447:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:30,695:INFO:Calculating mean and std
2022-09-28 11:27:30,695:INFO:Creating metrics dataframe
2022-09-28 11:27:30,697:INFO:Uploading results into container
2022-09-28 11:27:30,697:INFO:Uploading model into container now
2022-09-28 11:27:30,697:INFO:master_model_container: 15
2022-09-28 11:27:30,697:INFO:display_container: 2
2022-09-28 11:27:30,697:INFO:AdaBoostRegressor(random_state=123)
2022-09-28 11:27:30,698:INFO:create_model() successfully completed......................................
2022-09-28 11:27:30,757:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:30,757:INFO:Creating metrics dataframe
2022-09-28 11:27:30,763:INFO:Initializing Gradient Boosting Regressor
2022-09-28 11:27:30,763:INFO:Total runtime is 0.08891356388727822 minutes
2022-09-28 11:27:30,764:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:30,765:INFO:Initializing create_model()
2022-09-28 11:27:30,765:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:30,765:INFO:Checking exceptions
2022-09-28 11:27:30,766:INFO:Importing libraries
2022-09-28 11:27:30,766:INFO:Copying training dataset
2022-09-28 11:27:30,767:INFO:Defining folds
2022-09-28 11:27:30,767:INFO:Declaring metric variables
2022-09-28 11:27:30,768:INFO:Importing untrained model
2022-09-28 11:27:30,769:INFO:Gradient Boosting Regressor Imported successfully
2022-09-28 11:27:30,772:INFO:Starting cross validation
2022-09-28 11:27:30,773:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:31,348:INFO:Calculating mean and std
2022-09-28 11:27:31,349:INFO:Creating metrics dataframe
2022-09-28 11:27:31,350:INFO:Uploading results into container
2022-09-28 11:27:31,350:INFO:Uploading model into container now
2022-09-28 11:27:31,350:INFO:master_model_container: 16
2022-09-28 11:27:31,350:INFO:display_container: 2
2022-09-28 11:27:31,351:INFO:GradientBoostingRegressor(random_state=123)
2022-09-28 11:27:31,351:INFO:create_model() successfully completed......................................
2022-09-28 11:27:31,411:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:31,411:INFO:Creating metrics dataframe
2022-09-28 11:27:31,416:INFO:Initializing Extreme Gradient Boosting
2022-09-28 11:27:31,416:INFO:Total runtime is 0.09980219999949136 minutes
2022-09-28 11:27:31,418:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:31,418:INFO:Initializing create_model()
2022-09-28 11:27:31,418:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:31,418:INFO:Checking exceptions
2022-09-28 11:27:31,419:INFO:Importing libraries
2022-09-28 11:27:31,419:INFO:Copying training dataset
2022-09-28 11:27:31,420:INFO:Defining folds
2022-09-28 11:27:31,420:INFO:Declaring metric variables
2022-09-28 11:27:31,421:INFO:Importing untrained model
2022-09-28 11:27:31,423:INFO:Extreme Gradient Boosting Imported successfully
2022-09-28 11:27:31,425:INFO:Starting cross validation
2022-09-28 11:27:31,425:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:31,874:INFO:Calculating mean and std
2022-09-28 11:27:31,875:INFO:Creating metrics dataframe
2022-09-28 11:27:31,876:INFO:Uploading results into container
2022-09-28 11:27:31,876:INFO:Uploading model into container now
2022-09-28 11:27:31,876:INFO:master_model_container: 17
2022-09-28 11:27:31,876:INFO:display_container: 2
2022-09-28 11:27:31,877:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=123,
             reg_alpha=None, reg_lambda=None, ...)
2022-09-28 11:27:31,877:INFO:create_model() successfully completed......................................
2022-09-28 11:27:31,937:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:31,937:INFO:Creating metrics dataframe
2022-09-28 11:27:31,943:INFO:Initializing Light Gradient Boosting Machine
2022-09-28 11:27:31,943:INFO:Total runtime is 0.10857688188552855 minutes
2022-09-28 11:27:31,944:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:31,944:INFO:Initializing create_model()
2022-09-28 11:27:31,944:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:31,945:INFO:Checking exceptions
2022-09-28 11:27:31,946:INFO:Importing libraries
2022-09-28 11:27:31,946:INFO:Copying training dataset
2022-09-28 11:27:31,947:INFO:Defining folds
2022-09-28 11:27:31,947:INFO:Declaring metric variables
2022-09-28 11:27:31,948:INFO:Importing untrained model
2022-09-28 11:27:31,950:INFO:Light Gradient Boosting Machine Imported successfully
2022-09-28 11:27:31,952:INFO:Starting cross validation
2022-09-28 11:27:31,953:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:32,087:INFO:Calculating mean and std
2022-09-28 11:27:32,093:INFO:Creating metrics dataframe
2022-09-28 11:27:32,094:INFO:Uploading results into container
2022-09-28 11:27:32,094:INFO:Uploading model into container now
2022-09-28 11:27:32,094:INFO:master_model_container: 18
2022-09-28 11:27:32,094:INFO:display_container: 2
2022-09-28 11:27:32,095:INFO:LGBMRegressor(random_state=123)
2022-09-28 11:27:32,095:INFO:create_model() successfully completed......................................
2022-09-28 11:27:32,155:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:32,155:INFO:Creating metrics dataframe
2022-09-28 11:27:32,161:INFO:Initializing Dummy Regressor
2022-09-28 11:27:32,161:INFO:Total runtime is 0.11221293210983276 minutes
2022-09-28 11:27:32,162:INFO:SubProcess create_model() called ==================================
2022-09-28 11:27:32,162:INFO:Initializing create_model()
2022-09-28 11:27:32,162:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea5a50>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:32,162:INFO:Checking exceptions
2022-09-28 11:27:32,163:INFO:Importing libraries
2022-09-28 11:27:32,163:INFO:Copying training dataset
2022-09-28 11:27:32,165:INFO:Defining folds
2022-09-28 11:27:32,165:INFO:Declaring metric variables
2022-09-28 11:27:32,166:INFO:Importing untrained model
2022-09-28 11:27:32,167:INFO:Dummy Regressor Imported successfully
2022-09-28 11:27:32,169:INFO:Starting cross validation
2022-09-28 11:27:32,170:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:27:32,214:INFO:Calculating mean and std
2022-09-28 11:27:32,215:INFO:Creating metrics dataframe
2022-09-28 11:27:32,216:INFO:Uploading results into container
2022-09-28 11:27:32,216:INFO:Uploading model into container now
2022-09-28 11:27:32,216:INFO:master_model_container: 19
2022-09-28 11:27:32,216:INFO:display_container: 2
2022-09-28 11:27:32,217:INFO:DummyRegressor()
2022-09-28 11:27:32,217:INFO:create_model() successfully completed......................................
2022-09-28 11:27:32,276:INFO:SubProcess create_model() end ==================================
2022-09-28 11:27:32,276:INFO:Creating metrics dataframe
2022-09-28 11:27:32,286:INFO:Initializing create_model()
2022-09-28 11:27:32,286:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x297f4de10>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:27:32,286:INFO:Checking exceptions
2022-09-28 11:27:32,288:INFO:Importing libraries
2022-09-28 11:27:32,288:INFO:Copying training dataset
2022-09-28 11:27:32,289:INFO:Defining folds
2022-09-28 11:27:32,289:INFO:Declaring metric variables
2022-09-28 11:27:32,289:INFO:Importing untrained model
2022-09-28 11:27:32,289:INFO:Declaring custom model
2022-09-28 11:27:32,290:INFO:Extra Trees Regressor Imported successfully
2022-09-28 11:27:32,290:INFO:Cross validation set to False
2022-09-28 11:27:32,290:INFO:Fitting Model
2022-09-28 11:27:32,397:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:27:32,397:INFO:create_model() successfully completed......................................
2022-09-28 11:27:32,470:INFO:master_model_container: 19
2022-09-28 11:27:32,470:INFO:display_container: 2
2022-09-28 11:27:32,470:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:27:32,471:INFO:compare_models() successfully completed......................................
2022-09-28 11:30:51,373:INFO:PyCaret RegressionExperiment
2022-09-28 11:30:51,373:INFO:Logging name: reg-default-name
2022-09-28 11:30:51,373:INFO:ML Usecase: MLUsecase.REGRESSION
2022-09-28 11:30:51,373:INFO:version 3.0.0.rc4
2022-09-28 11:30:51,374:INFO:Initializing setup()
2022-09-28 11:30:51,374:INFO:self.USI: 638a
2022-09-28 11:30:51,374:INFO:self.variable_keys: {'gpu_param', 'n_jobs_param', 'target_param', 'fold_generator', 'variable_keys', '_all_metrics', 'data', 'exp_id', 'USI', 'y', 'master_model_container', 'seed', 'fold_shuffle_param', 'transform_target_method_param', 'y_train', 'logging_param', '_available_plots', 'X_test', '_ml_usecase', 'y_test', 'pipeline', 'X_train', '_all_models_internal', 'exp_name_log', 'X', 'transform_target_param', 'memory', 'log_plots_param', 'idx', 'fold_groups_param', '_gpu_n_jobs_param', 'display_container', '_all_models', 'html_param'}
2022-09-28 11:30:51,374:INFO:Checking environment
2022-09-28 11:30:51,374:INFO:python_version: 3.10.6
2022-09-28 11:30:51,374:INFO:python_build: ('main', 'Aug 11 2022 13:36:31')
2022-09-28 11:30:51,374:INFO:machine: arm64
2022-09-28 11:30:51,374:INFO:platform: macOS-12.5.1-arm64-arm-64bit
2022-09-28 11:30:51,374:INFO:Memory: svmem(total=17179869184, available=5633556480, percent=67.2, used=7323156480, free=91717632, active=5557075968, inactive=5539184640, wired=1766080512)
2022-09-28 11:30:51,374:INFO:Physical Core: 10
2022-09-28 11:30:51,374:INFO:Logical Core: 10
2022-09-28 11:30:51,374:INFO:Checking libraries
2022-09-28 11:30:51,374:INFO:System:
2022-09-28 11:30:51,374:INFO:    python: 3.10.6 (main, Aug 11 2022, 13:36:31) [Clang 13.1.6 (clang-1316.0.21.2.5)]
2022-09-28 11:30:51,375:INFO:executable: /Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/bin/python
2022-09-28 11:30:51,375:INFO:   machine: macOS-12.5.1-arm64-arm-64bit
2022-09-28 11:30:51,375:INFO:PyCaret required dependencies:
2022-09-28 11:30:51,375:INFO:                 pip: 22.2.2
2022-09-28 11:30:51,375:INFO:          setuptools: 65.4.0
2022-09-28 11:30:51,375:INFO:             pycaret: 3.0.0rc4
2022-09-28 11:30:51,375:INFO:             IPython: 8.5.0
2022-09-28 11:30:51,375:INFO:          ipywidgets: 8.0.2
2022-09-28 11:30:51,375:INFO:                tqdm: 4.64.1
2022-09-28 11:30:51,375:INFO:               numpy: 1.22.4
2022-09-28 11:30:51,375:INFO:              pandas: 1.4.4
2022-09-28 11:30:51,375:INFO:              jinja2: 3.1.2
2022-09-28 11:30:51,375:INFO:               scipy: 1.8.1
2022-09-28 11:30:51,375:INFO:              joblib: 1.2.0
2022-09-28 11:30:51,375:INFO:             sklearn: 1.1.2
2022-09-28 11:30:51,376:INFO:                pyod: 1.0.5
2022-09-28 11:30:51,376:INFO:            imblearn: 0.9.1
2022-09-28 11:30:51,376:INFO:   category_encoders: 2.5.0
2022-09-28 11:30:51,376:INFO:            lightgbm: 3.3.2
2022-09-28 11:30:51,376:INFO:               numba: 0.55.2
2022-09-28 11:30:51,376:INFO:            requests: 2.28.1
2022-09-28 11:30:51,376:INFO:          matplotlib: 3.6.0
2022-09-28 11:30:51,376:INFO:          scikitplot: 0.3.7
2022-09-28 11:30:51,376:INFO:         yellowbrick: 1.5
2022-09-28 11:30:51,376:INFO:              plotly: 5.10.0
2022-09-28 11:30:51,376:INFO:             kaleido: 0.2.1
2022-09-28 11:30:51,376:INFO:         statsmodels: 0.13.2
2022-09-28 11:30:51,376:INFO:              sktime: 0.13.4
2022-09-28 11:30:51,376:INFO:               tbats: 1.1.0
2022-09-28 11:30:51,376:INFO:            pmdarima: 1.8.5
2022-09-28 11:30:51,376:INFO:              psutil: 5.9.2
2022-09-28 11:30:51,376:INFO:PyCaret optional dependencies:
2022-09-28 11:30:51,377:INFO:                shap: Not installed
2022-09-28 11:30:51,377:INFO:           interpret: Not installed
2022-09-28 11:30:51,377:INFO:                umap: Not installed
2022-09-28 11:30:51,377:INFO:    pandas_profiling: Not installed
2022-09-28 11:30:51,377:INFO:  explainerdashboard: Not installed
2022-09-28 11:30:51,377:INFO:             autoviz: Not installed
2022-09-28 11:30:51,377:INFO:           fairlearn: Not installed
2022-09-28 11:30:51,377:INFO:             xgboost: 1.6.2
2022-09-28 11:30:51,377:INFO:            catboost: Not installed
2022-09-28 11:30:51,377:INFO:              kmodes: Not installed
2022-09-28 11:30:51,377:INFO:             mlxtend: Not installed
2022-09-28 11:30:51,377:INFO:       statsforecast: Not installed
2022-09-28 11:30:51,377:INFO:        tune_sklearn: Not installed
2022-09-28 11:30:51,377:INFO:                 ray: Not installed
2022-09-28 11:30:51,377:INFO:            hyperopt: Not installed
2022-09-28 11:30:51,377:INFO:              optuna: Not installed
2022-09-28 11:30:51,377:INFO:               skopt: Not installed
2022-09-28 11:30:51,377:INFO:              mlflow: Not installed
2022-09-28 11:30:51,378:INFO:              gradio: Not installed
2022-09-28 11:30:51,378:INFO:             fastapi: Not installed
2022-09-28 11:30:51,378:INFO:             uvicorn: Not installed
2022-09-28 11:30:51,378:INFO:              m2cgen: Not installed
2022-09-28 11:30:51,378:INFO:           evidently: Not installed
2022-09-28 11:30:51,378:INFO:                nltk: Not installed
2022-09-28 11:30:51,378:INFO:            pyLDAvis: Not installed
2022-09-28 11:30:51,378:INFO:              gensim: Not installed
2022-09-28 11:30:51,378:INFO:               spacy: Not installed
2022-09-28 11:30:51,378:INFO:           wordcloud: Not installed
2022-09-28 11:30:51,378:INFO:            textblob: Not installed
2022-09-28 11:30:51,378:INFO:               fugue: Not installed
2022-09-28 11:30:51,378:INFO:           streamlit: Not installed
2022-09-28 11:30:51,378:INFO:             prophet: Not installed
2022-09-28 11:30:51,378:INFO:None
2022-09-28 11:30:51,378:INFO:Set up data.
2022-09-28 11:30:51,387:INFO:Set up train/test split.
2022-09-28 11:30:51,391:INFO:Set up index.
2022-09-28 11:30:51,391:INFO:Set up folding strategy.
2022-09-28 11:30:51,391:INFO:Assigning column types.
2022-09-28 11:30:51,393:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-09-28 11:30:51,393:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,396:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,399:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,437:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,460:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,460:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:30:51,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:30:51,461:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,464:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,466:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,491:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,510:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,510:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:30:51,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:30:51,512:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-09-28 11:30:51,514:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,516:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,540:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,559:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,559:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:30:51,560:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:30:51,562:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,564:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,587:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,606:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,607:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:30:51,608:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:30:51,608:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-09-28 11:30:51,612:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,636:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,654:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,654:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:30:51,655:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:30:51,659:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,683:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,701:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,702:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:30:51,703:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:30:51,703:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-09-28 11:30:51,730:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,748:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,748:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:30:51,749:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:30:51,777:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,795:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,795:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:30:51,796:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:30:51,797:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-09-28 11:30:51,824:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,843:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:30:51,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:30:51,871:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:30:51,890:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:30:51,891:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:30:51,891:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-09-28 11:30:51,937:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:30:51,938:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:30:51,986:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:30:51,987:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:30:51,987:INFO:Preparing preprocessing pipeline...
2022-09-28 11:30:51,988:INFO:Set up simple imputation.
2022-09-28 11:30:51,988:INFO:Set up variance threshold.
2022-09-28 11:30:52,009:INFO:Finished creating preprocessing pipeline.
2022-09-28 11:30:52,011:INFO:Pipeline: Pipeline(memory=Memory(location=/var/folders/67/hmlyjz1x4x7b_71cqk6bxrg00000gq/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demand_point_index',
                                             'x_coordinate', 'y_coordinate',
                                             '2010', '2011', '2012', '2013',
                                             '2014', '2015', '2016', '2018'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-09-28 11:30:52,011:INFO:Creating final display dataframe.
2022-09-28 11:30:52,093:INFO:Setup display_container:                Description             Value
0               Session id               123
1                   Target              2017
2              Target type        Regression
3               Data shape        (4096, 12)
4         Train data shape        (2867, 12)
5          Test data shape        (1229, 12)
6         Numeric features                11
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              638a
2022-09-28 11:30:52,144:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:30:52,145:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:30:52,192:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:30:52,193:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:30:52,195:INFO:setup() successfully completed in 0.83s...............
2022-09-28 11:31:39,901:INFO:PyCaret RegressionExperiment
2022-09-28 11:31:39,901:INFO:Logging name: reg-default-name
2022-09-28 11:31:39,901:INFO:ML Usecase: MLUsecase.REGRESSION
2022-09-28 11:31:39,901:INFO:version 3.0.0.rc4
2022-09-28 11:31:39,902:INFO:Initializing setup()
2022-09-28 11:31:39,902:INFO:self.USI: 25ce
2022-09-28 11:31:39,902:INFO:self.variable_keys: {'gpu_param', 'n_jobs_param', 'target_param', 'fold_generator', 'variable_keys', '_all_metrics', 'data', 'exp_id', 'USI', 'y', 'master_model_container', 'seed', 'fold_shuffle_param', 'transform_target_method_param', 'y_train', 'logging_param', '_available_plots', 'X_test', '_ml_usecase', 'y_test', 'pipeline', 'X_train', '_all_models_internal', 'exp_name_log', 'X', 'transform_target_param', 'memory', 'log_plots_param', 'idx', 'fold_groups_param', '_gpu_n_jobs_param', 'display_container', '_all_models', 'html_param'}
2022-09-28 11:31:39,902:INFO:Checking environment
2022-09-28 11:31:39,902:INFO:python_version: 3.10.6
2022-09-28 11:31:39,902:INFO:python_build: ('main', 'Aug 11 2022 13:36:31')
2022-09-28 11:31:39,902:INFO:machine: arm64
2022-09-28 11:31:39,902:INFO:platform: macOS-12.5.1-arm64-arm-64bit
2022-09-28 11:31:39,902:INFO:Memory: svmem(total=17179869184, available=5567627264, percent=67.6, used=7211106304, free=130367488, active=5451546624, inactive=5433032704, wired=1759559680)
2022-09-28 11:31:39,902:INFO:Physical Core: 10
2022-09-28 11:31:39,902:INFO:Logical Core: 10
2022-09-28 11:31:39,903:INFO:Checking libraries
2022-09-28 11:31:39,903:INFO:System:
2022-09-28 11:31:39,903:INFO:    python: 3.10.6 (main, Aug 11 2022, 13:36:31) [Clang 13.1.6 (clang-1316.0.21.2.5)]
2022-09-28 11:31:39,903:INFO:executable: /Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/bin/python
2022-09-28 11:31:39,903:INFO:   machine: macOS-12.5.1-arm64-arm-64bit
2022-09-28 11:31:39,903:INFO:PyCaret required dependencies:
2022-09-28 11:31:39,903:INFO:                 pip: 22.2.2
2022-09-28 11:31:39,903:INFO:          setuptools: 65.4.0
2022-09-28 11:31:39,903:INFO:             pycaret: 3.0.0rc4
2022-09-28 11:31:39,903:INFO:             IPython: 8.5.0
2022-09-28 11:31:39,904:INFO:          ipywidgets: 8.0.2
2022-09-28 11:31:39,904:INFO:                tqdm: 4.64.1
2022-09-28 11:31:39,904:INFO:               numpy: 1.22.4
2022-09-28 11:31:39,904:INFO:              pandas: 1.4.4
2022-09-28 11:31:39,904:INFO:              jinja2: 3.1.2
2022-09-28 11:31:39,904:INFO:               scipy: 1.8.1
2022-09-28 11:31:39,904:INFO:              joblib: 1.2.0
2022-09-28 11:31:39,904:INFO:             sklearn: 1.1.2
2022-09-28 11:31:39,904:INFO:                pyod: 1.0.5
2022-09-28 11:31:39,904:INFO:            imblearn: 0.9.1
2022-09-28 11:31:39,905:INFO:   category_encoders: 2.5.0
2022-09-28 11:31:39,905:INFO:            lightgbm: 3.3.2
2022-09-28 11:31:39,905:INFO:               numba: 0.55.2
2022-09-28 11:31:39,905:INFO:            requests: 2.28.1
2022-09-28 11:31:39,905:INFO:          matplotlib: 3.6.0
2022-09-28 11:31:39,905:INFO:          scikitplot: 0.3.7
2022-09-28 11:31:39,905:INFO:         yellowbrick: 1.5
2022-09-28 11:31:39,905:INFO:              plotly: 5.10.0
2022-09-28 11:31:39,905:INFO:             kaleido: 0.2.1
2022-09-28 11:31:39,905:INFO:         statsmodels: 0.13.2
2022-09-28 11:31:39,905:INFO:              sktime: 0.13.4
2022-09-28 11:31:39,905:INFO:               tbats: 1.1.0
2022-09-28 11:31:39,905:INFO:            pmdarima: 1.8.5
2022-09-28 11:31:39,905:INFO:              psutil: 5.9.2
2022-09-28 11:31:39,905:INFO:PyCaret optional dependencies:
2022-09-28 11:31:39,906:INFO:                shap: Not installed
2022-09-28 11:31:39,906:INFO:           interpret: Not installed
2022-09-28 11:31:39,906:INFO:                umap: Not installed
2022-09-28 11:31:39,906:INFO:    pandas_profiling: Not installed
2022-09-28 11:31:39,906:INFO:  explainerdashboard: Not installed
2022-09-28 11:31:39,906:INFO:             autoviz: Not installed
2022-09-28 11:31:39,906:INFO:           fairlearn: Not installed
2022-09-28 11:31:39,906:INFO:             xgboost: 1.6.2
2022-09-28 11:31:39,906:INFO:            catboost: Not installed
2022-09-28 11:31:39,906:INFO:              kmodes: Not installed
2022-09-28 11:31:39,906:INFO:             mlxtend: Not installed
2022-09-28 11:31:39,906:INFO:       statsforecast: Not installed
2022-09-28 11:31:39,906:INFO:        tune_sklearn: Not installed
2022-09-28 11:31:39,907:INFO:                 ray: Not installed
2022-09-28 11:31:39,907:INFO:            hyperopt: Not installed
2022-09-28 11:31:39,907:INFO:              optuna: Not installed
2022-09-28 11:31:39,907:INFO:               skopt: Not installed
2022-09-28 11:31:39,907:INFO:              mlflow: Not installed
2022-09-28 11:31:39,907:INFO:              gradio: Not installed
2022-09-28 11:31:39,907:INFO:             fastapi: Not installed
2022-09-28 11:31:39,907:INFO:             uvicorn: Not installed
2022-09-28 11:31:39,907:INFO:              m2cgen: Not installed
2022-09-28 11:31:39,907:INFO:           evidently: Not installed
2022-09-28 11:31:39,907:INFO:                nltk: Not installed
2022-09-28 11:31:39,907:INFO:            pyLDAvis: Not installed
2022-09-28 11:31:39,907:INFO:              gensim: Not installed
2022-09-28 11:31:39,907:INFO:               spacy: Not installed
2022-09-28 11:31:39,907:INFO:           wordcloud: Not installed
2022-09-28 11:31:39,907:INFO:            textblob: Not installed
2022-09-28 11:31:39,907:INFO:               fugue: Not installed
2022-09-28 11:31:39,907:INFO:           streamlit: Not installed
2022-09-28 11:31:39,908:INFO:             prophet: Not installed
2022-09-28 11:31:39,908:INFO:None
2022-09-28 11:31:39,908:INFO:Set up data.
2022-09-28 11:31:39,915:INFO:Set up train/test split.
2022-09-28 11:31:39,917:INFO:Set up index.
2022-09-28 11:31:39,917:INFO:Set up folding strategy.
2022-09-28 11:31:39,918:INFO:Assigning column types.
2022-09-28 11:31:39,919:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-09-28 11:31:39,919:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-28 11:31:39,923:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:31:39,925:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:31:39,963:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:31:39,985:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:31:39,985:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:31:39,987:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:31:39,987:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-28 11:31:39,989:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:31:39,991:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,015:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,033:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,033:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:31:40,034:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:31:40,035:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-09-28 11:31:40,036:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,038:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,062:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,080:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,081:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:31:40,082:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:31:40,084:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,086:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,109:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,128:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,128:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:31:40,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:31:40,129:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-09-28 11:31:40,133:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,157:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,175:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,175:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:31:40,176:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:31:40,180:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,204:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,222:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,223:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:31:40,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:31:40,224:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-09-28 11:31:40,251:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,269:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,270:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:31:40,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:31:40,298:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,316:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,316:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:31:40,317:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:31:40,317:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-09-28 11:31:40,344:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,362:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:31:40,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:31:40,393:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:31:40,412:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:31:40,413:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:31:40,413:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-09-28 11:31:40,458:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:31:40,460:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:31:40,507:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:31:40,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:31:40,508:INFO:Preparing preprocessing pipeline...
2022-09-28 11:31:40,509:INFO:Set up simple imputation.
2022-09-28 11:31:40,509:INFO:Set up variance threshold.
2022-09-28 11:31:40,530:INFO:Finished creating preprocessing pipeline.
2022-09-28 11:31:40,532:INFO:Pipeline: Pipeline(memory=Memory(location=/var/folders/67/hmlyjz1x4x7b_71cqk6bxrg00000gq/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demand_point_index',
                                             'x_coordinate', 'y_coordinate',
                                             '2010', '2011', '2012', '2013',
                                             '2014', '2015', '2016'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-09-28 11:31:40,532:INFO:Creating final display dataframe.
2022-09-28 11:31:40,613:INFO:Setup display_container:                Description             Value
0               Session id               123
1                   Target              2017
2              Target type        Regression
3               Data shape        (4096, 11)
4         Train data shape        (2867, 11)
5          Test data shape        (1229, 11)
6         Numeric features                10
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              25ce
2022-09-28 11:31:40,663:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:31:40,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:31:40,711:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:31:40,712:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:31:40,714:INFO:setup() successfully completed in 0.82s...............
2022-09-28 11:31:49,560:INFO:Initializing compare_models()
2022-09-28 11:31:49,560:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-09-28 11:31:49,560:INFO:Checking exceptions
2022-09-28 11:31:49,567:INFO:Preparing display monitor
2022-09-28 11:31:49,596:INFO:Initializing Linear Regression
2022-09-28 11:31:49,596:INFO:Total runtime is 2.666314442952474e-06 minutes
2022-09-28 11:31:49,597:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:49,598:INFO:Initializing create_model()
2022-09-28 11:31:49,598:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:49,598:INFO:Checking exceptions
2022-09-28 11:31:49,599:INFO:Importing libraries
2022-09-28 11:31:49,599:INFO:Copying training dataset
2022-09-28 11:31:49,601:INFO:Defining folds
2022-09-28 11:31:49,601:INFO:Declaring metric variables
2022-09-28 11:31:49,603:INFO:Importing untrained model
2022-09-28 11:31:49,605:INFO:Linear Regression Imported successfully
2022-09-28 11:31:49,608:INFO:Starting cross validation
2022-09-28 11:31:49,610:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:49,771:INFO:Calculating mean and std
2022-09-28 11:31:49,771:INFO:Creating metrics dataframe
2022-09-28 11:31:49,772:INFO:Uploading results into container
2022-09-28 11:31:49,772:INFO:Uploading model into container now
2022-09-28 11:31:49,772:INFO:master_model_container: 1
2022-09-28 11:31:49,772:INFO:display_container: 2
2022-09-28 11:31:49,772:INFO:LinearRegression(n_jobs=-1)
2022-09-28 11:31:49,773:INFO:create_model() successfully completed......................................
2022-09-28 11:31:49,862:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:49,862:INFO:Creating metrics dataframe
2022-09-28 11:31:49,865:INFO:Initializing Lasso Regression
2022-09-28 11:31:49,866:INFO:Total runtime is 0.0044955174128214525 minutes
2022-09-28 11:31:49,867:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:49,867:INFO:Initializing create_model()
2022-09-28 11:31:49,867:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:49,867:INFO:Checking exceptions
2022-09-28 11:31:49,868:INFO:Importing libraries
2022-09-28 11:31:49,868:INFO:Copying training dataset
2022-09-28 11:31:49,869:INFO:Defining folds
2022-09-28 11:31:49,869:INFO:Declaring metric variables
2022-09-28 11:31:49,870:INFO:Importing untrained model
2022-09-28 11:31:49,871:INFO:Lasso Regression Imported successfully
2022-09-28 11:31:49,873:INFO:Starting cross validation
2022-09-28 11:31:49,874:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:49,929:INFO:Calculating mean and std
2022-09-28 11:31:49,929:INFO:Creating metrics dataframe
2022-09-28 11:31:49,930:INFO:Uploading results into container
2022-09-28 11:31:49,930:INFO:Uploading model into container now
2022-09-28 11:31:49,930:INFO:master_model_container: 2
2022-09-28 11:31:49,931:INFO:display_container: 2
2022-09-28 11:31:49,931:INFO:Lasso(random_state=123)
2022-09-28 11:31:49,931:INFO:create_model() successfully completed......................................
2022-09-28 11:31:50,015:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:50,015:INFO:Creating metrics dataframe
2022-09-28 11:31:50,018:INFO:Initializing Ridge Regression
2022-09-28 11:31:50,018:INFO:Total runtime is 0.0070391337076822925 minutes
2022-09-28 11:31:50,019:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:50,020:INFO:Initializing create_model()
2022-09-28 11:31:50,020:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:50,020:INFO:Checking exceptions
2022-09-28 11:31:50,021:INFO:Importing libraries
2022-09-28 11:31:50,021:INFO:Copying training dataset
2022-09-28 11:31:50,022:INFO:Defining folds
2022-09-28 11:31:50,022:INFO:Declaring metric variables
2022-09-28 11:31:50,023:INFO:Importing untrained model
2022-09-28 11:31:50,024:INFO:Ridge Regression Imported successfully
2022-09-28 11:31:50,027:INFO:Starting cross validation
2022-09-28 11:31:50,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:50,072:INFO:Calculating mean and std
2022-09-28 11:31:50,072:INFO:Creating metrics dataframe
2022-09-28 11:31:50,073:INFO:Uploading results into container
2022-09-28 11:31:50,074:INFO:Uploading model into container now
2022-09-28 11:31:50,074:INFO:master_model_container: 3
2022-09-28 11:31:50,074:INFO:display_container: 2
2022-09-28 11:31:50,074:INFO:Ridge(random_state=123)
2022-09-28 11:31:50,074:INFO:create_model() successfully completed......................................
2022-09-28 11:31:50,161:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:50,161:INFO:Creating metrics dataframe
2022-09-28 11:31:50,164:INFO:Initializing Elastic Net
2022-09-28 11:31:50,164:INFO:Total runtime is 0.00947410265604655 minutes
2022-09-28 11:31:50,166:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:50,166:INFO:Initializing create_model()
2022-09-28 11:31:50,166:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:50,166:INFO:Checking exceptions
2022-09-28 11:31:50,167:INFO:Importing libraries
2022-09-28 11:31:50,167:INFO:Copying training dataset
2022-09-28 11:31:50,168:INFO:Defining folds
2022-09-28 11:31:50,168:INFO:Declaring metric variables
2022-09-28 11:31:50,169:INFO:Importing untrained model
2022-09-28 11:31:50,170:INFO:Elastic Net Imported successfully
2022-09-28 11:31:50,172:INFO:Starting cross validation
2022-09-28 11:31:50,173:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:50,233:INFO:Calculating mean and std
2022-09-28 11:31:50,233:INFO:Creating metrics dataframe
2022-09-28 11:31:50,234:INFO:Uploading results into container
2022-09-28 11:31:50,234:INFO:Uploading model into container now
2022-09-28 11:31:50,235:INFO:master_model_container: 4
2022-09-28 11:31:50,235:INFO:display_container: 2
2022-09-28 11:31:50,235:INFO:ElasticNet(random_state=123)
2022-09-28 11:31:50,235:INFO:create_model() successfully completed......................................
2022-09-28 11:31:50,319:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:50,320:INFO:Creating metrics dataframe
2022-09-28 11:31:50,324:INFO:Initializing Least Angle Regression
2022-09-28 11:31:50,324:INFO:Total runtime is 0.012130220731099447 minutes
2022-09-28 11:31:50,325:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:50,325:INFO:Initializing create_model()
2022-09-28 11:31:50,325:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:50,325:INFO:Checking exceptions
2022-09-28 11:31:50,326:INFO:Importing libraries
2022-09-28 11:31:50,326:INFO:Copying training dataset
2022-09-28 11:31:50,327:INFO:Defining folds
2022-09-28 11:31:50,327:INFO:Declaring metric variables
2022-09-28 11:31:50,328:INFO:Importing untrained model
2022-09-28 11:31:50,330:INFO:Least Angle Regression Imported successfully
2022-09-28 11:31:50,333:INFO:Starting cross validation
2022-09-28 11:31:50,334:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:50,348:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,350:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,352:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,355:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,359:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,360:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,363:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,365:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,367:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,369:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,374:INFO:Calculating mean and std
2022-09-28 11:31:50,374:INFO:Creating metrics dataframe
2022-09-28 11:31:50,375:INFO:Uploading results into container
2022-09-28 11:31:50,376:INFO:Uploading model into container now
2022-09-28 11:31:50,376:INFO:master_model_container: 5
2022-09-28 11:31:50,376:INFO:display_container: 2
2022-09-28 11:31:50,376:INFO:Lars(random_state=123)
2022-09-28 11:31:50,376:INFO:create_model() successfully completed......................................
2022-09-28 11:31:50,464:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:50,464:INFO:Creating metrics dataframe
2022-09-28 11:31:50,468:INFO:Initializing Lasso Least Angle Regression
2022-09-28 11:31:50,468:INFO:Total runtime is 0.014541053771972658 minutes
2022-09-28 11:31:50,470:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:50,470:INFO:Initializing create_model()
2022-09-28 11:31:50,470:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:50,470:INFO:Checking exceptions
2022-09-28 11:31:50,471:INFO:Importing libraries
2022-09-28 11:31:50,471:INFO:Copying training dataset
2022-09-28 11:31:50,472:INFO:Defining folds
2022-09-28 11:31:50,472:INFO:Declaring metric variables
2022-09-28 11:31:50,473:INFO:Importing untrained model
2022-09-28 11:31:50,475:INFO:Lasso Least Angle Regression Imported successfully
2022-09-28 11:31:50,478:INFO:Starting cross validation
2022-09-28 11:31:50,478:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:50,492:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:31:50,497:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:31:50,500:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:31:50,503:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:31:50,505:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:31:50,508:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:31:50,510:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:31:50,512:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:31:50,515:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:31:50,518:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:31:50,522:INFO:Calculating mean and std
2022-09-28 11:31:50,522:INFO:Creating metrics dataframe
2022-09-28 11:31:50,524:INFO:Uploading results into container
2022-09-28 11:31:50,524:INFO:Uploading model into container now
2022-09-28 11:31:50,524:INFO:master_model_container: 6
2022-09-28 11:31:50,524:INFO:display_container: 2
2022-09-28 11:31:50,524:INFO:LassoLars(random_state=123)
2022-09-28 11:31:50,524:INFO:create_model() successfully completed......................................
2022-09-28 11:31:50,612:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:50,613:INFO:Creating metrics dataframe
2022-09-28 11:31:50,616:INFO:Initializing Orthogonal Matching Pursuit
2022-09-28 11:31:50,617:INFO:Total runtime is 0.01701215108235677 minutes
2022-09-28 11:31:50,618:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:50,618:INFO:Initializing create_model()
2022-09-28 11:31:50,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:50,618:INFO:Checking exceptions
2022-09-28 11:31:50,619:INFO:Importing libraries
2022-09-28 11:31:50,619:INFO:Copying training dataset
2022-09-28 11:31:50,620:INFO:Defining folds
2022-09-28 11:31:50,621:INFO:Declaring metric variables
2022-09-28 11:31:50,622:INFO:Importing untrained model
2022-09-28 11:31:50,623:INFO:Orthogonal Matching Pursuit Imported successfully
2022-09-28 11:31:50,625:INFO:Starting cross validation
2022-09-28 11:31:50,626:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:50,639:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,645:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,647:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,650:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,653:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,655:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,657:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,659:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,662:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,664:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:31:50,670:INFO:Calculating mean and std
2022-09-28 11:31:50,670:INFO:Creating metrics dataframe
2022-09-28 11:31:50,672:INFO:Uploading results into container
2022-09-28 11:31:50,678:INFO:Uploading model into container now
2022-09-28 11:31:50,678:INFO:master_model_container: 7
2022-09-28 11:31:50,678:INFO:display_container: 2
2022-09-28 11:31:50,678:INFO:OrthogonalMatchingPursuit()
2022-09-28 11:31:50,678:INFO:create_model() successfully completed......................................
2022-09-28 11:31:50,762:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:50,763:INFO:Creating metrics dataframe
2022-09-28 11:31:50,767:INFO:Initializing Bayesian Ridge
2022-09-28 11:31:50,767:INFO:Total runtime is 0.01951868534088135 minutes
2022-09-28 11:31:50,768:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:50,768:INFO:Initializing create_model()
2022-09-28 11:31:50,769:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:50,769:INFO:Checking exceptions
2022-09-28 11:31:50,769:INFO:Importing libraries
2022-09-28 11:31:50,769:INFO:Copying training dataset
2022-09-28 11:31:50,771:INFO:Defining folds
2022-09-28 11:31:50,771:INFO:Declaring metric variables
2022-09-28 11:31:50,772:INFO:Importing untrained model
2022-09-28 11:31:50,774:INFO:Bayesian Ridge Imported successfully
2022-09-28 11:31:50,776:INFO:Starting cross validation
2022-09-28 11:31:50,777:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:50,816:INFO:Calculating mean and std
2022-09-28 11:31:50,817:INFO:Creating metrics dataframe
2022-09-28 11:31:50,818:INFO:Uploading results into container
2022-09-28 11:31:50,818:INFO:Uploading model into container now
2022-09-28 11:31:50,818:INFO:master_model_container: 8
2022-09-28 11:31:50,818:INFO:display_container: 2
2022-09-28 11:31:50,818:INFO:BayesianRidge()
2022-09-28 11:31:50,818:INFO:create_model() successfully completed......................................
2022-09-28 11:31:50,905:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:50,905:INFO:Creating metrics dataframe
2022-09-28 11:31:50,909:INFO:Initializing Passive Aggressive Regressor
2022-09-28 11:31:50,909:INFO:Total runtime is 0.02189078728357951 minutes
2022-09-28 11:31:50,911:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:50,911:INFO:Initializing create_model()
2022-09-28 11:31:50,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:50,911:INFO:Checking exceptions
2022-09-28 11:31:50,912:INFO:Importing libraries
2022-09-28 11:31:50,912:INFO:Copying training dataset
2022-09-28 11:31:50,913:INFO:Defining folds
2022-09-28 11:31:50,913:INFO:Declaring metric variables
2022-09-28 11:31:50,915:INFO:Importing untrained model
2022-09-28 11:31:50,916:INFO:Passive Aggressive Regressor Imported successfully
2022-09-28 11:31:50,919:INFO:Starting cross validation
2022-09-28 11:31:50,919:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:50,969:INFO:Calculating mean and std
2022-09-28 11:31:50,969:INFO:Creating metrics dataframe
2022-09-28 11:31:50,970:INFO:Uploading results into container
2022-09-28 11:31:50,970:INFO:Uploading model into container now
2022-09-28 11:31:50,970:INFO:master_model_container: 9
2022-09-28 11:31:50,970:INFO:display_container: 2
2022-09-28 11:31:50,971:INFO:PassiveAggressiveRegressor(random_state=123)
2022-09-28 11:31:50,971:INFO:create_model() successfully completed......................................
2022-09-28 11:31:51,055:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:51,055:INFO:Creating metrics dataframe
2022-09-28 11:31:51,059:INFO:Initializing Huber Regressor
2022-09-28 11:31:51,059:INFO:Total runtime is 0.02438706954320272 minutes
2022-09-28 11:31:51,060:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:51,060:INFO:Initializing create_model()
2022-09-28 11:31:51,061:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:51,061:INFO:Checking exceptions
2022-09-28 11:31:51,061:INFO:Importing libraries
2022-09-28 11:31:51,061:INFO:Copying training dataset
2022-09-28 11:31:51,063:INFO:Defining folds
2022-09-28 11:31:51,063:INFO:Declaring metric variables
2022-09-28 11:31:51,064:INFO:Importing untrained model
2022-09-28 11:31:51,066:INFO:Huber Regressor Imported successfully
2022-09-28 11:31:51,068:INFO:Starting cross validation
2022-09-28 11:31:51,069:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:51,106:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:31:51,108:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:31:51,112:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:31:51,119:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:31:51,121:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:31:51,131:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:31:51,140:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:31:51,141:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:31:51,143:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:31:51,146:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:31:51,150:INFO:Calculating mean and std
2022-09-28 11:31:51,150:INFO:Creating metrics dataframe
2022-09-28 11:31:51,151:INFO:Uploading results into container
2022-09-28 11:31:51,152:INFO:Uploading model into container now
2022-09-28 11:31:51,152:INFO:master_model_container: 10
2022-09-28 11:31:51,152:INFO:display_container: 2
2022-09-28 11:31:51,152:INFO:HuberRegressor()
2022-09-28 11:31:51,152:INFO:create_model() successfully completed......................................
2022-09-28 11:31:51,239:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:51,239:INFO:Creating metrics dataframe
2022-09-28 11:31:51,244:INFO:Initializing K Neighbors Regressor
2022-09-28 11:31:51,244:INFO:Total runtime is 0.027466801802317302 minutes
2022-09-28 11:31:51,245:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:51,245:INFO:Initializing create_model()
2022-09-28 11:31:51,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:51,245:INFO:Checking exceptions
2022-09-28 11:31:51,246:INFO:Importing libraries
2022-09-28 11:31:51,246:INFO:Copying training dataset
2022-09-28 11:31:51,248:INFO:Defining folds
2022-09-28 11:31:51,248:INFO:Declaring metric variables
2022-09-28 11:31:51,249:INFO:Importing untrained model
2022-09-28 11:31:51,250:INFO:K Neighbors Regressor Imported successfully
2022-09-28 11:31:51,253:INFO:Starting cross validation
2022-09-28 11:31:51,253:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:51,297:INFO:Calculating mean and std
2022-09-28 11:31:51,297:INFO:Creating metrics dataframe
2022-09-28 11:31:51,298:INFO:Uploading results into container
2022-09-28 11:31:51,298:INFO:Uploading model into container now
2022-09-28 11:31:51,299:INFO:master_model_container: 11
2022-09-28 11:31:51,299:INFO:display_container: 2
2022-09-28 11:31:51,299:INFO:KNeighborsRegressor(n_jobs=-1)
2022-09-28 11:31:51,299:INFO:create_model() successfully completed......................................
2022-09-28 11:31:51,383:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:51,383:INFO:Creating metrics dataframe
2022-09-28 11:31:51,388:INFO:Initializing Decision Tree Regressor
2022-09-28 11:31:51,388:INFO:Total runtime is 0.029868868986765544 minutes
2022-09-28 11:31:51,389:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:51,389:INFO:Initializing create_model()
2022-09-28 11:31:51,389:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:51,389:INFO:Checking exceptions
2022-09-28 11:31:51,390:INFO:Importing libraries
2022-09-28 11:31:51,390:INFO:Copying training dataset
2022-09-28 11:31:51,392:INFO:Defining folds
2022-09-28 11:31:51,392:INFO:Declaring metric variables
2022-09-28 11:31:51,393:INFO:Importing untrained model
2022-09-28 11:31:51,395:INFO:Decision Tree Regressor Imported successfully
2022-09-28 11:31:51,397:INFO:Starting cross validation
2022-09-28 11:31:51,398:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:51,462:INFO:Calculating mean and std
2022-09-28 11:31:51,462:INFO:Creating metrics dataframe
2022-09-28 11:31:51,463:INFO:Uploading results into container
2022-09-28 11:31:51,464:INFO:Uploading model into container now
2022-09-28 11:31:51,464:INFO:master_model_container: 12
2022-09-28 11:31:51,464:INFO:display_container: 2
2022-09-28 11:31:51,464:INFO:DecisionTreeRegressor(random_state=123)
2022-09-28 11:31:51,464:INFO:create_model() successfully completed......................................
2022-09-28 11:31:51,553:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:51,553:INFO:Creating metrics dataframe
2022-09-28 11:31:51,558:INFO:Initializing Random Forest Regressor
2022-09-28 11:31:51,558:INFO:Total runtime is 0.03270108699798584 minutes
2022-09-28 11:31:51,559:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:51,559:INFO:Initializing create_model()
2022-09-28 11:31:51,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:51,560:INFO:Checking exceptions
2022-09-28 11:31:51,560:INFO:Importing libraries
2022-09-28 11:31:51,561:INFO:Copying training dataset
2022-09-28 11:31:51,562:INFO:Defining folds
2022-09-28 11:31:51,562:INFO:Declaring metric variables
2022-09-28 11:31:51,563:INFO:Importing untrained model
2022-09-28 11:31:51,565:INFO:Random Forest Regressor Imported successfully
2022-09-28 11:31:51,568:INFO:Starting cross validation
2022-09-28 11:31:51,568:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:52,654:INFO:Calculating mean and std
2022-09-28 11:31:52,655:INFO:Creating metrics dataframe
2022-09-28 11:31:52,656:INFO:Uploading results into container
2022-09-28 11:31:52,657:INFO:Uploading model into container now
2022-09-28 11:31:52,657:INFO:master_model_container: 13
2022-09-28 11:31:52,657:INFO:display_container: 2
2022-09-28 11:31:52,657:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:31:52,657:INFO:create_model() successfully completed......................................
2022-09-28 11:31:52,745:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:52,745:INFO:Creating metrics dataframe
2022-09-28 11:31:52,750:INFO:Initializing Extra Trees Regressor
2022-09-28 11:31:52,750:INFO:Total runtime is 0.05256976683934529 minutes
2022-09-28 11:31:52,751:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:52,751:INFO:Initializing create_model()
2022-09-28 11:31:52,751:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:52,752:INFO:Checking exceptions
2022-09-28 11:31:52,752:INFO:Importing libraries
2022-09-28 11:31:52,752:INFO:Copying training dataset
2022-09-28 11:31:52,753:INFO:Defining folds
2022-09-28 11:31:52,753:INFO:Declaring metric variables
2022-09-28 11:31:52,754:INFO:Importing untrained model
2022-09-28 11:31:52,756:INFO:Extra Trees Regressor Imported successfully
2022-09-28 11:31:52,758:INFO:Starting cross validation
2022-09-28 11:31:52,758:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:53,292:INFO:Calculating mean and std
2022-09-28 11:31:53,293:INFO:Creating metrics dataframe
2022-09-28 11:31:53,294:INFO:Uploading results into container
2022-09-28 11:31:53,294:INFO:Uploading model into container now
2022-09-28 11:31:53,294:INFO:master_model_container: 14
2022-09-28 11:31:53,294:INFO:display_container: 2
2022-09-28 11:31:53,295:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:31:53,295:INFO:create_model() successfully completed......................................
2022-09-28 11:31:53,382:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:53,382:INFO:Creating metrics dataframe
2022-09-28 11:31:53,387:INFO:Initializing AdaBoost Regressor
2022-09-28 11:31:53,387:INFO:Total runtime is 0.06318851709365844 minutes
2022-09-28 11:31:53,388:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:53,389:INFO:Initializing create_model()
2022-09-28 11:31:53,389:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:53,389:INFO:Checking exceptions
2022-09-28 11:31:53,390:INFO:Importing libraries
2022-09-28 11:31:53,390:INFO:Copying training dataset
2022-09-28 11:31:53,391:INFO:Defining folds
2022-09-28 11:31:53,391:INFO:Declaring metric variables
2022-09-28 11:31:53,392:INFO:Importing untrained model
2022-09-28 11:31:53,393:INFO:AdaBoost Regressor Imported successfully
2022-09-28 11:31:53,396:INFO:Starting cross validation
2022-09-28 11:31:53,396:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:53,558:INFO:Calculating mean and std
2022-09-28 11:31:53,559:INFO:Creating metrics dataframe
2022-09-28 11:31:53,560:INFO:Uploading results into container
2022-09-28 11:31:53,561:INFO:Uploading model into container now
2022-09-28 11:31:53,561:INFO:master_model_container: 15
2022-09-28 11:31:53,561:INFO:display_container: 2
2022-09-28 11:31:53,561:INFO:AdaBoostRegressor(random_state=123)
2022-09-28 11:31:53,561:INFO:create_model() successfully completed......................................
2022-09-28 11:31:53,647:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:53,647:INFO:Creating metrics dataframe
2022-09-28 11:31:53,652:INFO:Initializing Gradient Boosting Regressor
2022-09-28 11:31:53,652:INFO:Total runtime is 0.06759958664576211 minutes
2022-09-28 11:31:53,653:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:53,653:INFO:Initializing create_model()
2022-09-28 11:31:53,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:53,653:INFO:Checking exceptions
2022-09-28 11:31:53,654:INFO:Importing libraries
2022-09-28 11:31:53,654:INFO:Copying training dataset
2022-09-28 11:31:53,655:INFO:Defining folds
2022-09-28 11:31:53,655:INFO:Declaring metric variables
2022-09-28 11:31:53,656:INFO:Importing untrained model
2022-09-28 11:31:53,658:INFO:Gradient Boosting Regressor Imported successfully
2022-09-28 11:31:53,661:INFO:Starting cross validation
2022-09-28 11:31:53,661:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:54,206:INFO:Calculating mean and std
2022-09-28 11:31:54,207:INFO:Creating metrics dataframe
2022-09-28 11:31:54,209:INFO:Uploading results into container
2022-09-28 11:31:54,209:INFO:Uploading model into container now
2022-09-28 11:31:54,209:INFO:master_model_container: 16
2022-09-28 11:31:54,209:INFO:display_container: 2
2022-09-28 11:31:54,209:INFO:GradientBoostingRegressor(random_state=123)
2022-09-28 11:31:54,209:INFO:create_model() successfully completed......................................
2022-09-28 11:31:54,294:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:54,295:INFO:Creating metrics dataframe
2022-09-28 11:31:54,301:INFO:Initializing Extreme Gradient Boosting
2022-09-28 11:31:54,301:INFO:Total runtime is 0.07841620047887166 minutes
2022-09-28 11:31:54,302:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:54,303:INFO:Initializing create_model()
2022-09-28 11:31:54,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:54,303:INFO:Checking exceptions
2022-09-28 11:31:54,304:INFO:Importing libraries
2022-09-28 11:31:54,304:INFO:Copying training dataset
2022-09-28 11:31:54,305:INFO:Defining folds
2022-09-28 11:31:54,305:INFO:Declaring metric variables
2022-09-28 11:31:54,307:INFO:Importing untrained model
2022-09-28 11:31:54,308:INFO:Extreme Gradient Boosting Imported successfully
2022-09-28 11:31:54,312:INFO:Starting cross validation
2022-09-28 11:31:54,312:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:54,702:INFO:Calculating mean and std
2022-09-28 11:31:54,702:INFO:Creating metrics dataframe
2022-09-28 11:31:54,704:INFO:Uploading results into container
2022-09-28 11:31:54,704:INFO:Uploading model into container now
2022-09-28 11:31:54,704:INFO:master_model_container: 17
2022-09-28 11:31:54,704:INFO:display_container: 2
2022-09-28 11:31:54,705:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=123,
             reg_alpha=None, reg_lambda=None, ...)
2022-09-28 11:31:54,705:INFO:create_model() successfully completed......................................
2022-09-28 11:31:54,790:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:54,790:INFO:Creating metrics dataframe
2022-09-28 11:31:54,795:INFO:Initializing Light Gradient Boosting Machine
2022-09-28 11:31:54,796:INFO:Total runtime is 0.08666255076726277 minutes
2022-09-28 11:31:54,797:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:54,797:INFO:Initializing create_model()
2022-09-28 11:31:54,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:54,797:INFO:Checking exceptions
2022-09-28 11:31:54,798:INFO:Importing libraries
2022-09-28 11:31:54,798:INFO:Copying training dataset
2022-09-28 11:31:54,799:INFO:Defining folds
2022-09-28 11:31:54,799:INFO:Declaring metric variables
2022-09-28 11:31:54,800:INFO:Importing untrained model
2022-09-28 11:31:54,801:INFO:Light Gradient Boosting Machine Imported successfully
2022-09-28 11:31:54,804:INFO:Starting cross validation
2022-09-28 11:31:54,805:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:54,913:INFO:Calculating mean and std
2022-09-28 11:31:54,914:INFO:Creating metrics dataframe
2022-09-28 11:31:54,915:INFO:Uploading results into container
2022-09-28 11:31:54,915:INFO:Uploading model into container now
2022-09-28 11:31:54,915:INFO:master_model_container: 18
2022-09-28 11:31:54,915:INFO:display_container: 2
2022-09-28 11:31:54,916:INFO:LGBMRegressor(random_state=123)
2022-09-28 11:31:54,916:INFO:create_model() successfully completed......................................
2022-09-28 11:31:55,003:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:55,003:INFO:Creating metrics dataframe
2022-09-28 11:31:55,008:INFO:Initializing Dummy Regressor
2022-09-28 11:31:55,008:INFO:Total runtime is 0.0902090827624003 minutes
2022-09-28 11:31:55,010:INFO:SubProcess create_model() called ==================================
2022-09-28 11:31:55,010:INFO:Initializing create_model()
2022-09-28 11:31:55,010:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x298a01c00>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:55,010:INFO:Checking exceptions
2022-09-28 11:31:55,011:INFO:Importing libraries
2022-09-28 11:31:55,011:INFO:Copying training dataset
2022-09-28 11:31:55,013:INFO:Defining folds
2022-09-28 11:31:55,013:INFO:Declaring metric variables
2022-09-28 11:31:55,014:INFO:Importing untrained model
2022-09-28 11:31:55,015:INFO:Dummy Regressor Imported successfully
2022-09-28 11:31:55,018:INFO:Starting cross validation
2022-09-28 11:31:55,019:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:31:55,062:INFO:Calculating mean and std
2022-09-28 11:31:55,062:INFO:Creating metrics dataframe
2022-09-28 11:31:55,063:INFO:Uploading results into container
2022-09-28 11:31:55,063:INFO:Uploading model into container now
2022-09-28 11:31:55,064:INFO:master_model_container: 19
2022-09-28 11:31:55,064:INFO:display_container: 2
2022-09-28 11:31:55,064:INFO:DummyRegressor()
2022-09-28 11:31:55,064:INFO:create_model() successfully completed......................................
2022-09-28 11:31:55,149:INFO:SubProcess create_model() end ==================================
2022-09-28 11:31:55,149:INFO:Creating metrics dataframe
2022-09-28 11:31:55,158:INFO:Initializing create_model()
2022-09-28 11:31:55,158:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2a49c0a30>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:31:55,158:INFO:Checking exceptions
2022-09-28 11:31:55,160:INFO:Importing libraries
2022-09-28 11:31:55,160:INFO:Copying training dataset
2022-09-28 11:31:55,161:INFO:Defining folds
2022-09-28 11:31:55,161:INFO:Declaring metric variables
2022-09-28 11:31:55,161:INFO:Importing untrained model
2022-09-28 11:31:55,161:INFO:Declaring custom model
2022-09-28 11:31:55,162:INFO:Extra Trees Regressor Imported successfully
2022-09-28 11:31:55,162:INFO:Cross validation set to False
2022-09-28 11:31:55,162:INFO:Fitting Model
2022-09-28 11:31:55,263:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:31:55,263:INFO:create_model() successfully completed......................................
2022-09-28 11:31:55,361:INFO:master_model_container: 19
2022-09-28 11:31:55,362:INFO:display_container: 2
2022-09-28 11:31:55,362:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:31:55,362:INFO:compare_models() successfully completed......................................
2022-09-28 11:32:23,768:INFO:PyCaret RegressionExperiment
2022-09-28 11:32:23,769:INFO:Logging name: reg-default-name
2022-09-28 11:32:23,769:INFO:ML Usecase: MLUsecase.REGRESSION
2022-09-28 11:32:23,769:INFO:version 3.0.0.rc4
2022-09-28 11:32:23,769:INFO:Initializing setup()
2022-09-28 11:32:23,769:INFO:self.USI: 22f0
2022-09-28 11:32:23,769:INFO:self.variable_keys: {'gpu_param', 'n_jobs_param', 'target_param', 'fold_generator', 'variable_keys', '_all_metrics', 'data', 'exp_id', 'USI', 'y', 'master_model_container', 'seed', 'fold_shuffle_param', 'transform_target_method_param', 'y_train', 'logging_param', '_available_plots', 'X_test', '_ml_usecase', 'y_test', 'pipeline', 'X_train', '_all_models_internal', 'exp_name_log', 'X', 'transform_target_param', 'memory', 'log_plots_param', 'idx', 'fold_groups_param', '_gpu_n_jobs_param', 'display_container', '_all_models', 'html_param'}
2022-09-28 11:32:23,769:INFO:Checking environment
2022-09-28 11:32:23,769:INFO:python_version: 3.10.6
2022-09-28 11:32:23,769:INFO:python_build: ('main', 'Aug 11 2022 13:36:31')
2022-09-28 11:32:23,769:INFO:machine: arm64
2022-09-28 11:32:23,769:INFO:platform: macOS-12.5.1-arm64-arm-64bit
2022-09-28 11:32:23,769:INFO:Memory: svmem(total=17179869184, available=5448613888, percent=68.3, used=7113670656, free=125796352, active=5344329728, inactive=5320343552, wired=1769340928)
2022-09-28 11:32:23,769:INFO:Physical Core: 10
2022-09-28 11:32:23,769:INFO:Logical Core: 10
2022-09-28 11:32:23,770:INFO:Checking libraries
2022-09-28 11:32:23,770:INFO:System:
2022-09-28 11:32:23,770:INFO:    python: 3.10.6 (main, Aug 11 2022, 13:36:31) [Clang 13.1.6 (clang-1316.0.21.2.5)]
2022-09-28 11:32:23,770:INFO:executable: /Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/bin/python
2022-09-28 11:32:23,770:INFO:   machine: macOS-12.5.1-arm64-arm-64bit
2022-09-28 11:32:23,770:INFO:PyCaret required dependencies:
2022-09-28 11:32:23,770:INFO:                 pip: 22.2.2
2022-09-28 11:32:23,770:INFO:          setuptools: 65.4.0
2022-09-28 11:32:23,770:INFO:             pycaret: 3.0.0rc4
2022-09-28 11:32:23,770:INFO:             IPython: 8.5.0
2022-09-28 11:32:23,770:INFO:          ipywidgets: 8.0.2
2022-09-28 11:32:23,770:INFO:                tqdm: 4.64.1
2022-09-28 11:32:23,770:INFO:               numpy: 1.22.4
2022-09-28 11:32:23,770:INFO:              pandas: 1.4.4
2022-09-28 11:32:23,770:INFO:              jinja2: 3.1.2
2022-09-28 11:32:23,771:INFO:               scipy: 1.8.1
2022-09-28 11:32:23,771:INFO:              joblib: 1.2.0
2022-09-28 11:32:23,771:INFO:             sklearn: 1.1.2
2022-09-28 11:32:23,771:INFO:                pyod: 1.0.5
2022-09-28 11:32:23,771:INFO:            imblearn: 0.9.1
2022-09-28 11:32:23,771:INFO:   category_encoders: 2.5.0
2022-09-28 11:32:23,771:INFO:            lightgbm: 3.3.2
2022-09-28 11:32:23,771:INFO:               numba: 0.55.2
2022-09-28 11:32:23,771:INFO:            requests: 2.28.1
2022-09-28 11:32:23,771:INFO:          matplotlib: 3.6.0
2022-09-28 11:32:23,771:INFO:          scikitplot: 0.3.7
2022-09-28 11:32:23,771:INFO:         yellowbrick: 1.5
2022-09-28 11:32:23,772:INFO:              plotly: 5.10.0
2022-09-28 11:32:23,772:INFO:             kaleido: 0.2.1
2022-09-28 11:32:23,772:INFO:         statsmodels: 0.13.2
2022-09-28 11:32:23,772:INFO:              sktime: 0.13.4
2022-09-28 11:32:23,772:INFO:               tbats: 1.1.0
2022-09-28 11:32:23,772:INFO:            pmdarima: 1.8.5
2022-09-28 11:32:23,772:INFO:              psutil: 5.9.2
2022-09-28 11:32:23,772:INFO:PyCaret optional dependencies:
2022-09-28 11:32:23,772:INFO:                shap: Not installed
2022-09-28 11:32:23,772:INFO:           interpret: Not installed
2022-09-28 11:32:23,772:INFO:                umap: Not installed
2022-09-28 11:32:23,772:INFO:    pandas_profiling: Not installed
2022-09-28 11:32:23,773:INFO:  explainerdashboard: Not installed
2022-09-28 11:32:23,773:INFO:             autoviz: Not installed
2022-09-28 11:32:23,773:INFO:           fairlearn: Not installed
2022-09-28 11:32:23,773:INFO:             xgboost: 1.6.2
2022-09-28 11:32:23,773:INFO:            catboost: Not installed
2022-09-28 11:32:23,773:INFO:              kmodes: Not installed
2022-09-28 11:32:23,773:INFO:             mlxtend: Not installed
2022-09-28 11:32:23,773:INFO:       statsforecast: Not installed
2022-09-28 11:32:23,773:INFO:        tune_sklearn: Not installed
2022-09-28 11:32:23,773:INFO:                 ray: Not installed
2022-09-28 11:32:23,773:INFO:            hyperopt: Not installed
2022-09-28 11:32:23,773:INFO:              optuna: Not installed
2022-09-28 11:32:23,773:INFO:               skopt: Not installed
2022-09-28 11:32:23,774:INFO:              mlflow: Not installed
2022-09-28 11:32:23,774:INFO:              gradio: Not installed
2022-09-28 11:32:23,774:INFO:             fastapi: Not installed
2022-09-28 11:32:23,774:INFO:             uvicorn: Not installed
2022-09-28 11:32:23,774:INFO:              m2cgen: Not installed
2022-09-28 11:32:23,774:INFO:           evidently: Not installed
2022-09-28 11:32:23,774:INFO:                nltk: Not installed
2022-09-28 11:32:23,774:INFO:            pyLDAvis: Not installed
2022-09-28 11:32:23,774:INFO:              gensim: Not installed
2022-09-28 11:32:23,774:INFO:               spacy: Not installed
2022-09-28 11:32:23,774:INFO:           wordcloud: Not installed
2022-09-28 11:32:23,774:INFO:            textblob: Not installed
2022-09-28 11:32:23,774:INFO:               fugue: Not installed
2022-09-28 11:32:23,774:INFO:           streamlit: Not installed
2022-09-28 11:32:23,774:INFO:             prophet: Not installed
2022-09-28 11:32:23,774:INFO:None
2022-09-28 11:32:23,775:INFO:Set up data.
2022-09-28 11:32:23,782:INFO:Set up train/test split.
2022-09-28 11:32:23,785:INFO:Set up index.
2022-09-28 11:32:23,785:INFO:Set up folding strategy.
2022-09-28 11:32:23,785:INFO:Assigning column types.
2022-09-28 11:32:23,787:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-09-28 11:32:23,787:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-28 11:32:23,790:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:32:23,793:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:32:23,830:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:32:23,853:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:32:23,853:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:32:23,855:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:32:23,855:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-28 11:32:23,857:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:32:23,859:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:32:23,882:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:32:23,901:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:32:23,901:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:32:23,902:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:32:23,902:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-09-28 11:32:23,904:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:32:23,906:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:32:23,930:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:32:23,949:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:32:23,949:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:32:23,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:32:23,952:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:32:23,954:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:32:23,977:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:32:23,996:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:32:23,996:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:32:23,997:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:32:23,997:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-09-28 11:32:24,001:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:32:24,025:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:32:24,044:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:32:24,044:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:32:24,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:32:24,050:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:32:24,073:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:32:24,091:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:32:24,091:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:32:24,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:32:24,093:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-09-28 11:32:24,120:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:32:24,139:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:32:24,140:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:32:24,141:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:32:24,168:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:32:24,186:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:32:24,187:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:32:24,188:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:32:24,188:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-09-28 11:32:24,215:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:32:24,233:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:32:24,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:32:24,262:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:32:24,280:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:32:24,281:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:32:24,282:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-09-28 11:32:24,327:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:32:24,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:32:24,376:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:32:24,377:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:32:24,377:INFO:Preparing preprocessing pipeline...
2022-09-28 11:32:24,377:INFO:Set up simple imputation.
2022-09-28 11:32:24,377:INFO:Set up variance threshold.
2022-09-28 11:32:24,385:INFO:Finished creating preprocessing pipeline.
2022-09-28 11:32:24,387:INFO:Pipeline: Pipeline(memory=Memory(location=/var/folders/67/hmlyjz1x4x7b_71cqk6bxrg00000gq/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demand_point_index',
                                             'x_coordinate', 'y_coordinate',
                                             '2010', '2011', '2012', '2013',
                                             '2014', '2015', '2016', '2017'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-09-28 11:32:24,387:INFO:Creating final display dataframe.
2022-09-28 11:32:24,426:INFO:Setup display_container:                Description             Value
0               Session id               123
1                   Target              2018
2              Target type        Regression
3               Data shape        (4096, 12)
4         Train data shape        (2867, 12)
5          Test data shape        (1229, 12)
6         Numeric features                11
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              22f0
2022-09-28 11:32:24,476:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:32:24,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:32:24,523:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:32:24,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:32:24,527:INFO:setup() successfully completed in 0.76s...............
2022-09-28 11:32:28,094:INFO:Initializing compare_models()
2022-09-28 11:32:28,094:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-09-28 11:32:28,095:INFO:Checking exceptions
2022-09-28 11:32:28,101:INFO:Preparing display monitor
2022-09-28 11:32:28,128:INFO:Initializing Linear Regression
2022-09-28 11:32:28,128:INFO:Total runtime is 2.4318695068359373e-06 minutes
2022-09-28 11:32:28,130:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:28,130:INFO:Initializing create_model()
2022-09-28 11:32:28,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:28,130:INFO:Checking exceptions
2022-09-28 11:32:28,132:INFO:Importing libraries
2022-09-28 11:32:28,132:INFO:Copying training dataset
2022-09-28 11:32:28,134:INFO:Defining folds
2022-09-28 11:32:28,134:INFO:Declaring metric variables
2022-09-28 11:32:28,136:INFO:Importing untrained model
2022-09-28 11:32:28,137:INFO:Linear Regression Imported successfully
2022-09-28 11:32:28,140:INFO:Starting cross validation
2022-09-28 11:32:28,142:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:28,200:INFO:Calculating mean and std
2022-09-28 11:32:28,200:INFO:Creating metrics dataframe
2022-09-28 11:32:28,201:INFO:Uploading results into container
2022-09-28 11:32:28,202:INFO:Uploading model into container now
2022-09-28 11:32:28,202:INFO:master_model_container: 1
2022-09-28 11:32:28,202:INFO:display_container: 2
2022-09-28 11:32:28,202:INFO:LinearRegression(n_jobs=-1)
2022-09-28 11:32:28,202:INFO:create_model() successfully completed......................................
2022-09-28 11:32:28,288:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:28,288:INFO:Creating metrics dataframe
2022-09-28 11:32:28,291:INFO:Initializing Lasso Regression
2022-09-28 11:32:28,291:INFO:Total runtime is 0.0027168472607930504 minutes
2022-09-28 11:32:28,292:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:28,292:INFO:Initializing create_model()
2022-09-28 11:32:28,292:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:28,293:INFO:Checking exceptions
2022-09-28 11:32:28,293:INFO:Importing libraries
2022-09-28 11:32:28,293:INFO:Copying training dataset
2022-09-28 11:32:28,295:INFO:Defining folds
2022-09-28 11:32:28,295:INFO:Declaring metric variables
2022-09-28 11:32:28,296:INFO:Importing untrained model
2022-09-28 11:32:28,298:INFO:Lasso Regression Imported successfully
2022-09-28 11:32:28,301:INFO:Starting cross validation
2022-09-28 11:32:28,301:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:28,357:INFO:Calculating mean and std
2022-09-28 11:32:28,358:INFO:Creating metrics dataframe
2022-09-28 11:32:28,359:INFO:Uploading results into container
2022-09-28 11:32:28,359:INFO:Uploading model into container now
2022-09-28 11:32:28,359:INFO:master_model_container: 2
2022-09-28 11:32:28,359:INFO:display_container: 2
2022-09-28 11:32:28,360:INFO:Lasso(random_state=123)
2022-09-28 11:32:28,360:INFO:create_model() successfully completed......................................
2022-09-28 11:32:28,447:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:28,447:INFO:Creating metrics dataframe
2022-09-28 11:32:28,451:INFO:Initializing Ridge Regression
2022-09-28 11:32:28,451:INFO:Total runtime is 0.0053899288177490234 minutes
2022-09-28 11:32:28,453:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:28,453:INFO:Initializing create_model()
2022-09-28 11:32:28,453:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:28,453:INFO:Checking exceptions
2022-09-28 11:32:28,454:INFO:Importing libraries
2022-09-28 11:32:28,454:INFO:Copying training dataset
2022-09-28 11:32:28,455:INFO:Defining folds
2022-09-28 11:32:28,455:INFO:Declaring metric variables
2022-09-28 11:32:28,456:INFO:Importing untrained model
2022-09-28 11:32:28,457:INFO:Ridge Regression Imported successfully
2022-09-28 11:32:28,460:INFO:Starting cross validation
2022-09-28 11:32:28,460:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:28,502:INFO:Calculating mean and std
2022-09-28 11:32:28,502:INFO:Creating metrics dataframe
2022-09-28 11:32:28,503:INFO:Uploading results into container
2022-09-28 11:32:28,504:INFO:Uploading model into container now
2022-09-28 11:32:28,504:INFO:master_model_container: 3
2022-09-28 11:32:28,504:INFO:display_container: 2
2022-09-28 11:32:28,504:INFO:Ridge(random_state=123)
2022-09-28 11:32:28,504:INFO:create_model() successfully completed......................................
2022-09-28 11:32:28,588:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:28,588:INFO:Creating metrics dataframe
2022-09-28 11:32:28,592:INFO:Initializing Elastic Net
2022-09-28 11:32:28,592:INFO:Total runtime is 0.007729947566986084 minutes
2022-09-28 11:32:28,593:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:28,593:INFO:Initializing create_model()
2022-09-28 11:32:28,593:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:28,593:INFO:Checking exceptions
2022-09-28 11:32:28,594:INFO:Importing libraries
2022-09-28 11:32:28,594:INFO:Copying training dataset
2022-09-28 11:32:28,595:INFO:Defining folds
2022-09-28 11:32:28,595:INFO:Declaring metric variables
2022-09-28 11:32:28,597:INFO:Importing untrained model
2022-09-28 11:32:28,598:INFO:Elastic Net Imported successfully
2022-09-28 11:32:28,601:INFO:Starting cross validation
2022-09-28 11:32:28,602:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:28,659:INFO:Calculating mean and std
2022-09-28 11:32:28,659:INFO:Creating metrics dataframe
2022-09-28 11:32:28,660:INFO:Uploading results into container
2022-09-28 11:32:28,660:INFO:Uploading model into container now
2022-09-28 11:32:28,660:INFO:master_model_container: 4
2022-09-28 11:32:28,660:INFO:display_container: 2
2022-09-28 11:32:28,660:INFO:ElasticNet(random_state=123)
2022-09-28 11:32:28,660:INFO:create_model() successfully completed......................................
2022-09-28 11:32:28,747:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:28,747:INFO:Creating metrics dataframe
2022-09-28 11:32:28,751:INFO:Initializing Least Angle Regression
2022-09-28 11:32:28,751:INFO:Total runtime is 0.010384579499562582 minutes
2022-09-28 11:32:28,752:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:28,752:INFO:Initializing create_model()
2022-09-28 11:32:28,753:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:28,753:INFO:Checking exceptions
2022-09-28 11:32:28,754:INFO:Importing libraries
2022-09-28 11:32:28,754:INFO:Copying training dataset
2022-09-28 11:32:28,754:INFO:Defining folds
2022-09-28 11:32:28,754:INFO:Declaring metric variables
2022-09-28 11:32:28,756:INFO:Importing untrained model
2022-09-28 11:32:28,757:INFO:Least Angle Regression Imported successfully
2022-09-28 11:32:28,760:INFO:Starting cross validation
2022-09-28 11:32:28,760:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:28,775:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:28,777:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:28,782:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:28,787:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:28,789:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:28,791:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:28,794:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:28,799:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:28,801:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:28,804:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:28,808:INFO:Calculating mean and std
2022-09-28 11:32:28,808:INFO:Creating metrics dataframe
2022-09-28 11:32:28,810:INFO:Uploading results into container
2022-09-28 11:32:28,810:INFO:Uploading model into container now
2022-09-28 11:32:28,810:INFO:master_model_container: 5
2022-09-28 11:32:28,810:INFO:display_container: 2
2022-09-28 11:32:28,810:INFO:Lars(random_state=123)
2022-09-28 11:32:28,810:INFO:create_model() successfully completed......................................
2022-09-28 11:32:28,897:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:28,897:INFO:Creating metrics dataframe
2022-09-28 11:32:28,901:INFO:Initializing Lasso Least Angle Regression
2022-09-28 11:32:28,901:INFO:Total runtime is 0.012878366311391196 minutes
2022-09-28 11:32:28,902:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:28,902:INFO:Initializing create_model()
2022-09-28 11:32:28,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:28,902:INFO:Checking exceptions
2022-09-28 11:32:28,903:INFO:Importing libraries
2022-09-28 11:32:28,903:INFO:Copying training dataset
2022-09-28 11:32:28,904:INFO:Defining folds
2022-09-28 11:32:28,904:INFO:Declaring metric variables
2022-09-28 11:32:28,905:INFO:Importing untrained model
2022-09-28 11:32:28,906:INFO:Lasso Least Angle Regression Imported successfully
2022-09-28 11:32:28,908:INFO:Starting cross validation
2022-09-28 11:32:28,909:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:28,924:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:32:28,926:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:32:28,928:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:32:28,932:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:32:28,933:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:32:28,936:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:32:28,938:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:32:28,941:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:32:28,943:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:32:28,945:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:32:28,950:INFO:Calculating mean and std
2022-09-28 11:32:28,950:INFO:Creating metrics dataframe
2022-09-28 11:32:28,951:INFO:Uploading results into container
2022-09-28 11:32:28,951:INFO:Uploading model into container now
2022-09-28 11:32:28,951:INFO:master_model_container: 6
2022-09-28 11:32:28,952:INFO:display_container: 2
2022-09-28 11:32:28,952:INFO:LassoLars(random_state=123)
2022-09-28 11:32:28,952:INFO:create_model() successfully completed......................................
2022-09-28 11:32:29,037:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:29,037:INFO:Creating metrics dataframe
2022-09-28 11:32:29,041:INFO:Initializing Orthogonal Matching Pursuit
2022-09-28 11:32:29,041:INFO:Total runtime is 0.015216183662414551 minutes
2022-09-28 11:32:29,042:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:29,042:INFO:Initializing create_model()
2022-09-28 11:32:29,042:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:29,042:INFO:Checking exceptions
2022-09-28 11:32:29,043:INFO:Importing libraries
2022-09-28 11:32:29,043:INFO:Copying training dataset
2022-09-28 11:32:29,044:INFO:Defining folds
2022-09-28 11:32:29,045:INFO:Declaring metric variables
2022-09-28 11:32:29,046:INFO:Importing untrained model
2022-09-28 11:32:29,047:INFO:Orthogonal Matching Pursuit Imported successfully
2022-09-28 11:32:29,050:INFO:Starting cross validation
2022-09-28 11:32:29,050:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:29,065:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:29,067:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:29,069:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:29,076:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:29,078:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:29,080:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:29,083:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:29,085:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:29,088:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:29,090:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:32:29,095:INFO:Calculating mean and std
2022-09-28 11:32:29,095:INFO:Creating metrics dataframe
2022-09-28 11:32:29,096:INFO:Uploading results into container
2022-09-28 11:32:29,097:INFO:Uploading model into container now
2022-09-28 11:32:29,097:INFO:master_model_container: 7
2022-09-28 11:32:29,097:INFO:display_container: 2
2022-09-28 11:32:29,097:INFO:OrthogonalMatchingPursuit()
2022-09-28 11:32:29,097:INFO:create_model() successfully completed......................................
2022-09-28 11:32:29,184:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:29,184:INFO:Creating metrics dataframe
2022-09-28 11:32:29,188:INFO:Initializing Bayesian Ridge
2022-09-28 11:32:29,188:INFO:Total runtime is 0.01766941547393799 minutes
2022-09-28 11:32:29,189:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:29,189:INFO:Initializing create_model()
2022-09-28 11:32:29,189:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:29,190:INFO:Checking exceptions
2022-09-28 11:32:29,190:INFO:Importing libraries
2022-09-28 11:32:29,190:INFO:Copying training dataset
2022-09-28 11:32:29,192:INFO:Defining folds
2022-09-28 11:32:29,192:INFO:Declaring metric variables
2022-09-28 11:32:29,193:INFO:Importing untrained model
2022-09-28 11:32:29,194:INFO:Bayesian Ridge Imported successfully
2022-09-28 11:32:29,197:INFO:Starting cross validation
2022-09-28 11:32:29,197:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:29,245:INFO:Calculating mean and std
2022-09-28 11:32:29,245:INFO:Creating metrics dataframe
2022-09-28 11:32:29,246:INFO:Uploading results into container
2022-09-28 11:32:29,246:INFO:Uploading model into container now
2022-09-28 11:32:29,247:INFO:master_model_container: 8
2022-09-28 11:32:29,247:INFO:display_container: 2
2022-09-28 11:32:29,247:INFO:BayesianRidge()
2022-09-28 11:32:29,247:INFO:create_model() successfully completed......................................
2022-09-28 11:32:29,336:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:29,336:INFO:Creating metrics dataframe
2022-09-28 11:32:29,340:INFO:Initializing Passive Aggressive Regressor
2022-09-28 11:32:29,340:INFO:Total runtime is 0.020207432905832927 minutes
2022-09-28 11:32:29,342:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:29,342:INFO:Initializing create_model()
2022-09-28 11:32:29,342:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:29,342:INFO:Checking exceptions
2022-09-28 11:32:29,343:INFO:Importing libraries
2022-09-28 11:32:29,343:INFO:Copying training dataset
2022-09-28 11:32:29,345:INFO:Defining folds
2022-09-28 11:32:29,345:INFO:Declaring metric variables
2022-09-28 11:32:29,346:INFO:Importing untrained model
2022-09-28 11:32:29,347:INFO:Passive Aggressive Regressor Imported successfully
2022-09-28 11:32:29,350:INFO:Starting cross validation
2022-09-28 11:32:29,350:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:29,395:INFO:Calculating mean and std
2022-09-28 11:32:29,395:INFO:Creating metrics dataframe
2022-09-28 11:32:29,396:INFO:Uploading results into container
2022-09-28 11:32:29,397:INFO:Uploading model into container now
2022-09-28 11:32:29,397:INFO:master_model_container: 9
2022-09-28 11:32:29,397:INFO:display_container: 2
2022-09-28 11:32:29,397:INFO:PassiveAggressiveRegressor(random_state=123)
2022-09-28 11:32:29,397:INFO:create_model() successfully completed......................................
2022-09-28 11:32:29,484:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:29,484:INFO:Creating metrics dataframe
2022-09-28 11:32:29,489:INFO:Initializing Huber Regressor
2022-09-28 11:32:29,489:INFO:Total runtime is 0.02268054485321045 minutes
2022-09-28 11:32:29,490:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:29,490:INFO:Initializing create_model()
2022-09-28 11:32:29,490:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:29,490:INFO:Checking exceptions
2022-09-28 11:32:29,491:INFO:Importing libraries
2022-09-28 11:32:29,491:INFO:Copying training dataset
2022-09-28 11:32:29,493:INFO:Defining folds
2022-09-28 11:32:29,493:INFO:Declaring metric variables
2022-09-28 11:32:29,494:INFO:Importing untrained model
2022-09-28 11:32:29,495:INFO:Huber Regressor Imported successfully
2022-09-28 11:32:29,498:INFO:Starting cross validation
2022-09-28 11:32:29,498:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:29,538:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:32:29,538:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:32:29,543:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:32:29,548:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:32:29,553:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:32:29,556:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:32:29,561:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:32:29,570:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:32:29,575:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:32:29,578:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:32:29,582:INFO:Calculating mean and std
2022-09-28 11:32:29,582:INFO:Creating metrics dataframe
2022-09-28 11:32:29,584:INFO:Uploading results into container
2022-09-28 11:32:29,584:INFO:Uploading model into container now
2022-09-28 11:32:29,584:INFO:master_model_container: 10
2022-09-28 11:32:29,584:INFO:display_container: 2
2022-09-28 11:32:29,584:INFO:HuberRegressor()
2022-09-28 11:32:29,584:INFO:create_model() successfully completed......................................
2022-09-28 11:32:29,670:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:29,670:INFO:Creating metrics dataframe
2022-09-28 11:32:29,674:INFO:Initializing K Neighbors Regressor
2022-09-28 11:32:29,674:INFO:Total runtime is 0.025772511959075928 minutes
2022-09-28 11:32:29,675:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:29,676:INFO:Initializing create_model()
2022-09-28 11:32:29,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:29,676:INFO:Checking exceptions
2022-09-28 11:32:29,676:INFO:Importing libraries
2022-09-28 11:32:29,676:INFO:Copying training dataset
2022-09-28 11:32:29,678:INFO:Defining folds
2022-09-28 11:32:29,678:INFO:Declaring metric variables
2022-09-28 11:32:29,679:INFO:Importing untrained model
2022-09-28 11:32:29,681:INFO:K Neighbors Regressor Imported successfully
2022-09-28 11:32:29,683:INFO:Starting cross validation
2022-09-28 11:32:29,684:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:29,729:INFO:Calculating mean and std
2022-09-28 11:32:29,730:INFO:Creating metrics dataframe
2022-09-28 11:32:29,731:INFO:Uploading results into container
2022-09-28 11:32:29,731:INFO:Uploading model into container now
2022-09-28 11:32:29,731:INFO:master_model_container: 11
2022-09-28 11:32:29,731:INFO:display_container: 2
2022-09-28 11:32:29,731:INFO:KNeighborsRegressor(n_jobs=-1)
2022-09-28 11:32:29,731:INFO:create_model() successfully completed......................................
2022-09-28 11:32:29,819:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:29,819:INFO:Creating metrics dataframe
2022-09-28 11:32:29,824:INFO:Initializing Decision Tree Regressor
2022-09-28 11:32:29,824:INFO:Total runtime is 0.028273797035217284 minutes
2022-09-28 11:32:29,826:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:29,826:INFO:Initializing create_model()
2022-09-28 11:32:29,826:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:29,826:INFO:Checking exceptions
2022-09-28 11:32:29,827:INFO:Importing libraries
2022-09-28 11:32:29,827:INFO:Copying training dataset
2022-09-28 11:32:29,828:INFO:Defining folds
2022-09-28 11:32:29,828:INFO:Declaring metric variables
2022-09-28 11:32:29,829:INFO:Importing untrained model
2022-09-28 11:32:29,831:INFO:Decision Tree Regressor Imported successfully
2022-09-28 11:32:29,833:INFO:Starting cross validation
2022-09-28 11:32:29,834:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:29,903:INFO:Calculating mean and std
2022-09-28 11:32:29,903:INFO:Creating metrics dataframe
2022-09-28 11:32:29,904:INFO:Uploading results into container
2022-09-28 11:32:29,904:INFO:Uploading model into container now
2022-09-28 11:32:29,904:INFO:master_model_container: 12
2022-09-28 11:32:29,904:INFO:display_container: 2
2022-09-28 11:32:29,905:INFO:DecisionTreeRegressor(random_state=123)
2022-09-28 11:32:29,905:INFO:create_model() successfully completed......................................
2022-09-28 11:32:29,991:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:29,991:INFO:Creating metrics dataframe
2022-09-28 11:32:29,996:INFO:Initializing Random Forest Regressor
2022-09-28 11:32:29,996:INFO:Total runtime is 0.03113429546356201 minutes
2022-09-28 11:32:29,997:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:29,997:INFO:Initializing create_model()
2022-09-28 11:32:29,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:29,997:INFO:Checking exceptions
2022-09-28 11:32:29,998:INFO:Importing libraries
2022-09-28 11:32:29,999:INFO:Copying training dataset
2022-09-28 11:32:30,000:INFO:Defining folds
2022-09-28 11:32:30,000:INFO:Declaring metric variables
2022-09-28 11:32:30,002:INFO:Importing untrained model
2022-09-28 11:32:30,003:INFO:Random Forest Regressor Imported successfully
2022-09-28 11:32:30,006:INFO:Starting cross validation
2022-09-28 11:32:30,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:31,112:INFO:Calculating mean and std
2022-09-28 11:32:31,112:INFO:Creating metrics dataframe
2022-09-28 11:32:31,114:INFO:Uploading results into container
2022-09-28 11:32:31,114:INFO:Uploading model into container now
2022-09-28 11:32:31,114:INFO:master_model_container: 13
2022-09-28 11:32:31,114:INFO:display_container: 2
2022-09-28 11:32:31,114:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:32:31,114:INFO:create_model() successfully completed......................................
2022-09-28 11:32:31,204:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:31,204:INFO:Creating metrics dataframe
2022-09-28 11:32:31,210:INFO:Initializing Extra Trees Regressor
2022-09-28 11:32:31,210:INFO:Total runtime is 0.05136574506759643 minutes
2022-09-28 11:32:31,211:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:31,212:INFO:Initializing create_model()
2022-09-28 11:32:31,212:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:31,212:INFO:Checking exceptions
2022-09-28 11:32:31,213:INFO:Importing libraries
2022-09-28 11:32:31,213:INFO:Copying training dataset
2022-09-28 11:32:31,214:INFO:Defining folds
2022-09-28 11:32:31,214:INFO:Declaring metric variables
2022-09-28 11:32:31,215:INFO:Importing untrained model
2022-09-28 11:32:31,216:INFO:Extra Trees Regressor Imported successfully
2022-09-28 11:32:31,220:INFO:Starting cross validation
2022-09-28 11:32:31,220:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:31,782:INFO:Calculating mean and std
2022-09-28 11:32:31,782:INFO:Creating metrics dataframe
2022-09-28 11:32:31,784:INFO:Uploading results into container
2022-09-28 11:32:31,784:INFO:Uploading model into container now
2022-09-28 11:32:31,784:INFO:master_model_container: 14
2022-09-28 11:32:31,784:INFO:display_container: 2
2022-09-28 11:32:31,784:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:32:31,784:INFO:create_model() successfully completed......................................
2022-09-28 11:32:31,877:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:31,877:INFO:Creating metrics dataframe
2022-09-28 11:32:31,883:INFO:Initializing AdaBoost Regressor
2022-09-28 11:32:31,883:INFO:Total runtime is 0.06258819897969564 minutes
2022-09-28 11:32:31,884:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:31,885:INFO:Initializing create_model()
2022-09-28 11:32:31,885:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:31,885:INFO:Checking exceptions
2022-09-28 11:32:31,886:INFO:Importing libraries
2022-09-28 11:32:31,886:INFO:Copying training dataset
2022-09-28 11:32:31,887:INFO:Defining folds
2022-09-28 11:32:31,887:INFO:Declaring metric variables
2022-09-28 11:32:31,888:INFO:Importing untrained model
2022-09-28 11:32:31,890:INFO:AdaBoost Regressor Imported successfully
2022-09-28 11:32:31,893:INFO:Starting cross validation
2022-09-28 11:32:31,894:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:32,131:INFO:Calculating mean and std
2022-09-28 11:32:32,132:INFO:Creating metrics dataframe
2022-09-28 11:32:32,134:INFO:Uploading results into container
2022-09-28 11:32:32,134:INFO:Uploading model into container now
2022-09-28 11:32:32,134:INFO:master_model_container: 15
2022-09-28 11:32:32,134:INFO:display_container: 2
2022-09-28 11:32:32,134:INFO:AdaBoostRegressor(random_state=123)
2022-09-28 11:32:32,134:INFO:create_model() successfully completed......................................
2022-09-28 11:32:32,221:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:32,221:INFO:Creating metrics dataframe
2022-09-28 11:32:32,226:INFO:Initializing Gradient Boosting Regressor
2022-09-28 11:32:32,226:INFO:Total runtime is 0.06830073197682698 minutes
2022-09-28 11:32:32,227:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:32,227:INFO:Initializing create_model()
2022-09-28 11:32:32,227:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:32,227:INFO:Checking exceptions
2022-09-28 11:32:32,228:INFO:Importing libraries
2022-09-28 11:32:32,228:INFO:Copying training dataset
2022-09-28 11:32:32,229:INFO:Defining folds
2022-09-28 11:32:32,229:INFO:Declaring metric variables
2022-09-28 11:32:32,230:INFO:Importing untrained model
2022-09-28 11:32:32,232:INFO:Gradient Boosting Regressor Imported successfully
2022-09-28 11:32:32,234:INFO:Starting cross validation
2022-09-28 11:32:32,234:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:32,819:INFO:Calculating mean and std
2022-09-28 11:32:32,819:INFO:Creating metrics dataframe
2022-09-28 11:32:32,821:INFO:Uploading results into container
2022-09-28 11:32:32,821:INFO:Uploading model into container now
2022-09-28 11:32:32,821:INFO:master_model_container: 16
2022-09-28 11:32:32,821:INFO:display_container: 2
2022-09-28 11:32:32,821:INFO:GradientBoostingRegressor(random_state=123)
2022-09-28 11:32:32,821:INFO:create_model() successfully completed......................................
2022-09-28 11:32:32,907:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:32,907:INFO:Creating metrics dataframe
2022-09-28 11:32:32,912:INFO:Initializing Extreme Gradient Boosting
2022-09-28 11:32:32,912:INFO:Total runtime is 0.07973182996114095 minutes
2022-09-28 11:32:32,913:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:32,913:INFO:Initializing create_model()
2022-09-28 11:32:32,913:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:32,913:INFO:Checking exceptions
2022-09-28 11:32:32,914:INFO:Importing libraries
2022-09-28 11:32:32,914:INFO:Copying training dataset
2022-09-28 11:32:32,915:INFO:Defining folds
2022-09-28 11:32:32,915:INFO:Declaring metric variables
2022-09-28 11:32:32,916:INFO:Importing untrained model
2022-09-28 11:32:32,918:INFO:Extreme Gradient Boosting Imported successfully
2022-09-28 11:32:32,921:INFO:Starting cross validation
2022-09-28 11:32:32,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:33,353:INFO:Calculating mean and std
2022-09-28 11:32:33,354:INFO:Creating metrics dataframe
2022-09-28 11:32:33,355:INFO:Uploading results into container
2022-09-28 11:32:33,355:INFO:Uploading model into container now
2022-09-28 11:32:33,355:INFO:master_model_container: 17
2022-09-28 11:32:33,355:INFO:display_container: 2
2022-09-28 11:32:33,356:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=123,
             reg_alpha=None, reg_lambda=None, ...)
2022-09-28 11:32:33,356:INFO:create_model() successfully completed......................................
2022-09-28 11:32:33,442:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:33,442:INFO:Creating metrics dataframe
2022-09-28 11:32:33,447:INFO:Initializing Light Gradient Boosting Machine
2022-09-28 11:32:33,447:INFO:Total runtime is 0.08865052858988444 minutes
2022-09-28 11:32:33,448:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:33,448:INFO:Initializing create_model()
2022-09-28 11:32:33,448:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:33,448:INFO:Checking exceptions
2022-09-28 11:32:33,449:INFO:Importing libraries
2022-09-28 11:32:33,449:INFO:Copying training dataset
2022-09-28 11:32:33,450:INFO:Defining folds
2022-09-28 11:32:33,450:INFO:Declaring metric variables
2022-09-28 11:32:33,451:INFO:Importing untrained model
2022-09-28 11:32:33,453:INFO:Light Gradient Boosting Machine Imported successfully
2022-09-28 11:32:33,455:INFO:Starting cross validation
2022-09-28 11:32:33,456:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:33,571:INFO:Calculating mean and std
2022-09-28 11:32:33,572:INFO:Creating metrics dataframe
2022-09-28 11:32:33,573:INFO:Uploading results into container
2022-09-28 11:32:33,573:INFO:Uploading model into container now
2022-09-28 11:32:33,573:INFO:master_model_container: 18
2022-09-28 11:32:33,573:INFO:display_container: 2
2022-09-28 11:32:33,574:INFO:LGBMRegressor(random_state=123)
2022-09-28 11:32:33,574:INFO:create_model() successfully completed......................................
2022-09-28 11:32:33,661:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:33,661:INFO:Creating metrics dataframe
2022-09-28 11:32:33,667:INFO:Initializing Dummy Regressor
2022-09-28 11:32:33,667:INFO:Total runtime is 0.09231231609980266 minutes
2022-09-28 11:32:33,668:INFO:SubProcess create_model() called ==================================
2022-09-28 11:32:33,668:INFO:Initializing create_model()
2022-09-28 11:32:33,668:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11fea57b0>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:33,668:INFO:Checking exceptions
2022-09-28 11:32:33,669:INFO:Importing libraries
2022-09-28 11:32:33,669:INFO:Copying training dataset
2022-09-28 11:32:33,670:INFO:Defining folds
2022-09-28 11:32:33,670:INFO:Declaring metric variables
2022-09-28 11:32:33,671:INFO:Importing untrained model
2022-09-28 11:32:33,672:INFO:Dummy Regressor Imported successfully
2022-09-28 11:32:33,675:INFO:Starting cross validation
2022-09-28 11:32:33,676:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:32:33,716:INFO:Calculating mean and std
2022-09-28 11:32:33,716:INFO:Creating metrics dataframe
2022-09-28 11:32:33,718:INFO:Uploading results into container
2022-09-28 11:32:33,718:INFO:Uploading model into container now
2022-09-28 11:32:33,718:INFO:master_model_container: 19
2022-09-28 11:32:33,718:INFO:display_container: 2
2022-09-28 11:32:33,718:INFO:DummyRegressor()
2022-09-28 11:32:33,718:INFO:create_model() successfully completed......................................
2022-09-28 11:32:33,802:INFO:SubProcess create_model() end ==================================
2022-09-28 11:32:33,802:INFO:Creating metrics dataframe
2022-09-28 11:32:33,812:INFO:Initializing create_model()
2022-09-28 11:32:33,812:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x298d655d0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:32:33,812:INFO:Checking exceptions
2022-09-28 11:32:33,813:INFO:Importing libraries
2022-09-28 11:32:33,814:INFO:Copying training dataset
2022-09-28 11:32:33,815:INFO:Defining folds
2022-09-28 11:32:33,815:INFO:Declaring metric variables
2022-09-28 11:32:33,815:INFO:Importing untrained model
2022-09-28 11:32:33,815:INFO:Declaring custom model
2022-09-28 11:32:33,815:INFO:Extra Trees Regressor Imported successfully
2022-09-28 11:32:33,816:INFO:Cross validation set to False
2022-09-28 11:32:33,816:INFO:Fitting Model
2022-09-28 11:32:33,907:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:32:33,907:INFO:create_model() successfully completed......................................
2022-09-28 11:32:34,004:INFO:master_model_container: 19
2022-09-28 11:32:34,004:INFO:display_container: 2
2022-09-28 11:32:34,004:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:32:34,004:INFO:compare_models() successfully completed......................................
2022-09-28 11:32:53,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-28 11:32:53,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-28 11:32:53,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-28 11:32:53,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-28 11:32:54,028:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2022-09-28 11:39:38,595:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:765: FutureWarning: sklearn.metrics.SCORERS is deprecated and will be removed in v1.3. Please use sklearn.metrics.get_scorer_names to get a list of available scorers and sklearn.metrics.get_metric to get scorer.
  warnings.warn(

2022-09-28 11:39:39,097:INFO:PyCaret RegressionExperiment
2022-09-28 11:39:39,097:INFO:Logging name: reg-default-name
2022-09-28 11:39:39,097:INFO:ML Usecase: MLUsecase.REGRESSION
2022-09-28 11:39:39,097:INFO:version 3.0.0.rc4
2022-09-28 11:39:39,097:INFO:Initializing setup()
2022-09-28 11:39:39,097:INFO:self.USI: dd5f
2022-09-28 11:39:39,098:INFO:self.variable_keys: {'gpu_param', 'exp_id', 'USI', 'y_test', 'seed', 'X', 'X_train', 'idx', 'transform_target_param', '_gpu_n_jobs_param', 'y_train', 'X_test', 'display_container', 'fold_groups_param', 'master_model_container', 'fold_generator', 'n_jobs_param', 'y', '_available_plots', 'fold_shuffle_param', '_ml_usecase', '_all_models', 'exp_name_log', '_all_models_internal', 'memory', 'html_param', '_all_metrics', 'log_plots_param', 'logging_param', 'pipeline', 'transform_target_method_param', 'data', 'variable_keys', 'target_param'}
2022-09-28 11:39:39,098:INFO:Checking environment
2022-09-28 11:39:39,098:INFO:python_version: 3.10.6
2022-09-28 11:39:39,098:INFO:python_build: ('main', 'Aug 11 2022 13:36:31')
2022-09-28 11:39:39,098:INFO:machine: arm64
2022-09-28 11:39:39,098:INFO:platform: macOS-12.5.1-arm64-arm-64bit
2022-09-28 11:39:39,098:INFO:Memory: svmem(total=17179869184, available=5867995136, percent=65.8, used=6969311232, free=709050368, active=5173297152, inactive=5089853440, wired=1796014080)
2022-09-28 11:39:39,098:INFO:Physical Core: 10
2022-09-28 11:39:39,098:INFO:Logical Core: 10
2022-09-28 11:39:39,098:INFO:Checking libraries
2022-09-28 11:39:39,098:INFO:System:
2022-09-28 11:39:39,098:INFO:    python: 3.10.6 (main, Aug 11 2022, 13:36:31) [Clang 13.1.6 (clang-1316.0.21.2.5)]
2022-09-28 11:39:39,098:INFO:executable: /Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/bin/python
2022-09-28 11:39:39,098:INFO:   machine: macOS-12.5.1-arm64-arm-64bit
2022-09-28 11:39:39,098:INFO:PyCaret required dependencies:
2022-09-28 11:39:39,098:INFO:                 pip: 22.2.2
2022-09-28 11:39:39,098:INFO:          setuptools: 65.4.0
2022-09-28 11:39:39,098:INFO:             pycaret: 3.0.0rc4
2022-09-28 11:39:39,098:INFO:             IPython: 8.5.0
2022-09-28 11:39:39,098:INFO:          ipywidgets: 8.0.2
2022-09-28 11:39:39,098:INFO:                tqdm: 4.64.1
2022-09-28 11:39:39,098:INFO:               numpy: 1.22.4
2022-09-28 11:39:39,098:INFO:              pandas: 1.4.4
2022-09-28 11:39:39,098:INFO:              jinja2: 3.1.2
2022-09-28 11:39:39,098:INFO:               scipy: 1.8.1
2022-09-28 11:39:39,098:INFO:              joblib: 1.2.0
2022-09-28 11:39:39,098:INFO:             sklearn: 1.1.2
2022-09-28 11:39:39,098:INFO:                pyod: 1.0.5
2022-09-28 11:39:39,098:INFO:            imblearn: 0.9.1
2022-09-28 11:39:39,098:INFO:   category_encoders: 2.5.0
2022-09-28 11:39:39,098:INFO:            lightgbm: 3.3.2
2022-09-28 11:39:39,098:INFO:               numba: 0.55.2
2022-09-28 11:39:39,098:INFO:            requests: 2.28.1
2022-09-28 11:39:39,098:INFO:          matplotlib: 3.6.0
2022-09-28 11:39:39,098:INFO:          scikitplot: 0.3.7
2022-09-28 11:39:39,098:INFO:         yellowbrick: 1.5
2022-09-28 11:39:39,098:INFO:              plotly: 5.10.0
2022-09-28 11:39:39,098:INFO:             kaleido: 0.2.1
2022-09-28 11:39:39,098:INFO:         statsmodels: 0.13.2
2022-09-28 11:39:39,098:INFO:              sktime: 0.13.4
2022-09-28 11:39:39,098:INFO:               tbats: 1.1.0
2022-09-28 11:39:39,098:INFO:            pmdarima: 1.8.5
2022-09-28 11:39:39,098:INFO:              psutil: 5.9.2
2022-09-28 11:39:39,098:INFO:PyCaret optional dependencies:
2022-09-28 11:39:39,102:INFO:                shap: Not installed
2022-09-28 11:39:39,102:INFO:           interpret: Not installed
2022-09-28 11:39:39,102:INFO:                umap: Not installed
2022-09-28 11:39:39,102:INFO:    pandas_profiling: Not installed
2022-09-28 11:39:39,102:INFO:  explainerdashboard: Not installed
2022-09-28 11:39:39,102:INFO:             autoviz: Not installed
2022-09-28 11:39:39,102:INFO:           fairlearn: Not installed
2022-09-28 11:39:39,102:INFO:             xgboost: 1.6.2
2022-09-28 11:39:39,102:INFO:            catboost: Not installed
2022-09-28 11:39:39,102:INFO:              kmodes: Not installed
2022-09-28 11:39:39,102:INFO:             mlxtend: Not installed
2022-09-28 11:39:39,102:INFO:       statsforecast: Not installed
2022-09-28 11:39:39,102:INFO:        tune_sklearn: Not installed
2022-09-28 11:39:39,102:INFO:                 ray: Not installed
2022-09-28 11:39:39,102:INFO:            hyperopt: Not installed
2022-09-28 11:39:39,102:INFO:              optuna: Not installed
2022-09-28 11:39:39,102:INFO:               skopt: Not installed
2022-09-28 11:39:39,102:INFO:              mlflow: Not installed
2022-09-28 11:39:39,102:INFO:              gradio: Not installed
2022-09-28 11:39:39,102:INFO:             fastapi: Not installed
2022-09-28 11:39:39,102:INFO:             uvicorn: Not installed
2022-09-28 11:39:39,102:INFO:              m2cgen: Not installed
2022-09-28 11:39:39,102:INFO:           evidently: Not installed
2022-09-28 11:39:39,102:INFO:                nltk: Not installed
2022-09-28 11:39:39,102:INFO:            pyLDAvis: Not installed
2022-09-28 11:39:39,102:INFO:              gensim: Not installed
2022-09-28 11:39:39,102:INFO:               spacy: Not installed
2022-09-28 11:39:39,102:INFO:           wordcloud: Not installed
2022-09-28 11:39:39,102:INFO:            textblob: Not installed
2022-09-28 11:39:39,102:INFO:               fugue: Not installed
2022-09-28 11:39:39,102:INFO:           streamlit: Not installed
2022-09-28 11:39:39,102:INFO:             prophet: Not installed
2022-09-28 11:39:39,102:INFO:None
2022-09-28 11:39:39,102:INFO:Set up data.
2022-09-28 11:39:39,105:INFO:Set up train/test split.
2022-09-28 11:39:39,106:INFO:Set up index.
2022-09-28 11:39:39,106:INFO:Set up folding strategy.
2022-09-28 11:39:39,106:INFO:Assigning column types.
2022-09-28 11:39:39,107:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-09-28 11:39:39,107:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,109:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,111:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,135:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,154:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,154:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:39:39,167:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:39:39,167:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,169:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,171:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,195:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,213:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,214:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:39:39,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:39:39,215:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-09-28 11:39:39,217:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,218:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,242:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,261:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,261:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:39:39,262:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:39:39,264:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,267:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,291:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,310:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,310:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:39:39,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:39:39,311:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-09-28 11:39:39,315:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,339:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,358:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,358:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:39:39,359:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:39:39,363:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,387:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,405:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,406:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:39:39,407:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:39:39,407:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-09-28 11:39:39,434:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,453:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,453:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:39:39,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:39:39,481:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,500:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,501:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:39:39,502:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:39:39,502:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-09-28 11:39:39,530:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,548:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:39:39,549:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:39:39,577:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-28 11:39:39,595:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:39:39,597:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:39:39,597:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-09-28 11:39:39,645:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:39:39,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:39:39,693:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:39:39,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:39:39,695:INFO:Preparing preprocessing pipeline...
2022-09-28 11:39:39,695:INFO:Set up simple imputation.
2022-09-28 11:39:39,695:INFO:Set up variance threshold.
2022-09-28 11:39:39,704:INFO:Finished creating preprocessing pipeline.
2022-09-28 11:39:39,706:INFO:Pipeline: Pipeline(memory=Memory(location=/var/folders/67/hmlyjz1x4x7b_71cqk6bxrg00000gq/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demand_point_index',
                                             'x_coordinate', 'y_coordinate',
                                             '2010', '2011', '2012', '2013',
                                             '2014', '2015', '2016', '2017'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-09-28 11:39:39,706:INFO:Creating final display dataframe.
2022-09-28 11:39:39,748:INFO:Setup display_container:                Description             Value
0               Session id               123
1                   Target              2018
2              Target type        Regression
3               Data shape        (4096, 12)
4         Train data shape        (2867, 12)
5          Test data shape        (1229, 12)
6         Numeric features                11
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              dd5f
2022-09-28 11:39:39,798:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:39:39,799:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:39:39,846:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-28 11:39:39,847:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-28 11:39:39,849:INFO:setup() successfully completed in 0.75s...............
2022-09-28 11:39:39,851:INFO:Initializing compare_models()
2022-09-28 11:39:39,851:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-09-28 11:39:39,851:INFO:Checking exceptions
2022-09-28 11:39:39,852:INFO:Preparing display monitor
2022-09-28 11:39:39,868:INFO:Initializing Linear Regression
2022-09-28 11:39:39,868:INFO:Total runtime is 2.447764078776042e-06 minutes
2022-09-28 11:39:39,870:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:39,870:INFO:Initializing create_model()
2022-09-28 11:39:39,870:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:39,870:INFO:Checking exceptions
2022-09-28 11:39:39,872:INFO:Importing libraries
2022-09-28 11:39:39,872:INFO:Copying training dataset
2022-09-28 11:39:39,873:INFO:Defining folds
2022-09-28 11:39:39,873:INFO:Declaring metric variables
2022-09-28 11:39:39,875:INFO:Importing untrained model
2022-09-28 11:39:39,876:INFO:Linear Regression Imported successfully
2022-09-28 11:39:39,878:INFO:Starting cross validation
2022-09-28 11:39:39,879:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:41,372:INFO:Calculating mean and std
2022-09-28 11:39:41,382:INFO:Creating metrics dataframe
2022-09-28 11:39:41,385:INFO:Uploading results into container
2022-09-28 11:39:41,386:INFO:Uploading model into container now
2022-09-28 11:39:41,386:INFO:master_model_container: 1
2022-09-28 11:39:41,386:INFO:display_container: 2
2022-09-28 11:39:41,386:INFO:LinearRegression(n_jobs=-1)
2022-09-28 11:39:41,386:INFO:create_model() successfully completed......................................
2022-09-28 11:39:41,470:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:41,470:INFO:Creating metrics dataframe
2022-09-28 11:39:41,474:INFO:Initializing Lasso Regression
2022-09-28 11:39:41,474:INFO:Total runtime is 0.026767083009084064 minutes
2022-09-28 11:39:41,476:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:41,476:INFO:Initializing create_model()
2022-09-28 11:39:41,476:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:41,476:INFO:Checking exceptions
2022-09-28 11:39:41,477:INFO:Importing libraries
2022-09-28 11:39:41,477:INFO:Copying training dataset
2022-09-28 11:39:41,479:INFO:Defining folds
2022-09-28 11:39:41,479:INFO:Declaring metric variables
2022-09-28 11:39:41,481:INFO:Importing untrained model
2022-09-28 11:39:41,482:INFO:Lasso Regression Imported successfully
2022-09-28 11:39:41,485:INFO:Starting cross validation
2022-09-28 11:39:41,485:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:41,539:INFO:Calculating mean and std
2022-09-28 11:39:41,539:INFO:Creating metrics dataframe
2022-09-28 11:39:41,541:INFO:Uploading results into container
2022-09-28 11:39:41,541:INFO:Uploading model into container now
2022-09-28 11:39:41,541:INFO:master_model_container: 2
2022-09-28 11:39:41,541:INFO:display_container: 2
2022-09-28 11:39:41,541:INFO:Lasso(random_state=123)
2022-09-28 11:39:41,541:INFO:create_model() successfully completed......................................
2022-09-28 11:39:41,597:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:41,597:INFO:Creating metrics dataframe
2022-09-28 11:39:41,600:INFO:Initializing Ridge Regression
2022-09-28 11:39:41,601:INFO:Total runtime is 0.02887086470921834 minutes
2022-09-28 11:39:41,602:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:41,602:INFO:Initializing create_model()
2022-09-28 11:39:41,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:41,602:INFO:Checking exceptions
2022-09-28 11:39:41,604:INFO:Importing libraries
2022-09-28 11:39:41,604:INFO:Copying training dataset
2022-09-28 11:39:41,605:INFO:Defining folds
2022-09-28 11:39:41,606:INFO:Declaring metric variables
2022-09-28 11:39:41,607:INFO:Importing untrained model
2022-09-28 11:39:41,609:INFO:Ridge Regression Imported successfully
2022-09-28 11:39:41,611:INFO:Starting cross validation
2022-09-28 11:39:41,612:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:41,658:INFO:Calculating mean and std
2022-09-28 11:39:41,658:INFO:Creating metrics dataframe
2022-09-28 11:39:41,659:INFO:Uploading results into container
2022-09-28 11:39:41,659:INFO:Uploading model into container now
2022-09-28 11:39:41,660:INFO:master_model_container: 3
2022-09-28 11:39:41,660:INFO:display_container: 2
2022-09-28 11:39:41,660:INFO:Ridge(random_state=123)
2022-09-28 11:39:41,660:INFO:create_model() successfully completed......................................
2022-09-28 11:39:41,715:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:41,715:INFO:Creating metrics dataframe
2022-09-28 11:39:41,719:INFO:Initializing Elastic Net
2022-09-28 11:39:41,719:INFO:Total runtime is 0.030845681826273598 minutes
2022-09-28 11:39:41,720:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:41,721:INFO:Initializing create_model()
2022-09-28 11:39:41,721:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:41,721:INFO:Checking exceptions
2022-09-28 11:39:41,722:INFO:Importing libraries
2022-09-28 11:39:41,722:INFO:Copying training dataset
2022-09-28 11:39:41,723:INFO:Defining folds
2022-09-28 11:39:41,723:INFO:Declaring metric variables
2022-09-28 11:39:41,725:INFO:Importing untrained model
2022-09-28 11:39:41,726:INFO:Elastic Net Imported successfully
2022-09-28 11:39:41,728:INFO:Starting cross validation
2022-09-28 11:39:41,729:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:41,784:INFO:Calculating mean and std
2022-09-28 11:39:41,785:INFO:Creating metrics dataframe
2022-09-28 11:39:41,786:INFO:Uploading results into container
2022-09-28 11:39:41,786:INFO:Uploading model into container now
2022-09-28 11:39:41,786:INFO:master_model_container: 4
2022-09-28 11:39:41,786:INFO:display_container: 2
2022-09-28 11:39:41,786:INFO:ElasticNet(random_state=123)
2022-09-28 11:39:41,786:INFO:create_model() successfully completed......................................
2022-09-28 11:39:41,842:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:41,842:INFO:Creating metrics dataframe
2022-09-28 11:39:41,846:INFO:Initializing Least Angle Regression
2022-09-28 11:39:41,846:INFO:Total runtime is 0.03296206394831339 minutes
2022-09-28 11:39:41,847:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:41,848:INFO:Initializing create_model()
2022-09-28 11:39:41,848:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:41,848:INFO:Checking exceptions
2022-09-28 11:39:41,849:INFO:Importing libraries
2022-09-28 11:39:41,849:INFO:Copying training dataset
2022-09-28 11:39:41,850:INFO:Defining folds
2022-09-28 11:39:41,850:INFO:Declaring metric variables
2022-09-28 11:39:41,852:INFO:Importing untrained model
2022-09-28 11:39:41,853:INFO:Least Angle Regression Imported successfully
2022-09-28 11:39:41,855:INFO:Starting cross validation
2022-09-28 11:39:41,856:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:41,872:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:41,875:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:41,877:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:41,879:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:41,882:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:41,884:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:41,885:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:41,888:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:41,890:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:41,892:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:41,897:INFO:Calculating mean and std
2022-09-28 11:39:41,898:INFO:Creating metrics dataframe
2022-09-28 11:39:41,899:INFO:Uploading results into container
2022-09-28 11:39:41,899:INFO:Uploading model into container now
2022-09-28 11:39:41,899:INFO:master_model_container: 5
2022-09-28 11:39:41,899:INFO:display_container: 2
2022-09-28 11:39:41,899:INFO:Lars(random_state=123)
2022-09-28 11:39:41,899:INFO:create_model() successfully completed......................................
2022-09-28 11:39:41,955:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:41,955:INFO:Creating metrics dataframe
2022-09-28 11:39:41,960:INFO:Initializing Lasso Least Angle Regression
2022-09-28 11:39:41,960:INFO:Total runtime is 0.034855695565541585 minutes
2022-09-28 11:39:41,961:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:41,961:INFO:Initializing create_model()
2022-09-28 11:39:41,961:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:41,961:INFO:Checking exceptions
2022-09-28 11:39:41,962:INFO:Importing libraries
2022-09-28 11:39:41,962:INFO:Copying training dataset
2022-09-28 11:39:41,964:INFO:Defining folds
2022-09-28 11:39:41,964:INFO:Declaring metric variables
2022-09-28 11:39:41,965:INFO:Importing untrained model
2022-09-28 11:39:41,967:INFO:Lasso Least Angle Regression Imported successfully
2022-09-28 11:39:41,970:INFO:Starting cross validation
2022-09-28 11:39:41,971:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:41,985:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:39:41,993:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:39:41,995:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:39:41,999:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:39:42,002:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:39:42,004:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:39:42,007:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:39:42,009:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:39:42,012:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:39:42,015:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-28 11:39:42,019:INFO:Calculating mean and std
2022-09-28 11:39:42,020:INFO:Creating metrics dataframe
2022-09-28 11:39:42,021:INFO:Uploading results into container
2022-09-28 11:39:42,021:INFO:Uploading model into container now
2022-09-28 11:39:42,021:INFO:master_model_container: 6
2022-09-28 11:39:42,021:INFO:display_container: 2
2022-09-28 11:39:42,021:INFO:LassoLars(random_state=123)
2022-09-28 11:39:42,021:INFO:create_model() successfully completed......................................
2022-09-28 11:39:42,075:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:42,075:INFO:Creating metrics dataframe
2022-09-28 11:39:42,079:INFO:Initializing Orthogonal Matching Pursuit
2022-09-28 11:39:42,079:INFO:Total runtime is 0.03685166438420614 minutes
2022-09-28 11:39:42,081:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:42,081:INFO:Initializing create_model()
2022-09-28 11:39:42,081:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:42,081:INFO:Checking exceptions
2022-09-28 11:39:42,082:INFO:Importing libraries
2022-09-28 11:39:42,082:INFO:Copying training dataset
2022-09-28 11:39:42,084:INFO:Defining folds
2022-09-28 11:39:42,084:INFO:Declaring metric variables
2022-09-28 11:39:42,086:INFO:Importing untrained model
2022-09-28 11:39:42,087:INFO:Orthogonal Matching Pursuit Imported successfully
2022-09-28 11:39:42,090:INFO:Starting cross validation
2022-09-28 11:39:42,090:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:42,103:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:42,109:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:42,111:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:42,115:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:42,117:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:42,120:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:42,123:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:42,126:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:42,128:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:42,129:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-28 11:39:42,135:INFO:Calculating mean and std
2022-09-28 11:39:42,135:INFO:Creating metrics dataframe
2022-09-28 11:39:42,136:INFO:Uploading results into container
2022-09-28 11:39:42,136:INFO:Uploading model into container now
2022-09-28 11:39:42,136:INFO:master_model_container: 7
2022-09-28 11:39:42,136:INFO:display_container: 2
2022-09-28 11:39:42,136:INFO:OrthogonalMatchingPursuit()
2022-09-28 11:39:42,137:INFO:create_model() successfully completed......................................
2022-09-28 11:39:42,192:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:42,192:INFO:Creating metrics dataframe
2022-09-28 11:39:42,196:INFO:Initializing Bayesian Ridge
2022-09-28 11:39:42,196:INFO:Total runtime is 0.03880000114440918 minutes
2022-09-28 11:39:42,198:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:42,198:INFO:Initializing create_model()
2022-09-28 11:39:42,198:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:42,198:INFO:Checking exceptions
2022-09-28 11:39:42,199:INFO:Importing libraries
2022-09-28 11:39:42,199:INFO:Copying training dataset
2022-09-28 11:39:42,201:INFO:Defining folds
2022-09-28 11:39:42,201:INFO:Declaring metric variables
2022-09-28 11:39:42,202:INFO:Importing untrained model
2022-09-28 11:39:42,204:INFO:Bayesian Ridge Imported successfully
2022-09-28 11:39:42,208:INFO:Starting cross validation
2022-09-28 11:39:42,208:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:42,253:INFO:Calculating mean and std
2022-09-28 11:39:42,254:INFO:Creating metrics dataframe
2022-09-28 11:39:42,255:INFO:Uploading results into container
2022-09-28 11:39:42,255:INFO:Uploading model into container now
2022-09-28 11:39:42,255:INFO:master_model_container: 8
2022-09-28 11:39:42,255:INFO:display_container: 2
2022-09-28 11:39:42,255:INFO:BayesianRidge()
2022-09-28 11:39:42,255:INFO:create_model() successfully completed......................................
2022-09-28 11:39:42,311:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:42,311:INFO:Creating metrics dataframe
2022-09-28 11:39:42,316:INFO:Initializing Passive Aggressive Regressor
2022-09-28 11:39:42,316:INFO:Total runtime is 0.0407901128133138 minutes
2022-09-28 11:39:42,317:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:42,317:INFO:Initializing create_model()
2022-09-28 11:39:42,317:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:42,317:INFO:Checking exceptions
2022-09-28 11:39:42,318:INFO:Importing libraries
2022-09-28 11:39:42,318:INFO:Copying training dataset
2022-09-28 11:39:42,320:INFO:Defining folds
2022-09-28 11:39:42,320:INFO:Declaring metric variables
2022-09-28 11:39:42,321:INFO:Importing untrained model
2022-09-28 11:39:42,323:INFO:Passive Aggressive Regressor Imported successfully
2022-09-28 11:39:42,325:INFO:Starting cross validation
2022-09-28 11:39:42,325:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:42,367:INFO:Calculating mean and std
2022-09-28 11:39:42,367:INFO:Creating metrics dataframe
2022-09-28 11:39:42,369:INFO:Uploading results into container
2022-09-28 11:39:42,369:INFO:Uploading model into container now
2022-09-28 11:39:42,369:INFO:master_model_container: 9
2022-09-28 11:39:42,369:INFO:display_container: 2
2022-09-28 11:39:42,369:INFO:PassiveAggressiveRegressor(random_state=123)
2022-09-28 11:39:42,369:INFO:create_model() successfully completed......................................
2022-09-28 11:39:42,425:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:42,425:INFO:Creating metrics dataframe
2022-09-28 11:39:42,429:INFO:Initializing Huber Regressor
2022-09-28 11:39:42,429:INFO:Total runtime is 0.042681713898976646 minutes
2022-09-28 11:39:42,431:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:42,431:INFO:Initializing create_model()
2022-09-28 11:39:42,431:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:42,431:INFO:Checking exceptions
2022-09-28 11:39:42,432:INFO:Importing libraries
2022-09-28 11:39:42,432:INFO:Copying training dataset
2022-09-28 11:39:42,433:INFO:Defining folds
2022-09-28 11:39:42,434:INFO:Declaring metric variables
2022-09-28 11:39:42,435:INFO:Importing untrained model
2022-09-28 11:39:42,436:INFO:Huber Regressor Imported successfully
2022-09-28 11:39:42,439:INFO:Starting cross validation
2022-09-28 11:39:42,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:42,478:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:39:42,478:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:39:42,483:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:39:42,485:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:39:42,486:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:39:42,489:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:39:42,496:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:39:42,507:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:39:42,513:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:39:42,515:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-28 11:39:42,520:INFO:Calculating mean and std
2022-09-28 11:39:42,520:INFO:Creating metrics dataframe
2022-09-28 11:39:42,521:INFO:Uploading results into container
2022-09-28 11:39:42,521:INFO:Uploading model into container now
2022-09-28 11:39:42,521:INFO:master_model_container: 10
2022-09-28 11:39:42,521:INFO:display_container: 2
2022-09-28 11:39:42,522:INFO:HuberRegressor()
2022-09-28 11:39:42,522:INFO:create_model() successfully completed......................................
2022-09-28 11:39:42,577:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:42,577:INFO:Creating metrics dataframe
2022-09-28 11:39:42,581:INFO:Initializing K Neighbors Regressor
2022-09-28 11:39:42,581:INFO:Total runtime is 0.04521830081939698 minutes
2022-09-28 11:39:42,583:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:42,583:INFO:Initializing create_model()
2022-09-28 11:39:42,583:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:42,583:INFO:Checking exceptions
2022-09-28 11:39:42,584:INFO:Importing libraries
2022-09-28 11:39:42,584:INFO:Copying training dataset
2022-09-28 11:39:42,586:INFO:Defining folds
2022-09-28 11:39:42,586:INFO:Declaring metric variables
2022-09-28 11:39:42,587:INFO:Importing untrained model
2022-09-28 11:39:42,588:INFO:K Neighbors Regressor Imported successfully
2022-09-28 11:39:42,591:INFO:Starting cross validation
2022-09-28 11:39:42,591:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:42,641:INFO:Calculating mean and std
2022-09-28 11:39:42,642:INFO:Creating metrics dataframe
2022-09-28 11:39:42,643:INFO:Uploading results into container
2022-09-28 11:39:42,643:INFO:Uploading model into container now
2022-09-28 11:39:42,643:INFO:master_model_container: 11
2022-09-28 11:39:42,643:INFO:display_container: 2
2022-09-28 11:39:42,643:INFO:KNeighborsRegressor(n_jobs=-1)
2022-09-28 11:39:42,643:INFO:create_model() successfully completed......................................
2022-09-28 11:39:42,699:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:42,699:INFO:Creating metrics dataframe
2022-09-28 11:39:42,704:INFO:Initializing Decision Tree Regressor
2022-09-28 11:39:42,704:INFO:Total runtime is 0.0472565491994222 minutes
2022-09-28 11:39:42,705:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:42,705:INFO:Initializing create_model()
2022-09-28 11:39:42,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:42,705:INFO:Checking exceptions
2022-09-28 11:39:42,706:INFO:Importing libraries
2022-09-28 11:39:42,706:INFO:Copying training dataset
2022-09-28 11:39:42,708:INFO:Defining folds
2022-09-28 11:39:42,708:INFO:Declaring metric variables
2022-09-28 11:39:42,709:INFO:Importing untrained model
2022-09-28 11:39:42,711:INFO:Decision Tree Regressor Imported successfully
2022-09-28 11:39:42,714:INFO:Starting cross validation
2022-09-28 11:39:42,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:42,784:INFO:Calculating mean and std
2022-09-28 11:39:42,784:INFO:Creating metrics dataframe
2022-09-28 11:39:42,785:INFO:Uploading results into container
2022-09-28 11:39:42,785:INFO:Uploading model into container now
2022-09-28 11:39:42,785:INFO:master_model_container: 12
2022-09-28 11:39:42,785:INFO:display_container: 2
2022-09-28 11:39:42,786:INFO:DecisionTreeRegressor(random_state=123)
2022-09-28 11:39:42,786:INFO:create_model() successfully completed......................................
2022-09-28 11:39:42,840:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:42,840:INFO:Creating metrics dataframe
2022-09-28 11:39:42,845:INFO:Initializing Random Forest Regressor
2022-09-28 11:39:42,845:INFO:Total runtime is 0.049612398942311606 minutes
2022-09-28 11:39:42,846:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:42,847:INFO:Initializing create_model()
2022-09-28 11:39:42,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:42,847:INFO:Checking exceptions
2022-09-28 11:39:42,848:INFO:Importing libraries
2022-09-28 11:39:42,848:INFO:Copying training dataset
2022-09-28 11:39:42,849:INFO:Defining folds
2022-09-28 11:39:42,849:INFO:Declaring metric variables
2022-09-28 11:39:42,850:INFO:Importing untrained model
2022-09-28 11:39:42,852:INFO:Random Forest Regressor Imported successfully
2022-09-28 11:39:42,854:INFO:Starting cross validation
2022-09-28 11:39:42,855:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:43,968:INFO:Calculating mean and std
2022-09-28 11:39:43,968:INFO:Creating metrics dataframe
2022-09-28 11:39:43,970:INFO:Uploading results into container
2022-09-28 11:39:43,970:INFO:Uploading model into container now
2022-09-28 11:39:43,970:INFO:master_model_container: 13
2022-09-28 11:39:43,970:INFO:display_container: 2
2022-09-28 11:39:43,970:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:39:43,970:INFO:create_model() successfully completed......................................
2022-09-28 11:39:44,026:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:44,026:INFO:Creating metrics dataframe
2022-09-28 11:39:44,032:INFO:Initializing Extra Trees Regressor
2022-09-28 11:39:44,032:INFO:Total runtime is 0.06938831806182862 minutes
2022-09-28 11:39:44,033:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:44,033:INFO:Initializing create_model()
2022-09-28 11:39:44,033:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:44,033:INFO:Checking exceptions
2022-09-28 11:39:44,034:INFO:Importing libraries
2022-09-28 11:39:44,034:INFO:Copying training dataset
2022-09-28 11:39:44,036:INFO:Defining folds
2022-09-28 11:39:44,036:INFO:Declaring metric variables
2022-09-28 11:39:44,038:INFO:Importing untrained model
2022-09-28 11:39:44,039:INFO:Extra Trees Regressor Imported successfully
2022-09-28 11:39:44,041:INFO:Starting cross validation
2022-09-28 11:39:44,042:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:44,606:INFO:Calculating mean and std
2022-09-28 11:39:44,606:INFO:Creating metrics dataframe
2022-09-28 11:39:44,609:INFO:Uploading results into container
2022-09-28 11:39:44,609:INFO:Uploading model into container now
2022-09-28 11:39:44,610:INFO:master_model_container: 14
2022-09-28 11:39:44,610:INFO:display_container: 2
2022-09-28 11:39:44,610:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:39:44,610:INFO:create_model() successfully completed......................................
2022-09-28 11:39:44,673:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:44,673:INFO:Creating metrics dataframe
2022-09-28 11:39:44,678:INFO:Initializing AdaBoost Regressor
2022-09-28 11:39:44,679:INFO:Total runtime is 0.08016990025838217 minutes
2022-09-28 11:39:44,680:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:44,680:INFO:Initializing create_model()
2022-09-28 11:39:44,680:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:44,680:INFO:Checking exceptions
2022-09-28 11:39:44,681:INFO:Importing libraries
2022-09-28 11:39:44,681:INFO:Copying training dataset
2022-09-28 11:39:44,682:INFO:Defining folds
2022-09-28 11:39:44,682:INFO:Declaring metric variables
2022-09-28 11:39:44,683:INFO:Importing untrained model
2022-09-28 11:39:44,685:INFO:AdaBoost Regressor Imported successfully
2022-09-28 11:39:44,687:INFO:Starting cross validation
2022-09-28 11:39:44,688:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:44,928:INFO:Calculating mean and std
2022-09-28 11:39:44,929:INFO:Creating metrics dataframe
2022-09-28 11:39:44,930:INFO:Uploading results into container
2022-09-28 11:39:44,930:INFO:Uploading model into container now
2022-09-28 11:39:44,931:INFO:master_model_container: 15
2022-09-28 11:39:44,931:INFO:display_container: 2
2022-09-28 11:39:44,931:INFO:AdaBoostRegressor(random_state=123)
2022-09-28 11:39:44,931:INFO:create_model() successfully completed......................................
2022-09-28 11:39:44,986:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:44,986:INFO:Creating metrics dataframe
2022-09-28 11:39:44,991:INFO:Initializing Gradient Boosting Regressor
2022-09-28 11:39:44,991:INFO:Total runtime is 0.08537526528040569 minutes
2022-09-28 11:39:44,992:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:44,992:INFO:Initializing create_model()
2022-09-28 11:39:44,992:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:44,992:INFO:Checking exceptions
2022-09-28 11:39:44,993:INFO:Importing libraries
2022-09-28 11:39:44,994:INFO:Copying training dataset
2022-09-28 11:39:44,994:INFO:Defining folds
2022-09-28 11:39:44,994:INFO:Declaring metric variables
2022-09-28 11:39:44,996:INFO:Importing untrained model
2022-09-28 11:39:44,997:INFO:Gradient Boosting Regressor Imported successfully
2022-09-28 11:39:45,000:INFO:Starting cross validation
2022-09-28 11:39:45,000:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:45,580:INFO:Calculating mean and std
2022-09-28 11:39:45,581:INFO:Creating metrics dataframe
2022-09-28 11:39:45,583:INFO:Uploading results into container
2022-09-28 11:39:45,583:INFO:Uploading model into container now
2022-09-28 11:39:45,583:INFO:master_model_container: 16
2022-09-28 11:39:45,583:INFO:display_container: 2
2022-09-28 11:39:45,583:INFO:GradientBoostingRegressor(random_state=123)
2022-09-28 11:39:45,583:INFO:create_model() successfully completed......................................
2022-09-28 11:39:45,639:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:45,639:INFO:Creating metrics dataframe
2022-09-28 11:39:45,644:INFO:Initializing Extreme Gradient Boosting
2022-09-28 11:39:45,644:INFO:Total runtime is 0.09626786708831789 minutes
2022-09-28 11:39:45,646:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:45,646:INFO:Initializing create_model()
2022-09-28 11:39:45,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:45,646:INFO:Checking exceptions
2022-09-28 11:39:45,647:INFO:Importing libraries
2022-09-28 11:39:45,647:INFO:Copying training dataset
2022-09-28 11:39:45,648:INFO:Defining folds
2022-09-28 11:39:45,648:INFO:Declaring metric variables
2022-09-28 11:39:45,649:INFO:Importing untrained model
2022-09-28 11:39:45,651:INFO:Extreme Gradient Boosting Imported successfully
2022-09-28 11:39:45,653:INFO:Starting cross validation
2022-09-28 11:39:45,653:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:46,108:INFO:Calculating mean and std
2022-09-28 11:39:46,109:INFO:Creating metrics dataframe
2022-09-28 11:39:46,110:INFO:Uploading results into container
2022-09-28 11:39:46,111:INFO:Uploading model into container now
2022-09-28 11:39:46,111:INFO:master_model_container: 17
2022-09-28 11:39:46,111:INFO:display_container: 2
2022-09-28 11:39:46,111:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=123,
             reg_alpha=None, reg_lambda=None, ...)
2022-09-28 11:39:46,112:INFO:create_model() successfully completed......................................
2022-09-28 11:39:46,167:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:46,167:INFO:Creating metrics dataframe
2022-09-28 11:39:46,172:INFO:Initializing Light Gradient Boosting Machine
2022-09-28 11:39:46,173:INFO:Total runtime is 0.10507059892018637 minutes
2022-09-28 11:39:46,174:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:46,174:INFO:Initializing create_model()
2022-09-28 11:39:46,174:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:46,174:INFO:Checking exceptions
2022-09-28 11:39:46,175:INFO:Importing libraries
2022-09-28 11:39:46,175:INFO:Copying training dataset
2022-09-28 11:39:46,176:INFO:Defining folds
2022-09-28 11:39:46,176:INFO:Declaring metric variables
2022-09-28 11:39:46,178:INFO:Importing untrained model
2022-09-28 11:39:46,180:INFO:Light Gradient Boosting Machine Imported successfully
2022-09-28 11:39:46,185:INFO:Starting cross validation
2022-09-28 11:39:46,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:46,327:INFO:Calculating mean and std
2022-09-28 11:39:46,328:INFO:Creating metrics dataframe
2022-09-28 11:39:46,329:INFO:Uploading results into container
2022-09-28 11:39:46,329:INFO:Uploading model into container now
2022-09-28 11:39:46,330:INFO:master_model_container: 18
2022-09-28 11:39:46,330:INFO:display_container: 2
2022-09-28 11:39:46,330:INFO:LGBMRegressor(random_state=123)
2022-09-28 11:39:46,330:INFO:create_model() successfully completed......................................
2022-09-28 11:39:46,386:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:46,386:INFO:Creating metrics dataframe
2022-09-28 11:39:46,391:INFO:Initializing Dummy Regressor
2022-09-28 11:39:46,391:INFO:Total runtime is 0.10871771574020386 minutes
2022-09-28 11:39:46,393:INFO:SubProcess create_model() called ==================================
2022-09-28 11:39:46,393:INFO:Initializing create_model()
2022-09-28 11:39:46,393:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2a0952800>, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:46,393:INFO:Checking exceptions
2022-09-28 11:39:46,394:INFO:Importing libraries
2022-09-28 11:39:46,394:INFO:Copying training dataset
2022-09-28 11:39:46,395:INFO:Defining folds
2022-09-28 11:39:46,395:INFO:Declaring metric variables
2022-09-28 11:39:46,396:INFO:Importing untrained model
2022-09-28 11:39:46,398:INFO:Dummy Regressor Imported successfully
2022-09-28 11:39:46,400:INFO:Starting cross validation
2022-09-28 11:39:46,401:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:39:46,439:INFO:Calculating mean and std
2022-09-28 11:39:46,440:INFO:Creating metrics dataframe
2022-09-28 11:39:46,441:INFO:Uploading results into container
2022-09-28 11:39:46,441:INFO:Uploading model into container now
2022-09-28 11:39:46,441:INFO:master_model_container: 19
2022-09-28 11:39:46,442:INFO:display_container: 2
2022-09-28 11:39:46,442:INFO:DummyRegressor()
2022-09-28 11:39:46,442:INFO:create_model() successfully completed......................................
2022-09-28 11:39:46,497:INFO:SubProcess create_model() end ==================================
2022-09-28 11:39:46,497:INFO:Creating metrics dataframe
2022-09-28 11:39:46,506:INFO:Initializing create_model()
2022-09-28 11:39:46,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:39:46,506:INFO:Checking exceptions
2022-09-28 11:39:46,508:INFO:Importing libraries
2022-09-28 11:39:46,508:INFO:Copying training dataset
2022-09-28 11:39:46,510:INFO:Defining folds
2022-09-28 11:39:46,510:INFO:Declaring metric variables
2022-09-28 11:39:46,510:INFO:Importing untrained model
2022-09-28 11:39:46,510:INFO:Declaring custom model
2022-09-28 11:39:46,510:INFO:Extra Trees Regressor Imported successfully
2022-09-28 11:39:46,510:INFO:Cross validation set to False
2022-09-28 11:39:46,510:INFO:Fitting Model
2022-09-28 11:39:46,605:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:39:46,605:INFO:create_model() successfully completed......................................
2022-09-28 11:39:46,673:INFO:master_model_container: 19
2022-09-28 11:39:46,674:INFO:display_container: 2
2022-09-28 11:39:46,674:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:39:46,674:INFO:compare_models() successfully completed......................................
2022-09-28 11:43:30,152:INFO:Initializing create_model()
2022-09-28 11:43:30,153:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:43:30,153:INFO:Checking exceptions
2022-09-28 11:43:30,181:INFO:Importing libraries
2022-09-28 11:43:30,181:INFO:Copying training dataset
2022-09-28 11:43:30,184:INFO:Defining folds
2022-09-28 11:43:30,184:INFO:Declaring metric variables
2022-09-28 11:43:30,186:INFO:Importing untrained model
2022-09-28 11:43:30,188:INFO:Extra Trees Regressor Imported successfully
2022-09-28 11:43:30,191:INFO:Starting cross validation
2022-09-28 11:43:30,192:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:43:30,772:INFO:Calculating mean and std
2022-09-28 11:43:30,773:INFO:Creating metrics dataframe
2022-09-28 11:43:30,775:INFO:Finalizing model
2022-09-28 11:43:30,869:INFO:Uploading results into container
2022-09-28 11:43:30,869:INFO:Uploading model into container now
2022-09-28 11:43:30,873:INFO:master_model_container: 20
2022-09-28 11:43:30,873:INFO:display_container: 3
2022-09-28 11:43:30,873:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:43:30,873:INFO:create_model() successfully completed......................................
2022-09-28 11:43:54,407:INFO:Initializing tune_model()
2022-09-28 11:43:54,407:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>)
2022-09-28 11:43:54,407:INFO:Checking exceptions
2022-09-28 11:43:54,438:INFO:Copying training dataset
2022-09-28 11:43:54,441:INFO:Checking base model
2022-09-28 11:43:54,441:INFO:Base model : Extra Trees Regressor
2022-09-28 11:43:54,443:INFO:Declaring metric variables
2022-09-28 11:43:54,446:INFO:Defining Hyperparameters
2022-09-28 11:43:54,504:INFO:Tuning with n_jobs=-1
2022-09-28 11:43:54,504:INFO:Initializing RandomizedSearchCV
2022-09-28 11:43:54,524:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,526:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,535:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,537:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,546:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,548:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,552:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,565:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,576:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,603:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,705:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,713:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,715:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,719:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,723:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,728:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,728:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,761:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,766:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,857:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,877:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,880:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,886:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,899:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,907:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,910:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,910:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,938:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:54,943:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,090:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,127:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,148:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,161:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,172:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,214:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,282:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,284:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,294:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,326:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,328:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,331:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,342:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,349:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,356:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,597:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,617:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,631:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,637:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,640:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,709:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,754:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,813:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,819:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:43:55,903:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:43:56,200:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:56,339:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:56,369:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:56,409:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:56,418:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:56,892:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:56,895:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:56,961:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:57,020:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:57,088:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:57,297:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:57,309:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:57,311:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:57,318:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:57,463:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:57,858:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:57,859:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:57,882:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:57,938:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:58,091:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:58,441:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:43:58,538:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:43:58,540:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:43:58,601:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:43:58,654:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:43:58,970:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:44:00,325:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:44:00,574:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:44:00,598:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:44:01,101:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:44:01,351:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:44:06,160:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:44:06,327:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:44:06,402:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:44:06,409:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:44:06,644:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:44:07,104:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:07,193:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:07,289:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:07,349:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:07,560:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:07,598:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:07,603:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:07,779:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:07,897:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:08,119:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:10,929:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'mse', 'actual_estimator__bootstrap': True}
2022-09-28 11:44:10,929:INFO:Hyperparameter search completed
2022-09-28 11:44:10,929:INFO:SubProcess create_model() called ==================================
2022-09-28 11:44:10,930:INFO:Initializing create_model()
2022-09-28 11:44:10,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17fac5e40>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'mse', 'bootstrap': True})
2022-09-28 11:44:10,930:INFO:Checking exceptions
2022-09-28 11:44:10,931:INFO:Importing libraries
2022-09-28 11:44:10,931:INFO:Copying training dataset
2022-09-28 11:44:10,932:INFO:Defining folds
2022-09-28 11:44:10,932:INFO:Declaring metric variables
2022-09-28 11:44:10,934:INFO:Importing untrained model
2022-09-28 11:44:10,934:INFO:Declaring custom model
2022-09-28 11:44:10,936:INFO:Extra Trees Regressor Imported successfully
2022-09-28 11:44:10,939:INFO:Starting cross validation
2022-09-28 11:44:10,940:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:44:10,959:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:10,962:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:10,971:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:10,975:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:10,984:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:10,985:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:10,994:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:10,999:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:11,012:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:11,020:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:11,216:INFO:Calculating mean and std
2022-09-28 11:44:11,217:INFO:Creating metrics dataframe
2022-09-28 11:44:11,219:INFO:Finalizing model
2022-09-28 11:44:11,229:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:44:11,307:INFO:Uploading results into container
2022-09-28 11:44:11,307:INFO:Uploading model into container now
2022-09-28 11:44:11,307:INFO:master_model_container: 21
2022-09-28 11:44:11,307:INFO:display_container: 4
2022-09-28 11:44:11,307:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    min_impurity_decrease=0.1, min_samples_leaf=4,
                    min_samples_split=7, n_jobs=-1, random_state=123)
2022-09-28 11:44:11,307:INFO:create_model() successfully completed......................................
2022-09-28 11:44:11,363:INFO:SubProcess create_model() end ==================================
2022-09-28 11:44:11,363:INFO:choose_better activated
2022-09-28 11:44:11,365:INFO:SubProcess create_model() called ==================================
2022-09-28 11:44:11,365:INFO:Initializing create_model()
2022-09-28 11:44:11,365:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:44:11,365:INFO:Checking exceptions
2022-09-28 11:44:11,367:INFO:Importing libraries
2022-09-28 11:44:11,367:INFO:Copying training dataset
2022-09-28 11:44:11,369:INFO:Defining folds
2022-09-28 11:44:11,369:INFO:Declaring metric variables
2022-09-28 11:44:11,369:INFO:Importing untrained model
2022-09-28 11:44:11,369:INFO:Declaring custom model
2022-09-28 11:44:11,369:INFO:Extra Trees Regressor Imported successfully
2022-09-28 11:44:11,369:INFO:Starting cross validation
2022-09-28 11:44:11,369:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:44:11,972:INFO:Calculating mean and std
2022-09-28 11:44:11,973:INFO:Creating metrics dataframe
2022-09-28 11:44:11,974:INFO:Finalizing model
2022-09-28 11:44:12,068:INFO:Uploading results into container
2022-09-28 11:44:12,068:INFO:Uploading model into container now
2022-09-28 11:44:12,069:INFO:master_model_container: 22
2022-09-28 11:44:12,069:INFO:display_container: 5
2022-09-28 11:44:12,069:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:44:12,069:INFO:create_model() successfully completed......................................
2022-09-28 11:44:12,124:INFO:SubProcess create_model() end ==================================
2022-09-28 11:44:12,135:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9897
2022-09-28 11:44:12,135:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    min_impurity_decrease=0.1, min_samples_leaf=4,
                    min_samples_split=7, n_jobs=-1, random_state=123) result for R2 is 0.9898
2022-09-28 11:44:12,138:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    min_impurity_decrease=0.1, min_samples_leaf=4,
                    min_samples_split=7, n_jobs=-1, random_state=123) is best model
2022-09-28 11:44:12,138:INFO:choose_better completed
2022-09-28 11:44:12,142:INFO:master_model_container: 22
2022-09-28 11:44:12,142:INFO:display_container: 4
2022-09-28 11:44:12,142:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    min_impurity_decrease=0.1, min_samples_leaf=4,
                    min_samples_split=7, n_jobs=-1, random_state=123)
2022-09-28 11:44:12,142:INFO:tune_model() successfully completed......................................
2022-09-28 11:46:05,420:INFO:Initializing tune_model()
2022-09-28 11:46:05,421:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>)
2022-09-28 11:46:05,421:INFO:Checking exceptions
2022-09-28 11:46:05,449:INFO:Copying training dataset
2022-09-28 11:46:05,451:INFO:Checking base model
2022-09-28 11:46:05,452:INFO:Base model : Extra Trees Regressor
2022-09-28 11:46:05,454:INFO:Declaring metric variables
2022-09-28 11:46:05,456:INFO:Defining Hyperparameters
2022-09-28 11:46:05,515:INFO:Tuning with n_jobs=-1
2022-09-28 11:46:05,515:INFO:Initializing RandomizedSearchCV
2022-09-28 11:46:05,536:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,537:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,541:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,542:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,544:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,551:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,556:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,563:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,580:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,589:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,724:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,729:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,736:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,740:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,753:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,757:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,764:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,769:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,797:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,803:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,876:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,883:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,895:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,898:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,915:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,931:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,933:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:05,951:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,007:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,034:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,148:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,168:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,182:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,211:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,226:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,228:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,245:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,291:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,310:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,334:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,351:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,360:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,386:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,429:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,552:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,642:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,672:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,672:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,675:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,687:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,687:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,746:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:06,766:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:07,023:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:07,122:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:07,180:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:07,352:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:07,501:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:07,619:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:07,643:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:07,659:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:07,660:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:07,921:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:08,106:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:08,138:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:08,141:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:08,150:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:08,360:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:08,884:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:08,898:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:08,933:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:08,977:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:08,979:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:09,285:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:09,338:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:09,340:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:09,528:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:09,571:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:09,924:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:09,930:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:11,077:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:11,535:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:11,548:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:12,373:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:12,418:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:16,936:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:17,206:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:17,225:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:17,341:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:17,368:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:17,592:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 11:46:17,668:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:17,747:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:17,978:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:18,045:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:18,125:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:18,359:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:18,398:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:18,449:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:18,684:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:21,439:INFO:best_params: {'actual_estimator__n_estimators': 200, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'mse', 'actual_estimator__bootstrap': False}
2022-09-28 11:46:21,440:INFO:Hyperparameter search completed
2022-09-28 11:46:21,440:INFO:SubProcess create_model() called ==================================
2022-09-28 11:46:21,440:INFO:Initializing create_model()
2022-09-28 11:46:21,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1068673a0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 200, 'min_samples_split': 7, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'mse', 'bootstrap': False})
2022-09-28 11:46:21,440:INFO:Checking exceptions
2022-09-28 11:46:21,442:INFO:Importing libraries
2022-09-28 11:46:21,442:INFO:Copying training dataset
2022-09-28 11:46:21,443:INFO:Defining folds
2022-09-28 11:46:21,443:INFO:Declaring metric variables
2022-09-28 11:46:21,444:INFO:Importing untrained model
2022-09-28 11:46:21,444:INFO:Declaring custom model
2022-09-28 11:46:21,446:INFO:Extra Trees Regressor Imported successfully
2022-09-28 11:46:21,448:INFO:Starting cross validation
2022-09-28 11:46:21,449:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:46:21,464:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:21,469:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:21,472:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:21,475:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:21,480:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:21,481:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:21,492:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:21,498:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:21,504:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:21,508:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:21,781:INFO:Calculating mean and std
2022-09-28 11:46:21,782:INFO:Creating metrics dataframe
2022-09-28 11:46:21,785:INFO:Finalizing model
2022-09-28 11:46:21,794:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 11:46:21,908:INFO:Uploading results into container
2022-09-28 11:46:21,908:INFO:Uploading model into container now
2022-09-28 11:46:21,908:INFO:master_model_container: 23
2022-09-28 11:46:21,909:INFO:display_container: 5
2022-09-28 11:46:21,909:INFO:ExtraTreesRegressor(criterion='mse', max_depth=11, max_features='sqrt',
                    min_impurity_decrease=0.0002, min_samples_leaf=5,
                    min_samples_split=7, n_estimators=200, n_jobs=-1,
                    random_state=123)
2022-09-28 11:46:21,909:INFO:create_model() successfully completed......................................
2022-09-28 11:46:21,965:INFO:SubProcess create_model() end ==================================
2022-09-28 11:46:21,965:INFO:choose_better activated
2022-09-28 11:46:21,967:INFO:SubProcess create_model() called ==================================
2022-09-28 11:46:21,967:INFO:Initializing create_model()
2022-09-28 11:46:21,967:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-28 11:46:21,967:INFO:Checking exceptions
2022-09-28 11:46:21,969:INFO:Importing libraries
2022-09-28 11:46:21,969:INFO:Copying training dataset
2022-09-28 11:46:21,970:INFO:Defining folds
2022-09-28 11:46:21,970:INFO:Declaring metric variables
2022-09-28 11:46:21,970:INFO:Importing untrained model
2022-09-28 11:46:21,970:INFO:Declaring custom model
2022-09-28 11:46:21,970:INFO:Extra Trees Regressor Imported successfully
2022-09-28 11:46:21,970:INFO:Starting cross validation
2022-09-28 11:46:21,971:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 11:46:22,537:INFO:Calculating mean and std
2022-09-28 11:46:22,538:INFO:Creating metrics dataframe
2022-09-28 11:46:22,539:INFO:Finalizing model
2022-09-28 11:46:22,645:INFO:Uploading results into container
2022-09-28 11:46:22,645:INFO:Uploading model into container now
2022-09-28 11:46:22,645:INFO:master_model_container: 24
2022-09-28 11:46:22,645:INFO:display_container: 6
2022-09-28 11:46:22,645:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:46:22,645:INFO:create_model() successfully completed......................................
2022-09-28 11:46:22,705:INFO:SubProcess create_model() end ==================================
2022-09-28 11:46:22,705:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAPE is 0.0602
2022-09-28 11:46:22,706:INFO:ExtraTreesRegressor(criterion='mse', max_depth=11, max_features='sqrt',
                    min_impurity_decrease=0.0002, min_samples_leaf=5,
                    min_samples_split=7, n_estimators=200, n_jobs=-1,
                    random_state=123) result for MAPE is 0.0703
2022-09-28 11:46:22,706:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2022-09-28 11:46:22,706:INFO:choose_better completed
2022-09-28 11:46:22,706:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2022-09-28 11:46:22,711:INFO:master_model_container: 24
2022-09-28 11:46:22,711:INFO:display_container: 5
2022-09-28 11:46:22,711:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-28 11:46:22,711:INFO:tune_model() successfully completed......................................
2022-09-28 12:11:30,651:INFO:Initializing tune_model()
2022-09-28 12:11:30,654:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>)
2022-09-28 12:11:30,654:INFO:Checking exceptions
2022-09-28 12:11:30,681:INFO:Copying training dataset
2022-09-28 12:11:30,684:INFO:Checking base model
2022-09-28 12:11:30,684:INFO:Base model : Extra Trees Regressor
2022-09-28 12:11:30,687:INFO:Declaring metric variables
2022-09-28 12:11:30,689:INFO:Defining Hyperparameters
2022-09-28 12:11:30,762:INFO:Tuning with n_jobs=-1
2022-09-28 12:11:30,762:INFO:Initializing RandomizedSearchCV
2022-09-28 12:11:32,335:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,335:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,335:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,335:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,336:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,336:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,336:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,337:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,341:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,347:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,570:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,572:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,573:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,579:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,583:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,586:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,595:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,606:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,607:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,615:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,739:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,752:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,754:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,761:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,761:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,765:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,771:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,774:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,780:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:32,783:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,113:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,119:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,124:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,127:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,131:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,133:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,137:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,139:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,142:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,295:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,312:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,326:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,330:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,337:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,343:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,347:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,349:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,353:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,369:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,566:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,604:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,612:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,621:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,623:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,623:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,629:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,708:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:33,741:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:34,096:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:34,187:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:39,856:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,136:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,147:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,169:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,206:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,218:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,231:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,239:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,280:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,286:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,288:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,422:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,450:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,465:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,468:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,492:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,494:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,496:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,503:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,510:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,602:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,750:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,768:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,785:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,793:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,804:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,818:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,909:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:40,941:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:41,263:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-28 12:11:47,789:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,148:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,267:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,353:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,369:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,374:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,390:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,392:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,395:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,399:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,499:INFO:best_params: {'actual_estimator__n_estimators': 200, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'mse', 'actual_estimator__bootstrap': False}
2022-09-28 12:11:48,500:INFO:Hyperparameter search completed
2022-09-28 12:11:48,500:INFO:SubProcess create_model() called ==================================
2022-09-28 12:11:48,500:INFO:Initializing create_model()
2022-09-28 12:11:48,500:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28a459c60>, model_only=True, return_train_score=False, kwargs={'n_estimators': 200, 'min_samples_split': 7, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'mse', 'bootstrap': False})
2022-09-28 12:11:48,501:INFO:Checking exceptions
2022-09-28 12:11:48,502:INFO:Importing libraries
2022-09-28 12:11:48,502:INFO:Copying training dataset
2022-09-28 12:11:48,503:INFO:Defining folds
2022-09-28 12:11:48,503:INFO:Declaring metric variables
2022-09-28 12:11:48,505:INFO:Importing untrained model
2022-09-28 12:11:48,505:INFO:Declaring custom model
2022-09-28 12:11:48,507:INFO:Extra Trees Regressor Imported successfully
2022-09-28 12:11:48,510:INFO:Starting cross validation
2022-09-28 12:11:48,510:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 12:11:48,527:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,530:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,533:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,535:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,537:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,546:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,551:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,553:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,558:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,567:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,798:INFO:Calculating mean and std
2022-09-28 12:11:48,799:INFO:Creating metrics dataframe
2022-09-28 12:11:48,802:INFO:Finalizing model
2022-09-28 12:11:48,812:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-28 12:11:48,938:INFO:Uploading results into container
2022-09-28 12:11:48,938:INFO:Uploading model into container now
2022-09-28 12:11:48,938:INFO:master_model_container: 25
2022-09-28 12:11:48,938:INFO:display_container: 6
2022-09-28 12:11:48,939:INFO:ExtraTreesRegressor(criterion='mse', max_depth=11, max_features='sqrt',
                    min_impurity_decrease=0.0002, min_samples_leaf=5,
                    min_samples_split=7, n_estimators=200, n_jobs=-1,
                    random_state=123)
2022-09-28 12:11:48,939:INFO:create_model() successfully completed......................................
2022-09-28 12:11:48,999:INFO:SubProcess create_model() end ==================================
2022-09-28 12:11:48,999:INFO:choose_better activated
2022-09-28 12:11:49,000:INFO:SubProcess create_model() called ==================================
2022-09-28 12:11:49,001:INFO:Initializing create_model()
2022-09-28 12:11:49,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a2538e0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-28 12:11:49,001:INFO:Checking exceptions
2022-09-28 12:11:49,002:INFO:Importing libraries
2022-09-28 12:11:49,003:INFO:Copying training dataset
2022-09-28 12:11:49,003:INFO:Defining folds
2022-09-28 12:11:49,003:INFO:Declaring metric variables
2022-09-28 12:11:49,003:INFO:Importing untrained model
2022-09-28 12:11:49,003:INFO:Declaring custom model
2022-09-28 12:11:49,004:INFO:Extra Trees Regressor Imported successfully
2022-09-28 12:11:49,004:INFO:Starting cross validation
2022-09-28 12:11:49,004:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-28 12:11:49,570:INFO:Calculating mean and std
2022-09-28 12:11:49,570:INFO:Creating metrics dataframe
2022-09-28 12:11:49,571:INFO:Finalizing model
2022-09-28 12:11:49,662:INFO:Uploading results into container
2022-09-28 12:11:49,662:INFO:Uploading model into container now
2022-09-28 12:11:49,663:INFO:master_model_container: 26
2022-09-28 12:11:49,663:INFO:display_container: 7
2022-09-28 12:11:49,663:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-28 12:11:49,663:INFO:create_model() successfully completed......................................
2022-09-28 12:11:49,719:INFO:SubProcess create_model() end ==================================
2022-09-28 12:11:49,719:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAPE is 0.0602
2022-09-28 12:11:49,719:INFO:ExtraTreesRegressor(criterion='mse', max_depth=11, max_features='sqrt',
                    min_impurity_decrease=0.0002, min_samples_leaf=5,
                    min_samples_split=7, n_estimators=200, n_jobs=-1,
                    random_state=123) result for MAPE is 0.0703
2022-09-28 12:11:49,720:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2022-09-28 12:11:49,720:INFO:choose_better completed
2022-09-28 12:11:49,720:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2022-09-28 12:11:49,724:INFO:master_model_container: 26
2022-09-28 12:11:49,724:INFO:display_container: 6
2022-09-28 12:11:49,724:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-28 12:11:49,724:INFO:tune_model() successfully completed......................................
2022-09-30 19:44:06,900:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2022-09-30 19:45:19,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-30 19:45:19,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-30 19:45:19,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-30 19:45:19,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-09-30 19:45:20,193:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2022-09-30 19:45:22,529:INFO:PyCaret RegressionExperiment
2022-09-30 19:45:22,529:INFO:Logging name: reg-default-name
2022-09-30 19:45:22,529:INFO:ML Usecase: MLUsecase.REGRESSION
2022-09-30 19:45:22,529:INFO:version 3.0.0.rc4
2022-09-30 19:45:22,529:INFO:Initializing setup()
2022-09-30 19:45:22,529:INFO:self.USI: 0de5
2022-09-30 19:45:22,529:INFO:self.variable_keys: {'X_train', 'y_train', '_gpu_n_jobs_param', 'X_test', 'display_container', 'fold_groups_param', '_all_models', 'y_test', '_available_plots', 'n_jobs_param', 'X', 'target_param', 'variable_keys', 'exp_name_log', '_ml_usecase', 'data', 'transform_target_method_param', '_all_models_internal', 'html_param', '_all_metrics', 'idx', 'memory', 'pipeline', 'USI', 'logging_param', 'gpu_param', 'fold_shuffle_param', 'y', 'fold_generator', 'seed', 'transform_target_param', 'log_plots_param', 'master_model_container', 'exp_id'}
2022-09-30 19:45:22,529:INFO:Checking environment
2022-09-30 19:45:22,529:INFO:python_version: 3.10.6
2022-09-30 19:45:22,529:INFO:python_build: ('main', 'Aug 11 2022 13:36:31')
2022-09-30 19:45:22,529:INFO:machine: arm64
2022-09-30 19:45:22,529:INFO:platform: macOS-12.5.1-arm64-arm-64bit
2022-09-30 19:45:22,529:INFO:Memory: svmem(total=17179869184, available=4629889024, percent=73.1, used=6361825280, free=62275584, active=4590223360, inactive=4536303616, wired=1771601920)
2022-09-30 19:45:22,529:INFO:Physical Core: 10
2022-09-30 19:45:22,529:INFO:Logical Core: 10
2022-09-30 19:45:22,529:INFO:Checking libraries
2022-09-30 19:45:22,529:INFO:System:
2022-09-30 19:45:22,529:INFO:    python: 3.10.6 (main, Aug 11 2022, 13:36:31) [Clang 13.1.6 (clang-1316.0.21.2.5)]
2022-09-30 19:45:22,529:INFO:executable: /Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/bin/python
2022-09-30 19:45:22,529:INFO:   machine: macOS-12.5.1-arm64-arm-64bit
2022-09-30 19:45:22,529:INFO:PyCaret required dependencies:
2022-09-30 19:45:22,529:INFO:                 pip: 22.2.2
2022-09-30 19:45:22,529:INFO:          setuptools: 65.4.0
2022-09-30 19:45:22,529:INFO:             pycaret: 3.0.0rc4
2022-09-30 19:45:22,529:INFO:             IPython: 8.5.0
2022-09-30 19:45:22,529:INFO:          ipywidgets: 8.0.2
2022-09-30 19:45:22,529:INFO:                tqdm: 4.64.1
2022-09-30 19:45:22,529:INFO:               numpy: 1.22.4
2022-09-30 19:45:22,529:INFO:              pandas: 1.4.4
2022-09-30 19:45:22,529:INFO:              jinja2: 3.1.2
2022-09-30 19:45:22,529:INFO:               scipy: 1.8.1
2022-09-30 19:45:22,529:INFO:              joblib: 1.2.0
2022-09-30 19:45:22,529:INFO:             sklearn: 1.1.2
2022-09-30 19:45:22,529:INFO:                pyod: 1.0.5
2022-09-30 19:45:22,529:INFO:            imblearn: 0.9.1
2022-09-30 19:45:22,529:INFO:   category_encoders: 2.5.0
2022-09-30 19:45:22,529:INFO:            lightgbm: 3.3.2
2022-09-30 19:45:22,529:INFO:               numba: 0.55.2
2022-09-30 19:45:22,529:INFO:            requests: 2.28.1
2022-09-30 19:45:22,529:INFO:          matplotlib: 3.6.0
2022-09-30 19:45:22,529:INFO:          scikitplot: 0.3.7
2022-09-30 19:45:22,529:INFO:         yellowbrick: 1.5
2022-09-30 19:45:22,529:INFO:              plotly: 5.10.0
2022-09-30 19:45:22,529:INFO:             kaleido: 0.2.1
2022-09-30 19:45:22,529:INFO:         statsmodels: 0.13.2
2022-09-30 19:45:22,529:INFO:              sktime: 0.13.4
2022-09-30 19:45:22,529:INFO:               tbats: 1.1.0
2022-09-30 19:45:22,529:INFO:            pmdarima: 1.8.5
2022-09-30 19:45:22,529:INFO:              psutil: 5.9.2
2022-09-30 19:45:22,529:INFO:PyCaret optional dependencies:
2022-09-30 19:45:22,533:INFO:                shap: Not installed
2022-09-30 19:45:22,533:INFO:           interpret: Not installed
2022-09-30 19:45:22,533:INFO:                umap: Not installed
2022-09-30 19:45:22,533:INFO:    pandas_profiling: Not installed
2022-09-30 19:45:22,533:INFO:  explainerdashboard: Not installed
2022-09-30 19:45:22,533:INFO:             autoviz: Not installed
2022-09-30 19:45:22,533:INFO:           fairlearn: Not installed
2022-09-30 19:45:22,533:INFO:             xgboost: 1.6.2
2022-09-30 19:45:22,533:INFO:            catboost: Not installed
2022-09-30 19:45:22,533:INFO:              kmodes: Not installed
2022-09-30 19:45:22,533:INFO:             mlxtend: Not installed
2022-09-30 19:45:22,533:INFO:       statsforecast: Not installed
2022-09-30 19:45:22,533:INFO:        tune_sklearn: Not installed
2022-09-30 19:45:22,533:INFO:                 ray: Not installed
2022-09-30 19:45:22,533:INFO:            hyperopt: Not installed
2022-09-30 19:45:22,533:INFO:              optuna: Not installed
2022-09-30 19:45:22,533:INFO:               skopt: Not installed
2022-09-30 19:45:22,533:INFO:              mlflow: Not installed
2022-09-30 19:45:22,533:INFO:              gradio: Not installed
2022-09-30 19:45:22,533:INFO:             fastapi: Not installed
2022-09-30 19:45:22,533:INFO:             uvicorn: Not installed
2022-09-30 19:45:22,533:INFO:              m2cgen: Not installed
2022-09-30 19:45:22,533:INFO:           evidently: Not installed
2022-09-30 19:45:22,533:INFO:                nltk: Not installed
2022-09-30 19:45:22,533:INFO:            pyLDAvis: Not installed
2022-09-30 19:45:22,534:INFO:              gensim: Not installed
2022-09-30 19:45:22,534:INFO:               spacy: Not installed
2022-09-30 19:45:22,534:INFO:           wordcloud: Not installed
2022-09-30 19:45:22,534:INFO:            textblob: Not installed
2022-09-30 19:45:22,534:INFO:               fugue: Not installed
2022-09-30 19:45:22,534:INFO:           streamlit: Not installed
2022-09-30 19:45:22,534:INFO:             prophet: Not installed
2022-09-30 19:45:22,534:INFO:None
2022-09-30 19:45:22,534:INFO:Set up data.
2022-09-30 19:45:22,537:INFO:Set up train/test split.
2022-09-30 19:45:22,539:INFO:Set up index.
2022-09-30 19:45:22,539:INFO:Set up folding strategy.
2022-09-30 19:45:22,539:INFO:Assigning column types.
2022-09-30 19:45:22,541:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-09-30 19:45:22,541:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,543:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,545:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,568:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,587:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,587:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-30 19:45:22,646:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-30 19:45:22,646:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,648:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,650:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,673:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,692:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,692:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-30 19:45:22,693:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-30 19:45:22,693:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-09-30 19:45:22,695:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,697:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,720:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,738:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,738:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-30 19:45:22,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-30 19:45:22,741:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,743:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,767:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,785:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,785:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-30 19:45:22,787:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-30 19:45:22,787:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-09-30 19:45:22,790:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,814:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,832:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,832:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-30 19:45:22,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-30 19:45:22,837:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,860:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,879:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,879:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-30 19:45:22,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-30 19:45:22,880:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-09-30 19:45:22,908:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,926:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,926:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-30 19:45:22,927:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-30 19:45:22,954:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,973:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-09-30 19:45:22,973:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-30 19:45:22,974:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-30 19:45:22,974:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-09-30 19:45:23,001:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-30 19:45:23,019:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-30 19:45:23,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-30 19:45:23,048:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-09-30 19:45:23,066:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-30 19:45:23,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-30 19:45:23,068:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-09-30 19:45:23,114:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-30 19:45:23,115:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-30 19:45:23,160:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-30 19:45:23,161:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-30 19:45:23,162:INFO:Preparing preprocessing pipeline...
2022-09-30 19:45:23,162:INFO:Set up simple imputation.
2022-09-30 19:45:23,162:INFO:Set up variance threshold.
2022-09-30 19:45:23,172:INFO:Finished creating preprocessing pipeline.
2022-09-30 19:45:23,175:INFO:Pipeline: Pipeline(memory=Memory(location=/var/folders/67/hmlyjz1x4x7b_71cqk6bxrg00000gq/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demand_point_index',
                                             'x_coordinate', 'y_coordinate',
                                             '2010', '2011', '2012', '2013',
                                             '2014', '2015', '2016', '2017'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-09-30 19:45:23,175:INFO:Creating final display dataframe.
2022-09-30 19:45:23,218:INFO:Setup display_container:                Description             Value
0               Session id               123
1                   Target              2018
2              Target type        Regression
3               Data shape        (4096, 12)
4         Train data shape        (2867, 12)
5          Test data shape        (1229, 12)
6         Numeric features                11
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              0de5
2022-09-30 19:45:23,272:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-30 19:45:23,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-30 19:45:23,320:INFO:Soft dependency imported: xgboost: 1.6.2
2022-09-30 19:45:23,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-09-30 19:45:23,323:INFO:setup() successfully completed in 0.8s...............
2022-09-30 19:45:23,325:INFO:Initializing compare_models()
2022-09-30 19:45:23,325:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-09-30 19:45:23,325:INFO:Checking exceptions
2022-09-30 19:45:23,327:INFO:Preparing display monitor
2022-09-30 19:45:23,355:INFO:Initializing Linear Regression
2022-09-30 19:45:23,355:INFO:Total runtime is 5.682309468587239e-06 minutes
2022-09-30 19:45:23,357:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:23,357:INFO:Initializing create_model()
2022-09-30 19:45:23,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:23,357:INFO:Checking exceptions
2022-09-30 19:45:23,359:INFO:Importing libraries
2022-09-30 19:45:23,359:INFO:Copying training dataset
2022-09-30 19:45:23,361:INFO:Defining folds
2022-09-30 19:45:23,361:INFO:Declaring metric variables
2022-09-30 19:45:23,363:INFO:Importing untrained model
2022-09-30 19:45:23,364:INFO:Linear Regression Imported successfully
2022-09-30 19:45:23,367:INFO:Starting cross validation
2022-09-30 19:45:23,367:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:24,983:INFO:Calculating mean and std
2022-09-30 19:45:24,988:INFO:Creating metrics dataframe
2022-09-30 19:45:24,997:INFO:Uploading results into container
2022-09-30 19:45:24,998:INFO:Uploading model into container now
2022-09-30 19:45:24,999:INFO:master_model_container: 1
2022-09-30 19:45:24,999:INFO:display_container: 2
2022-09-30 19:45:25,000:INFO:LinearRegression(n_jobs=-1)
2022-09-30 19:45:25,000:INFO:create_model() successfully completed......................................
2022-09-30 19:45:25,081:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:25,081:INFO:Creating metrics dataframe
2022-09-30 19:45:25,085:INFO:Initializing Lasso Regression
2022-09-30 19:45:25,085:INFO:Total runtime is 0.028839433193206785 minutes
2022-09-30 19:45:25,086:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:25,087:INFO:Initializing create_model()
2022-09-30 19:45:25,087:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:25,087:INFO:Checking exceptions
2022-09-30 19:45:25,088:INFO:Importing libraries
2022-09-30 19:45:25,088:INFO:Copying training dataset
2022-09-30 19:45:25,089:INFO:Defining folds
2022-09-30 19:45:25,089:INFO:Declaring metric variables
2022-09-30 19:45:25,091:INFO:Importing untrained model
2022-09-30 19:45:25,092:INFO:Lasso Regression Imported successfully
2022-09-30 19:45:25,095:INFO:Starting cross validation
2022-09-30 19:45:25,095:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:25,152:INFO:Calculating mean and std
2022-09-30 19:45:25,152:INFO:Creating metrics dataframe
2022-09-30 19:45:25,153:INFO:Uploading results into container
2022-09-30 19:45:25,153:INFO:Uploading model into container now
2022-09-30 19:45:25,154:INFO:master_model_container: 2
2022-09-30 19:45:25,154:INFO:display_container: 2
2022-09-30 19:45:25,154:INFO:Lasso(random_state=123)
2022-09-30 19:45:25,154:INFO:create_model() successfully completed......................................
2022-09-30 19:45:25,208:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:25,208:INFO:Creating metrics dataframe
2022-09-30 19:45:25,212:INFO:Initializing Ridge Regression
2022-09-30 19:45:25,212:INFO:Total runtime is 0.030955449740091956 minutes
2022-09-30 19:45:25,213:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:25,214:INFO:Initializing create_model()
2022-09-30 19:45:25,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:25,214:INFO:Checking exceptions
2022-09-30 19:45:25,215:INFO:Importing libraries
2022-09-30 19:45:25,215:INFO:Copying training dataset
2022-09-30 19:45:25,216:INFO:Defining folds
2022-09-30 19:45:25,216:INFO:Declaring metric variables
2022-09-30 19:45:25,218:INFO:Importing untrained model
2022-09-30 19:45:25,219:INFO:Ridge Regression Imported successfully
2022-09-30 19:45:25,222:INFO:Starting cross validation
2022-09-30 19:45:25,222:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:25,265:INFO:Calculating mean and std
2022-09-30 19:45:25,265:INFO:Creating metrics dataframe
2022-09-30 19:45:25,267:INFO:Uploading results into container
2022-09-30 19:45:25,267:INFO:Uploading model into container now
2022-09-30 19:45:25,267:INFO:master_model_container: 3
2022-09-30 19:45:25,267:INFO:display_container: 2
2022-09-30 19:45:25,267:INFO:Ridge(random_state=123)
2022-09-30 19:45:25,267:INFO:create_model() successfully completed......................................
2022-09-30 19:45:25,321:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:25,321:INFO:Creating metrics dataframe
2022-09-30 19:45:25,325:INFO:Initializing Elastic Net
2022-09-30 19:45:25,325:INFO:Total runtime is 0.03284339904785156 minutes
2022-09-30 19:45:25,327:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:25,327:INFO:Initializing create_model()
2022-09-30 19:45:25,327:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:25,327:INFO:Checking exceptions
2022-09-30 19:45:25,328:INFO:Importing libraries
2022-09-30 19:45:25,328:INFO:Copying training dataset
2022-09-30 19:45:25,330:INFO:Defining folds
2022-09-30 19:45:25,330:INFO:Declaring metric variables
2022-09-30 19:45:25,331:INFO:Importing untrained model
2022-09-30 19:45:25,333:INFO:Elastic Net Imported successfully
2022-09-30 19:45:25,335:INFO:Starting cross validation
2022-09-30 19:45:25,336:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:25,412:INFO:Calculating mean and std
2022-09-30 19:45:25,412:INFO:Creating metrics dataframe
2022-09-30 19:45:25,414:INFO:Uploading results into container
2022-09-30 19:45:25,414:INFO:Uploading model into container now
2022-09-30 19:45:25,414:INFO:master_model_container: 4
2022-09-30 19:45:25,414:INFO:display_container: 2
2022-09-30 19:45:25,414:INFO:ElasticNet(random_state=123)
2022-09-30 19:45:25,414:INFO:create_model() successfully completed......................................
2022-09-30 19:45:25,468:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:25,469:INFO:Creating metrics dataframe
2022-09-30 19:45:25,473:INFO:Initializing Least Angle Regression
2022-09-30 19:45:25,473:INFO:Total runtime is 0.03530391852060953 minutes
2022-09-30 19:45:25,474:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:25,475:INFO:Initializing create_model()
2022-09-30 19:45:25,475:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:25,475:INFO:Checking exceptions
2022-09-30 19:45:25,476:INFO:Importing libraries
2022-09-30 19:45:25,476:INFO:Copying training dataset
2022-09-30 19:45:25,477:INFO:Defining folds
2022-09-30 19:45:25,477:INFO:Declaring metric variables
2022-09-30 19:45:25,479:INFO:Importing untrained model
2022-09-30 19:45:25,480:INFO:Least Angle Regression Imported successfully
2022-09-30 19:45:25,483:INFO:Starting cross validation
2022-09-30 19:45:25,483:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:25,499:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,502:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,506:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,508:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,511:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,513:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,516:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,517:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,519:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,522:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,527:INFO:Calculating mean and std
2022-09-30 19:45:25,527:INFO:Creating metrics dataframe
2022-09-30 19:45:25,528:INFO:Uploading results into container
2022-09-30 19:45:25,528:INFO:Uploading model into container now
2022-09-30 19:45:25,529:INFO:master_model_container: 5
2022-09-30 19:45:25,529:INFO:display_container: 2
2022-09-30 19:45:25,529:INFO:Lars(random_state=123)
2022-09-30 19:45:25,529:INFO:create_model() successfully completed......................................
2022-09-30 19:45:25,584:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:25,584:INFO:Creating metrics dataframe
2022-09-30 19:45:25,589:INFO:Initializing Lasso Least Angle Regression
2022-09-30 19:45:25,589:INFO:Total runtime is 0.0372311512629191 minutes
2022-09-30 19:45:25,590:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:25,590:INFO:Initializing create_model()
2022-09-30 19:45:25,590:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:25,590:INFO:Checking exceptions
2022-09-30 19:45:25,592:INFO:Importing libraries
2022-09-30 19:45:25,592:INFO:Copying training dataset
2022-09-30 19:45:25,593:INFO:Defining folds
2022-09-30 19:45:25,593:INFO:Declaring metric variables
2022-09-30 19:45:25,595:INFO:Importing untrained model
2022-09-30 19:45:25,597:INFO:Lasso Least Angle Regression Imported successfully
2022-09-30 19:45:25,600:INFO:Starting cross validation
2022-09-30 19:45:25,600:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:25,615:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-30 19:45:25,617:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-30 19:45:25,621:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-30 19:45:25,624:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-30 19:45:25,626:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-30 19:45:25,628:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-30 19:45:25,630:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-30 19:45:25,632:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-30 19:45:25,635:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-30 19:45:25,637:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-09-30 19:45:25,642:INFO:Calculating mean and std
2022-09-30 19:45:25,642:INFO:Creating metrics dataframe
2022-09-30 19:45:25,643:INFO:Uploading results into container
2022-09-30 19:45:25,643:INFO:Uploading model into container now
2022-09-30 19:45:25,644:INFO:master_model_container: 6
2022-09-30 19:45:25,644:INFO:display_container: 2
2022-09-30 19:45:25,644:INFO:LassoLars(random_state=123)
2022-09-30 19:45:25,644:INFO:create_model() successfully completed......................................
2022-09-30 19:45:25,698:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:25,699:INFO:Creating metrics dataframe
2022-09-30 19:45:25,703:INFO:Initializing Orthogonal Matching Pursuit
2022-09-30 19:45:25,703:INFO:Total runtime is 0.03913294871648152 minutes
2022-09-30 19:45:25,704:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:25,704:INFO:Initializing create_model()
2022-09-30 19:45:25,704:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:25,704:INFO:Checking exceptions
2022-09-30 19:45:25,705:INFO:Importing libraries
2022-09-30 19:45:25,706:INFO:Copying training dataset
2022-09-30 19:45:25,707:INFO:Defining folds
2022-09-30 19:45:25,708:INFO:Declaring metric variables
2022-09-30 19:45:25,709:INFO:Importing untrained model
2022-09-30 19:45:25,711:INFO:Orthogonal Matching Pursuit Imported successfully
2022-09-30 19:45:25,714:INFO:Starting cross validation
2022-09-30 19:45:25,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:25,729:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,732:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,735:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,737:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,741:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,744:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,747:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,752:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,756:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,756:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-09-30 19:45:25,762:INFO:Calculating mean and std
2022-09-30 19:45:25,762:INFO:Creating metrics dataframe
2022-09-30 19:45:25,763:INFO:Uploading results into container
2022-09-30 19:45:25,764:INFO:Uploading model into container now
2022-09-30 19:45:25,764:INFO:master_model_container: 7
2022-09-30 19:45:25,764:INFO:display_container: 2
2022-09-30 19:45:25,764:INFO:OrthogonalMatchingPursuit()
2022-09-30 19:45:25,764:INFO:create_model() successfully completed......................................
2022-09-30 19:45:25,819:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:25,819:INFO:Creating metrics dataframe
2022-09-30 19:45:25,823:INFO:Initializing Bayesian Ridge
2022-09-30 19:45:25,823:INFO:Total runtime is 0.04114578167597452 minutes
2022-09-30 19:45:25,825:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:25,825:INFO:Initializing create_model()
2022-09-30 19:45:25,825:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:25,825:INFO:Checking exceptions
2022-09-30 19:45:25,826:INFO:Importing libraries
2022-09-30 19:45:25,826:INFO:Copying training dataset
2022-09-30 19:45:25,828:INFO:Defining folds
2022-09-30 19:45:25,828:INFO:Declaring metric variables
2022-09-30 19:45:25,829:INFO:Importing untrained model
2022-09-30 19:45:25,831:INFO:Bayesian Ridge Imported successfully
2022-09-30 19:45:25,833:INFO:Starting cross validation
2022-09-30 19:45:25,834:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:25,875:INFO:Calculating mean and std
2022-09-30 19:45:25,875:INFO:Creating metrics dataframe
2022-09-30 19:45:25,876:INFO:Uploading results into container
2022-09-30 19:45:25,876:INFO:Uploading model into container now
2022-09-30 19:45:25,876:INFO:master_model_container: 8
2022-09-30 19:45:25,876:INFO:display_container: 2
2022-09-30 19:45:25,877:INFO:BayesianRidge()
2022-09-30 19:45:25,877:INFO:create_model() successfully completed......................................
2022-09-30 19:45:25,929:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:25,930:INFO:Creating metrics dataframe
2022-09-30 19:45:25,934:INFO:Initializing Passive Aggressive Regressor
2022-09-30 19:45:25,934:INFO:Total runtime is 0.04298663139343261 minutes
2022-09-30 19:45:25,935:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:25,936:INFO:Initializing create_model()
2022-09-30 19:45:25,936:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:25,936:INFO:Checking exceptions
2022-09-30 19:45:25,937:INFO:Importing libraries
2022-09-30 19:45:25,937:INFO:Copying training dataset
2022-09-30 19:45:25,938:INFO:Defining folds
2022-09-30 19:45:25,938:INFO:Declaring metric variables
2022-09-30 19:45:25,940:INFO:Importing untrained model
2022-09-30 19:45:25,941:INFO:Passive Aggressive Regressor Imported successfully
2022-09-30 19:45:25,945:INFO:Starting cross validation
2022-09-30 19:45:25,945:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:25,989:INFO:Calculating mean and std
2022-09-30 19:45:25,989:INFO:Creating metrics dataframe
2022-09-30 19:45:25,991:INFO:Uploading results into container
2022-09-30 19:45:25,991:INFO:Uploading model into container now
2022-09-30 19:45:25,991:INFO:master_model_container: 9
2022-09-30 19:45:25,991:INFO:display_container: 2
2022-09-30 19:45:25,991:INFO:PassiveAggressiveRegressor(random_state=123)
2022-09-30 19:45:25,991:INFO:create_model() successfully completed......................................
2022-09-30 19:45:26,045:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:26,045:INFO:Creating metrics dataframe
2022-09-30 19:45:26,049:INFO:Initializing Huber Regressor
2022-09-30 19:45:26,050:INFO:Total runtime is 0.0449131965637207 minutes
2022-09-30 19:45:26,051:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:26,051:INFO:Initializing create_model()
2022-09-30 19:45:26,051:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:26,051:INFO:Checking exceptions
2022-09-30 19:45:26,052:INFO:Importing libraries
2022-09-30 19:45:26,052:INFO:Copying training dataset
2022-09-30 19:45:26,054:INFO:Defining folds
2022-09-30 19:45:26,054:INFO:Declaring metric variables
2022-09-30 19:45:26,055:INFO:Importing untrained model
2022-09-30 19:45:26,057:INFO:Huber Regressor Imported successfully
2022-09-30 19:45:26,059:INFO:Starting cross validation
2022-09-30 19:45:26,060:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:26,100:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-30 19:45:26,100:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-30 19:45:26,109:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-30 19:45:26,113:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-30 19:45:26,116:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-30 19:45:26,119:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-30 19:45:26,119:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-30 19:45:26,127:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-30 19:45:26,138:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-30 19:45:26,140:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-09-30 19:45:26,144:INFO:Calculating mean and std
2022-09-30 19:45:26,144:INFO:Creating metrics dataframe
2022-09-30 19:45:26,146:INFO:Uploading results into container
2022-09-30 19:45:26,146:INFO:Uploading model into container now
2022-09-30 19:45:26,146:INFO:master_model_container: 10
2022-09-30 19:45:26,146:INFO:display_container: 2
2022-09-30 19:45:26,146:INFO:HuberRegressor()
2022-09-30 19:45:26,146:INFO:create_model() successfully completed......................................
2022-09-30 19:45:26,200:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:26,201:INFO:Creating metrics dataframe
2022-09-30 19:45:26,205:INFO:Initializing K Neighbors Regressor
2022-09-30 19:45:26,205:INFO:Total runtime is 0.04750691652297973 minutes
2022-09-30 19:45:26,206:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:26,207:INFO:Initializing create_model()
2022-09-30 19:45:26,207:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:26,207:INFO:Checking exceptions
2022-09-30 19:45:26,208:INFO:Importing libraries
2022-09-30 19:45:26,208:INFO:Copying training dataset
2022-09-30 19:45:26,210:INFO:Defining folds
2022-09-30 19:45:26,210:INFO:Declaring metric variables
2022-09-30 19:45:26,211:INFO:Importing untrained model
2022-09-30 19:45:26,212:INFO:K Neighbors Regressor Imported successfully
2022-09-30 19:45:26,215:INFO:Starting cross validation
2022-09-30 19:45:26,215:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:26,267:INFO:Calculating mean and std
2022-09-30 19:45:26,267:INFO:Creating metrics dataframe
2022-09-30 19:45:26,268:INFO:Uploading results into container
2022-09-30 19:45:26,268:INFO:Uploading model into container now
2022-09-30 19:45:26,269:INFO:master_model_container: 11
2022-09-30 19:45:26,269:INFO:display_container: 2
2022-09-30 19:45:26,269:INFO:KNeighborsRegressor(n_jobs=-1)
2022-09-30 19:45:26,269:INFO:create_model() successfully completed......................................
2022-09-30 19:45:26,324:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:26,324:INFO:Creating metrics dataframe
2022-09-30 19:45:26,329:INFO:Initializing Decision Tree Regressor
2022-09-30 19:45:26,329:INFO:Total runtime is 0.049569729963938394 minutes
2022-09-30 19:45:26,330:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:26,330:INFO:Initializing create_model()
2022-09-30 19:45:26,330:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:26,330:INFO:Checking exceptions
2022-09-30 19:45:26,332:INFO:Importing libraries
2022-09-30 19:45:26,332:INFO:Copying training dataset
2022-09-30 19:45:26,333:INFO:Defining folds
2022-09-30 19:45:26,333:INFO:Declaring metric variables
2022-09-30 19:45:26,335:INFO:Importing untrained model
2022-09-30 19:45:26,336:INFO:Decision Tree Regressor Imported successfully
2022-09-30 19:45:26,338:INFO:Starting cross validation
2022-09-30 19:45:26,339:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:26,407:INFO:Calculating mean and std
2022-09-30 19:45:26,407:INFO:Creating metrics dataframe
2022-09-30 19:45:26,408:INFO:Uploading results into container
2022-09-30 19:45:26,409:INFO:Uploading model into container now
2022-09-30 19:45:26,409:INFO:master_model_container: 12
2022-09-30 19:45:26,409:INFO:display_container: 2
2022-09-30 19:45:26,409:INFO:DecisionTreeRegressor(random_state=123)
2022-09-30 19:45:26,409:INFO:create_model() successfully completed......................................
2022-09-30 19:45:26,464:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:26,464:INFO:Creating metrics dataframe
2022-09-30 19:45:26,469:INFO:Initializing Random Forest Regressor
2022-09-30 19:45:26,469:INFO:Total runtime is 0.05190291404724121 minutes
2022-09-30 19:45:26,470:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:26,470:INFO:Initializing create_model()
2022-09-30 19:45:26,471:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:26,471:INFO:Checking exceptions
2022-09-30 19:45:26,472:INFO:Importing libraries
2022-09-30 19:45:26,472:INFO:Copying training dataset
2022-09-30 19:45:26,473:INFO:Defining folds
2022-09-30 19:45:26,473:INFO:Declaring metric variables
2022-09-30 19:45:26,475:INFO:Importing untrained model
2022-09-30 19:45:26,476:INFO:Random Forest Regressor Imported successfully
2022-09-30 19:45:26,479:INFO:Starting cross validation
2022-09-30 19:45:26,479:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:27,620:INFO:Calculating mean and std
2022-09-30 19:45:27,621:INFO:Creating metrics dataframe
2022-09-30 19:45:27,622:INFO:Uploading results into container
2022-09-30 19:45:27,622:INFO:Uploading model into container now
2022-09-30 19:45:27,622:INFO:master_model_container: 13
2022-09-30 19:45:27,622:INFO:display_container: 2
2022-09-30 19:45:27,622:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-09-30 19:45:27,622:INFO:create_model() successfully completed......................................
2022-09-30 19:45:27,677:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:27,677:INFO:Creating metrics dataframe
2022-09-30 19:45:27,682:INFO:Initializing Extra Trees Regressor
2022-09-30 19:45:27,682:INFO:Total runtime is 0.07212040026982626 minutes
2022-09-30 19:45:27,683:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:27,684:INFO:Initializing create_model()
2022-09-30 19:45:27,684:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:27,684:INFO:Checking exceptions
2022-09-30 19:45:27,685:INFO:Importing libraries
2022-09-30 19:45:27,685:INFO:Copying training dataset
2022-09-30 19:45:27,686:INFO:Defining folds
2022-09-30 19:45:27,686:INFO:Declaring metric variables
2022-09-30 19:45:27,688:INFO:Importing untrained model
2022-09-30 19:45:27,689:INFO:Extra Trees Regressor Imported successfully
2022-09-30 19:45:27,692:INFO:Starting cross validation
2022-09-30 19:45:27,692:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:28,285:INFO:Calculating mean and std
2022-09-30 19:45:28,285:INFO:Creating metrics dataframe
2022-09-30 19:45:28,287:INFO:Uploading results into container
2022-09-30 19:45:28,287:INFO:Uploading model into container now
2022-09-30 19:45:28,287:INFO:master_model_container: 14
2022-09-30 19:45:28,287:INFO:display_container: 2
2022-09-30 19:45:28,288:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-30 19:45:28,288:INFO:create_model() successfully completed......................................
2022-09-30 19:45:28,342:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:28,342:INFO:Creating metrics dataframe
2022-09-30 19:45:28,347:INFO:Initializing AdaBoost Regressor
2022-09-30 19:45:28,347:INFO:Total runtime is 0.08320840199788412 minutes
2022-09-30 19:45:28,349:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:28,349:INFO:Initializing create_model()
2022-09-30 19:45:28,349:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:28,349:INFO:Checking exceptions
2022-09-30 19:45:28,350:INFO:Importing libraries
2022-09-30 19:45:28,350:INFO:Copying training dataset
2022-09-30 19:45:28,351:INFO:Defining folds
2022-09-30 19:45:28,351:INFO:Declaring metric variables
2022-09-30 19:45:28,352:INFO:Importing untrained model
2022-09-30 19:45:28,353:INFO:AdaBoost Regressor Imported successfully
2022-09-30 19:45:28,356:INFO:Starting cross validation
2022-09-30 19:45:28,356:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:28,606:INFO:Calculating mean and std
2022-09-30 19:45:28,607:INFO:Creating metrics dataframe
2022-09-30 19:45:28,608:INFO:Uploading results into container
2022-09-30 19:45:28,608:INFO:Uploading model into container now
2022-09-30 19:45:28,608:INFO:master_model_container: 15
2022-09-30 19:45:28,608:INFO:display_container: 2
2022-09-30 19:45:28,608:INFO:AdaBoostRegressor(random_state=123)
2022-09-30 19:45:28,608:INFO:create_model() successfully completed......................................
2022-09-30 19:45:28,664:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:28,664:INFO:Creating metrics dataframe
2022-09-30 19:45:28,670:INFO:Initializing Gradient Boosting Regressor
2022-09-30 19:45:28,670:INFO:Total runtime is 0.08858746687571209 minutes
2022-09-30 19:45:28,671:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:28,671:INFO:Initializing create_model()
2022-09-30 19:45:28,671:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:28,671:INFO:Checking exceptions
2022-09-30 19:45:28,673:INFO:Importing libraries
2022-09-30 19:45:28,673:INFO:Copying training dataset
2022-09-30 19:45:28,674:INFO:Defining folds
2022-09-30 19:45:28,674:INFO:Declaring metric variables
2022-09-30 19:45:28,675:INFO:Importing untrained model
2022-09-30 19:45:28,676:INFO:Gradient Boosting Regressor Imported successfully
2022-09-30 19:45:28,679:INFO:Starting cross validation
2022-09-30 19:45:28,680:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:29,338:INFO:Calculating mean and std
2022-09-30 19:45:29,339:INFO:Creating metrics dataframe
2022-09-30 19:45:29,340:INFO:Uploading results into container
2022-09-30 19:45:29,341:INFO:Uploading model into container now
2022-09-30 19:45:29,341:INFO:master_model_container: 16
2022-09-30 19:45:29,341:INFO:display_container: 2
2022-09-30 19:45:29,341:INFO:GradientBoostingRegressor(random_state=123)
2022-09-30 19:45:29,341:INFO:create_model() successfully completed......................................
2022-09-30 19:45:29,398:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:29,398:INFO:Creating metrics dataframe
2022-09-30 19:45:29,403:INFO:Initializing Extreme Gradient Boosting
2022-09-30 19:45:29,403:INFO:Total runtime is 0.1008018970489502 minutes
2022-09-30 19:45:29,404:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:29,404:INFO:Initializing create_model()
2022-09-30 19:45:29,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:29,404:INFO:Checking exceptions
2022-09-30 19:45:29,405:INFO:Importing libraries
2022-09-30 19:45:29,405:INFO:Copying training dataset
2022-09-30 19:45:29,407:INFO:Defining folds
2022-09-30 19:45:29,407:INFO:Declaring metric variables
2022-09-30 19:45:29,408:INFO:Importing untrained model
2022-09-30 19:45:29,409:INFO:Extreme Gradient Boosting Imported successfully
2022-09-30 19:45:29,412:INFO:Starting cross validation
2022-09-30 19:45:29,413:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:29,900:INFO:Calculating mean and std
2022-09-30 19:45:29,900:INFO:Creating metrics dataframe
2022-09-30 19:45:29,902:INFO:Uploading results into container
2022-09-30 19:45:29,902:INFO:Uploading model into container now
2022-09-30 19:45:29,902:INFO:master_model_container: 17
2022-09-30 19:45:29,902:INFO:display_container: 2
2022-09-30 19:45:29,903:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=123,
             reg_alpha=None, reg_lambda=None, ...)
2022-09-30 19:45:29,903:INFO:create_model() successfully completed......................................
2022-09-30 19:45:29,959:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:29,959:INFO:Creating metrics dataframe
2022-09-30 19:45:29,964:INFO:Initializing Light Gradient Boosting Machine
2022-09-30 19:45:29,964:INFO:Total runtime is 0.11016110181808472 minutes
2022-09-30 19:45:29,966:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:29,966:INFO:Initializing create_model()
2022-09-30 19:45:29,966:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:29,966:INFO:Checking exceptions
2022-09-30 19:45:29,967:INFO:Importing libraries
2022-09-30 19:45:29,967:INFO:Copying training dataset
2022-09-30 19:45:29,968:INFO:Defining folds
2022-09-30 19:45:29,968:INFO:Declaring metric variables
2022-09-30 19:45:29,970:INFO:Importing untrained model
2022-09-30 19:45:29,971:INFO:Light Gradient Boosting Machine Imported successfully
2022-09-30 19:45:29,974:INFO:Starting cross validation
2022-09-30 19:45:29,974:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:30,117:INFO:Calculating mean and std
2022-09-30 19:45:30,118:INFO:Creating metrics dataframe
2022-09-30 19:45:30,119:INFO:Uploading results into container
2022-09-30 19:45:30,119:INFO:Uploading model into container now
2022-09-30 19:45:30,120:INFO:master_model_container: 18
2022-09-30 19:45:30,120:INFO:display_container: 2
2022-09-30 19:45:30,120:INFO:LGBMRegressor(random_state=123)
2022-09-30 19:45:30,120:INFO:create_model() successfully completed......................................
2022-09-30 19:45:30,175:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:30,175:INFO:Creating metrics dataframe
2022-09-30 19:45:30,181:INFO:Initializing Dummy Regressor
2022-09-30 19:45:30,181:INFO:Total runtime is 0.11377111673355103 minutes
2022-09-30 19:45:30,182:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:30,183:INFO:Initializing create_model()
2022-09-30 19:45:30,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x290d9f580>, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:30,183:INFO:Checking exceptions
2022-09-30 19:45:30,184:INFO:Importing libraries
2022-09-30 19:45:30,184:INFO:Copying training dataset
2022-09-30 19:45:30,185:INFO:Defining folds
2022-09-30 19:45:30,185:INFO:Declaring metric variables
2022-09-30 19:45:30,186:INFO:Importing untrained model
2022-09-30 19:45:30,187:INFO:Dummy Regressor Imported successfully
2022-09-30 19:45:30,190:INFO:Starting cross validation
2022-09-30 19:45:30,190:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:30,231:INFO:Calculating mean and std
2022-09-30 19:45:30,232:INFO:Creating metrics dataframe
2022-09-30 19:45:30,233:INFO:Uploading results into container
2022-09-30 19:45:30,234:INFO:Uploading model into container now
2022-09-30 19:45:30,234:INFO:master_model_container: 19
2022-09-30 19:45:30,234:INFO:display_container: 2
2022-09-30 19:45:30,234:INFO:DummyRegressor()
2022-09-30 19:45:30,235:INFO:create_model() successfully completed......................................
2022-09-30 19:45:30,289:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:30,289:INFO:Creating metrics dataframe
2022-09-30 19:45:30,299:INFO:Initializing create_model()
2022-09-30 19:45:30,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:30,299:INFO:Checking exceptions
2022-09-30 19:45:30,301:INFO:Importing libraries
2022-09-30 19:45:30,301:INFO:Copying training dataset
2022-09-30 19:45:30,302:INFO:Defining folds
2022-09-30 19:45:30,302:INFO:Declaring metric variables
2022-09-30 19:45:30,302:INFO:Importing untrained model
2022-09-30 19:45:30,302:INFO:Declaring custom model
2022-09-30 19:45:30,302:INFO:Extra Trees Regressor Imported successfully
2022-09-30 19:45:30,302:INFO:Cross validation set to False
2022-09-30 19:45:30,302:INFO:Fitting Model
2022-09-30 19:45:30,396:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-30 19:45:30,396:INFO:create_model() successfully completed......................................
2022-09-30 19:45:30,466:INFO:master_model_container: 19
2022-09-30 19:45:30,466:INFO:display_container: 2
2022-09-30 19:45:30,466:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-30 19:45:30,466:INFO:compare_models() successfully completed......................................
2022-09-30 19:45:30,469:INFO:Initializing create_model()
2022-09-30 19:45:30,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:30,470:INFO:Checking exceptions
2022-09-30 19:45:30,483:INFO:Importing libraries
2022-09-30 19:45:30,483:INFO:Copying training dataset
2022-09-30 19:45:30,486:INFO:Defining folds
2022-09-30 19:45:30,486:INFO:Declaring metric variables
2022-09-30 19:45:30,488:INFO:Importing untrained model
2022-09-30 19:45:30,490:INFO:Extra Trees Regressor Imported successfully
2022-09-30 19:45:30,492:INFO:Starting cross validation
2022-09-30 19:45:30,493:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:31,078:INFO:Calculating mean and std
2022-09-30 19:45:31,079:INFO:Creating metrics dataframe
2022-09-30 19:45:31,081:INFO:Finalizing model
2022-09-30 19:45:31,177:INFO:Uploading results into container
2022-09-30 19:45:31,178:INFO:Uploading model into container now
2022-09-30 19:45:31,182:INFO:master_model_container: 20
2022-09-30 19:45:31,182:INFO:display_container: 3
2022-09-30 19:45:31,182:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-30 19:45:31,182:INFO:create_model() successfully completed......................................
2022-09-30 19:45:31,240:INFO:Initializing tune_model()
2022-09-30 19:45:31,240:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>)
2022-09-30 19:45:31,240:INFO:Checking exceptions
2022-09-30 19:45:31,253:INFO:Copying training dataset
2022-09-30 19:45:31,256:INFO:Checking base model
2022-09-30 19:45:31,256:INFO:Base model : Extra Trees Regressor
2022-09-30 19:45:31,257:INFO:Declaring metric variables
2022-09-30 19:45:31,259:INFO:Defining Hyperparameters
2022-09-30 19:45:31,314:INFO:Tuning with n_jobs=-1
2022-09-30 19:45:31,314:INFO:Initializing RandomizedSearchCV
2022-09-30 19:45:31,335:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,335:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,337:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,341:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,346:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,348:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,350:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,355:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,365:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,381:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,524:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,533:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,535:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,537:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,541:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,545:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,556:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,563:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,575:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,580:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,694:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,700:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,704:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,705:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,714:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,720:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,720:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,744:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,765:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,782:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,905:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,959:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:31,977:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,004:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,083:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,109:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,130:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,148:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,159:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,169:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,174:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,192:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,217:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,251:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,277:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,539:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,540:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,568:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,585:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,591:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,598:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,605:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,693:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,820:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:32,831:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:33,158:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:33,174:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:33,177:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:33,349:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:33,471:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:33,471:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:33,483:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:33,532:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:33,699:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:33,997:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:34,010:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:34,015:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:34,039:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:34,201:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:34,372:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:34,421:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:34,432:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:34,447:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:34,581:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:34,857:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:34,867:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:34,869:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:34,904:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:35,036:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:35,746:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:37,737:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:38,229:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:38,500:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:38,653:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:38,859:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:42,340:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:42,396:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:42,740:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:42,845:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:43,514:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:407: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2022-09-30 19:45:44,201:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:44,410:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:44,430:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:44,699:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:44,720:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:44,865:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:45,014:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:45,068:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:45,162:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:45,321:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:47,528:INFO:best_params: {'actual_estimator__n_estimators': 200, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'mse', 'actual_estimator__bootstrap': False}
2022-09-30 19:45:47,528:INFO:Hyperparameter search completed
2022-09-30 19:45:47,528:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:47,529:INFO:Initializing create_model()
2022-09-30 19:45:47,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1775fb400>, model_only=True, return_train_score=False, kwargs={'n_estimators': 200, 'min_samples_split': 7, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'mse', 'bootstrap': False})
2022-09-30 19:45:47,529:INFO:Checking exceptions
2022-09-30 19:45:47,530:INFO:Importing libraries
2022-09-30 19:45:47,530:INFO:Copying training dataset
2022-09-30 19:45:47,531:INFO:Defining folds
2022-09-30 19:45:47,531:INFO:Declaring metric variables
2022-09-30 19:45:47,532:INFO:Importing untrained model
2022-09-30 19:45:47,532:INFO:Declaring custom model
2022-09-30 19:45:47,534:INFO:Extra Trees Regressor Imported successfully
2022-09-30 19:45:47,536:INFO:Starting cross validation
2022-09-30 19:45:47,537:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:47,553:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:47,555:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:47,557:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:47,560:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:47,562:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:47,568:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:47,575:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:47,580:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:47,589:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:47,604:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:47,859:INFO:Calculating mean and std
2022-09-30 19:45:47,860:INFO:Creating metrics dataframe
2022-09-30 19:45:47,862:INFO:Finalizing model
2022-09-30 19:45:47,872:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2022-09-30 19:45:47,984:INFO:Uploading results into container
2022-09-30 19:45:47,985:INFO:Uploading model into container now
2022-09-30 19:45:47,985:INFO:master_model_container: 21
2022-09-30 19:45:47,985:INFO:display_container: 4
2022-09-30 19:45:47,985:INFO:ExtraTreesRegressor(criterion='mse', max_depth=11, max_features='sqrt',
                    min_impurity_decrease=0.0002, min_samples_leaf=5,
                    min_samples_split=7, n_estimators=200, n_jobs=-1,
                    random_state=123)
2022-09-30 19:45:47,985:INFO:create_model() successfully completed......................................
2022-09-30 19:45:48,041:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:48,041:INFO:choose_better activated
2022-09-30 19:45:48,042:INFO:SubProcess create_model() called ==================================
2022-09-30 19:45:48,043:INFO:Initializing create_model()
2022-09-30 19:45:48,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x290d9e7d0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-09-30 19:45:48,043:INFO:Checking exceptions
2022-09-30 19:45:48,045:INFO:Importing libraries
2022-09-30 19:45:48,045:INFO:Copying training dataset
2022-09-30 19:45:48,046:INFO:Defining folds
2022-09-30 19:45:48,046:INFO:Declaring metric variables
2022-09-30 19:45:48,046:INFO:Importing untrained model
2022-09-30 19:45:48,046:INFO:Declaring custom model
2022-09-30 19:45:48,046:INFO:Extra Trees Regressor Imported successfully
2022-09-30 19:45:48,046:INFO:Starting cross validation
2022-09-30 19:45:48,047:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-09-30 19:45:48,624:INFO:Calculating mean and std
2022-09-30 19:45:48,624:INFO:Creating metrics dataframe
2022-09-30 19:45:48,625:INFO:Finalizing model
2022-09-30 19:45:48,713:INFO:Uploading results into container
2022-09-30 19:45:48,713:INFO:Uploading model into container now
2022-09-30 19:45:48,713:INFO:master_model_container: 22
2022-09-30 19:45:48,714:INFO:display_container: 5
2022-09-30 19:45:48,714:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-30 19:45:48,714:INFO:create_model() successfully completed......................................
2022-09-30 19:45:48,767:INFO:SubProcess create_model() end ==================================
2022-09-30 19:45:48,768:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAPE is 0.0602
2022-09-30 19:45:48,768:INFO:ExtraTreesRegressor(criterion='mse', max_depth=11, max_features='sqrt',
                    min_impurity_decrease=0.0002, min_samples_leaf=5,
                    min_samples_split=7, n_estimators=200, n_jobs=-1,
                    random_state=123) result for MAPE is 0.0703
2022-09-30 19:45:48,768:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2022-09-30 19:45:48,768:INFO:choose_better completed
2022-09-30 19:45:48,768:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2022-09-30 19:45:48,772:INFO:master_model_container: 22
2022-09-30 19:45:48,772:INFO:display_container: 4
2022-09-30 19:45:48,773:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-09-30 19:45:48,773:INFO:tune_model() successfully completed......................................
2022-09-30 19:45:49,301:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2022-09-30 19:47:01,114:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2022-09-30 19:47:47,765:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2022-09-30 19:49:00,269:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- 2018

  warnings.warn(message, FutureWarning)

2022-09-30 19:50:12,046:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- 2018
Feature names seen at fit time, yet now missing:
- 2010

  warnings.warn(message, FutureWarning)

2022-09-30 19:50:32,103:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- 2018
Feature names seen at fit time, yet now missing:
- 2010

  warnings.warn(message, FutureWarning)

2022-09-30 19:51:43,130:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- 2018
- 2019
Feature names seen at fit time, yet now missing:
- 2010

  warnings.warn(message, FutureWarning)

2022-09-30 19:52:19,517:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- 2018
- 2019
Feature names seen at fit time, yet now missing:
- 2010

  warnings.warn(message, FutureWarning)

2022-09-30 19:52:31,544:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- 2018
- 2019
Feature names seen at fit time, yet now missing:
- 2010

  warnings.warn(message, FutureWarning)

2022-09-30 19:53:47,042:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- 2018
Feature names seen at fit time, yet now missing:
- 2010

  warnings.warn(message, FutureWarning)

2022-09-30 19:54:05,914:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- 2018
Feature names seen at fit time, yet now missing:
- 2010

  warnings.warn(message, FutureWarning)

2022-09-30 19:55:27,367:WARNING:/Users/andreas.maier/.local/share/virtualenvs/shellhackathon-J-_FuwKv/lib/python3.10/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- 2018
- 2019
Feature names seen at fit time, yet now missing:
- 2010
- 2011

  warnings.warn(message, FutureWarning)

